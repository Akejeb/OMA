[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Orchestrating Microbiome Analysis with Bioconductor",
    "section": "",
    "text": "Welcome\nYou are reading the online book, Orchestrating Microbiome Analysis with Bioconductor (Lahti et al. 2021), where we walk through common strategies and workflows in microbiome data science.\nThe book shows through concrete examples how you can take advantage of the latest developments in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical and heterogeneous microbiome profiling data sets. The book was borne out of necessity, while updating microbiome analysis tools to work with Bioconductor classes that provide support for multi-modal data collections. Many of these techniques are generic and widely applicable in other contexts as well.\nThis work has been heavily influenced by other similar resources, in particular the Orchestrating Single-Cell Analysis with Bioconductor (Amezquita et al. 2020), phyloseq tutorials (Callahan et al. 2016) and microbiome tutorials (Shetty and Lahti 2019). This book extends these resources to teach the grammar of Bioconductor workflows in the context of microbiome data science. As such, it supports the adoption of general skills in the analysis of large, hierarchical, and multi-modal data collections. We focus on microbiome analysis tools, including entirely new, partially updated as well as previously established methods.\nThis online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new contributors. Several individuals have contributed methods, workflows and improvements as acknowledged in the Introduction. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io. This online resource has been written in RMarkdown with the bookdown R package. The material is free to use with the Creative Commons Attribution-NonCommercial 3.0 License.\n\n\n// This block adds image to the front page\ntitle=document.getElementById('header');\ntitle.innerHTML = title.innerHTML + \n\n'&lt;img src=\"https://user-images.githubusercontent.com/60338854/128359392\\\n-6feef8df-30e9-4ea0-ae3b-4bb619d746ed.png\" alt=\"Microbiome\" width=\"50%\"/&gt;' +\n\n'&lt;p style=\"font-size:12px\"&gt;Figure source: Moreno-Indias &lt;i&gt;et al&lt;/i&gt;. (2021) \\\n&lt;a href=\"https://doi.org/10.3389/fmicb.2021.635781\"&gt;Statistical and \\\nMachine Learning Techniques in Human Microbiome Studies: Contemporary \\\nChallenges and Solutions&lt;/a&gt;. Frontiers in Microbiology 12:11.&lt;/p&gt;'\n\n\n\n\n\n\nAmezquita, Robert, Aaron Lun, Stephanie Hicks, and Raphael Gottardo. 2020. Orchestrating Single-Cell Analysis with Bioconductor. Bioconductor. https://bioconductor.org/books/release/OSCA/.\n\n\nCallahan, Ben J., Kris Sankaran, Julia A. Fukuyama, Paul J. McMurdie, and Susan P. Holmes. 2016. “Bioconductor Workflow for Microbiome Data Analysis: From Raw Reads to Community Analyses [Version 2; Peer Review: 3 Approved].” F1000Research 5: 1492. https://doi.org/10.12688/f1000research.8986.2.\n\n\nLahti, Leo, Sudarshan Shetty, Felix M Ernst, et al. 2021. Orchestrating Microbiome Analysis with Bioconductor [Beta Version]. microbiome.github.io/oma/.\n\n\nShetty, Sudarshan, and Leo Lahti. 2019. “Microbiome Data Science.” Journal of Biosciences 44: 115. https://doi.org/10.1007/s12038-019-9930-2."
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "(PART) Introduction",
    "section": "",
    "text": "Introduction\n\n\nThis work - Orchestrating Microbiome Analysis with Bioconductor [@OMA] - contributes novel methods and educational resources for microbiome data science. It aims to teach the grammar of Bioconductor workflows in the context of microbiome data science. We show through concrete examples how to use the latest developments and data analytical strategies in R/Bioconductor for the manipulation, analysis, and reproducible reporting of hierarchical, heterogeneous, and multi-modal microbiome profiling data. The data science methodology is tightly integrated with the broader R/Bioconductor ecosystem that focuses on the development of high-quality open research software for life sciences (@Gentleman2004, @Huber2015). The support for modularity and interoperability is a key to efficient resource sharing and collaborative development both within and across research fields. The central data infrastructure, the SummarizedExperiment data container and its derivatives, have already been widely adopted in microbiome research, single cell sequencing, and in other fields, allowing a rapid adoption and extensions of emerging data science techniques across application domains.\nWe assume that the reader is already familiar with R programming. For references and tips on introductory material for R and Bioconductor, see Chapter @ref(resources). This online resource and its associated ecosystem of microbiome data science tools are a result of a community-driven development process, and welcoming new users and contributors. You can find more information on how to find us online and join the developer community through the project homepage at microbiome.github.io.\nThe book is organized into three parts. We start by introducing the material and link to further resources for learning R and Bioconductor. We describe the key data infrastructure, the TreeSummarizedExperiment class that provides a container for microbiome data, and how to get started by loading microbiome data set in the context of this new framework. The second section, Focus Topics, covers the common steps in microbiome data analysis, beginning with the most common steps and progressing to more specialized methods in subsequent sections. Third, Workflows, provides case studies for the various datasets used throughout the book. Finally, Appendix, links to further resources and acknowledgments."
  },
  {
    "objectID": "06_packages.html#package-installation",
    "href": "06_packages.html#package-installation",
    "title": "2  Packages",
    "section": "2.1 Package installation",
    "text": "2.1 Package installation\nYou can install all packages that are required to run every example in this book via the following command:\n\nsource(\"https://raw.githubusercontent.com/microbiome/OMA/master/install_packages.R\")\n\n\n2.1.1 Installing specific packages\nYou can install R packages of your choice with the following command line procedure.\n\n\n\n\n\n\n\nBioconductor development version requires the installation of the latest R beta version. This is primarily recommended for those who already have experience with R/Bioconductor and need access to the latest updates.\n\nBiocManager::install(\"microbiome/mia\", version=\"devel\")\n\nGithub development version provides access to the latest but potentially unstable features. This is useful when you want access to all available tools.\n\ndevtools::install_github(\"microbiome/mia\")"
  },
  {
    "objectID": "06_packages.html#ecosystem",
    "href": "06_packages.html#ecosystem",
    "title": "2  Packages",
    "section": "2.2 Package ecosystem",
    "text": "2.2 Package ecosystem\nMethods for (Tree)SummarizedExperiment and MultiAssayExperiment data containers are provided by multiple independent developers through R/Bioconductor packages. Some of these are listed below (tips on new packages are welcome).\n\n2.2.1 mia package family\nThe mia package family provides general methods for microbiome data wrangling, analysis and visualization.\n\nmia: Microbiome analysis tools [@R_mia]\nmiaViz: Microbiome analysis specific visualization [@Ernst2022]\nmiaSim: Microbiome data simulations [@Simsek2021]\nmiaTime: Microbiome time series analysis [@Lahti2021]\n\n\n\n2.2.2 Differential abundance\nThe following DA methods support (Tree)SummarizedExperiment.\n\nANCOMBC for differential abundance analysis\nbenchdamic for benchmarking differential abundance methods\nALDEx2 for differential abundance analysis\n\n\n\n2.2.3 Other packages\n\nphilr (@Silverman2017) phylogeny-aware phILR transformation\nMicrobiotaProcess for “tidy” analysis of microbiome and other ecological data\nTools for Microbiome Analysis site listed over 130 R packages for microbiome data science in\n\nMany of these are not in Bioconductor, or do not directly support the data containers used in this book but can be often used with minor modifications. The phyloseq-based tools can be used by converting the TreeSE data into phyloseq with makePhyloseqFromTreeSummarizedExperiment.\n\n\n\n\n2.2.4 Open microbiome data\nHundreds of published microbiome data sets are readily available in these data containers (see @ref(example-data))."
  },
  {
    "objectID": "04_containers.html#data-science-framework",
    "href": "04_containers.html#data-science-framework",
    "title": "3  Microbiome Data",
    "section": "3.1 Data science framework",
    "text": "3.1 Data science framework\nThe building blocks of the framework are data container (SummarizedExperiment and its derivatives), packages from various developers using the TreeSE container, open demonstration data sets, in a separate chapter @ref(example-data), and online tutorials including this online book as well as the various package vignettes and other materials."
  },
  {
    "objectID": "04_containers.html#data-containers",
    "href": "04_containers.html#data-containers",
    "title": "3  Microbiome Data",
    "section": "3.2 Data containers",
    "text": "3.2 Data containers\nSummarizedExperiment (SE) [@R_SummarizedExperiment] is a generic and highly optimized container for complex data structures. It has become a common choice for analysing various types of biomedical profiling data, such as RNAseq, ChIp-Seq, microarrays, flow cytometry, proteomics, and single-cell sequencing.\n[TreeSummarizedExperiment] (TreeSE) [@R_TreeSummarizedExperiment] was developed as an extension to incorporate hierarchical information (such as phylogenetic trees and sample hierarchies) and reference sequences.\n[MultiAssayExperiment] (MAE) [@Ramos2017] provides an organized way to bind several different data containers together in a single object. For example, we can bind microbiome data (in TreeSE container) with metabolomic profiling data (in SE) container, with (partially) shared sample metadata. This is convenient and robust for instance in subsetting and other data manipulation tasks. Microbiome data can be part of multiomics experiments and analysis strategies. We highlight how the methods used througout in this book relate to this data framework by using the TreeSummarizedExperiment, MultiAssayExperiment, and classes beyond.\nThis section provides an introductions to these data containers. In microbiome data science, these containers link taxonomic abundance tables with rich side information on the features and samples. Taxonomic abundance data can be obtained by 16S rRNA amplicon or metagenomic sequencing, phylogenetic microarrays, or by other means. Many microbiome experiments include multiple versions and types of data generated independently or derived from each other through transformation or agglomeration. We start by providing recommendations on how to represent different varieties of multi-table data within the TreeSummarizedExperiment class.\nThe options and recommendations are summarized in Table @ref(tab:options).\n\n3.2.1 Assay data\nThe original count-based taxonomic abundance tables may have different transformations, such as logarithmic, Centered Log-Ratio (CLR), or relative abundance. These are typically stored in assays.\nLet us load example data and rename it as tse.\n\nlibrary(mia)\ndata(\"hitchip1006\", package = \"miaTime\")\ntse &lt;- hitchip1006\n\nThe assays slot contains the experimental data as multiple count matrices. The result of assays is a list of matrices.\n\nassays(tse)\n\nList of length 1\nnames(1): counts\n\n\nIndividual assays can be accessed via assay\n\nassay(tse, \"counts\")[1:5,1:7]\n\n                             Sample-1 Sample-2 Sample-3 Sample-4 Sample-5\nActinomycetaceae                    0        0        0        0        0\nAerococcus                          0        0        0        0        0\nAeromonas                           0        0        0        0        0\nAkkermansia                        21       36      475       61       34\nAlcaligenes faecalis et rel.        1        1        1        2        1\n                             Sample-6 Sample-7\nActinomycetaceae                    0        0\nAerococcus                          0        0\nAeromonas                           0        0\nAkkermansia                        14       27\nAlcaligenes faecalis et rel.        1        1\n\n\nTo illustrate the use of multiple assays, the relative abundance data can be calculated and stored along the original count data using transformAssay.\n\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\nassays(tse)\n\nList of length 2\nnames(2): counts relabundance\n\n\nNow there are two assays available in the tse object, counts and relabundance.\n\nassay(tse, \"relabundance\")[1:5,1:7]\n\n                              Sample-1  Sample-2  Sample-3  Sample-4  Sample-5\nActinomycetaceae             0.0000000 0.000e+00 0.0000000 0.0000000 0.000e+00\nAerococcus                   0.0000000 0.000e+00 0.0000000 0.0000000 0.000e+00\nAeromonas                    0.0000000 0.000e+00 0.0000000 0.0000000 0.000e+00\nAkkermansia                  0.0027657 3.547e-03 0.0666106 0.0056195 2.833e-03\nAlcaligenes faecalis et rel. 0.0001317 9.854e-05 0.0001402 0.0001842 8.333e-05\n                              Sample-6  Sample-7\nActinomycetaceae             0.0000000 0.0000000\nAerococcus                   0.0000000 0.0000000\nAeromonas                    0.0000000 0.0000000\nAkkermansia                  0.0017690 0.0045570\nAlcaligenes faecalis et rel. 0.0001264 0.0001688\n\n\nHere the dimension of the count data remains unchanged in transformation. This is in fact, a requirement for the assays.\n\n\n3.2.2 colData\ncolData contains data on the samples.\n\ncolData(tse)\n\nDataFrame with 1151 rows and 10 columns\n                  age      sex nationality DNA_extraction_method  project\n            &lt;integer&gt; &lt;factor&gt;    &lt;factor&gt;              &lt;factor&gt; &lt;factor&gt;\nSample-1           28   male            US                    NA        1\nSample-2           24   female          US                    NA        1\nSample-3           52   male            US                    NA        1\nSample-4           22   female          US                    NA        1\nSample-5           25   female          US                    NA        1\n...               ...      ...         ...                   ...      ...\nSample-1168        50   female Scandinavia                     r       40\nSample-1169        31   female Scandinavia                     r       40\nSample-1170        31   female Scandinavia                     r       40\nSample-1171        52   male   Scandinavia                     r       40\nSample-1172        52   male   Scandinavia                     r       40\n            diversity   bmi_group  subject      time      sample\n            &lt;numeric&gt;    &lt;factor&gt; &lt;factor&gt; &lt;numeric&gt; &lt;character&gt;\nSample-1         5.76 severeobese        1         0    Sample-1\nSample-2         6.06 obese              2         0    Sample-2\nSample-3         5.50 lean               3         0    Sample-3\nSample-4         5.87 underweight        4         0    Sample-4\nSample-5         5.89 lean               5         0    Sample-5\n...               ...         ...      ...       ...         ...\nSample-1168      5.87 severeobese      244       8.1 Sample-1168\nSample-1169      5.87 overweight       245       2.3 Sample-1169\nSample-1170      5.92 overweight       245       8.2 Sample-1170\nSample-1171      6.04 overweight       246       2.1 Sample-1171\nSample-1172      5.74 overweight       246       7.9 Sample-1172\n\n\n\n\n3.2.3 rowData\nrowData contains data on the features of the analyzed samples. Of particular interest to the microbiome field, this is used to store taxonomic information.\n\nrowData(tse)\n\nDataFrame with 130 rows and 3 columns\n                                      Phylum          Family\n                                 &lt;character&gt;     &lt;character&gt;\nActinomycetaceae              Actinobacteria  Actinobacteria\nAerococcus                        Firmicutes         Bacilli\nAeromonas                     Proteobacteria  Proteobacteria\nAkkermansia                  Verrucomicrobia Verrucomicrobia\nAlcaligenes faecalis et rel.  Proteobacteria  Proteobacteria\n...                                      ...             ...\nVibrio                        Proteobacteria  Proteobacteria\nWeissella et rel.                 Firmicutes         Bacilli\nWissella et rel.                  Firmicutes         Bacilli\nXanthomonadaceae              Proteobacteria  Proteobacteria\nYersinia et rel.              Proteobacteria  Proteobacteria\n                                              Genus\n                                        &lt;character&gt;\nActinomycetaceae                   Actinomycetaceae\nAerococcus                               Aerococcus\nAeromonas                                 Aeromonas\nAkkermansia                             Akkermansia\nAlcaligenes faecalis et rel. Alcaligenes faecalis..\n...                                             ...\nVibrio                                       Vibrio\nWeissella et rel.                 Weissella et rel.\nWissella et rel.                   Wissella et rel.\nXanthomonadaceae                   Xanthomonadaceae\nYersinia et rel.                   Yersinia et rel.\n\n\n\n\n3.2.4 rowTree\nPhylogenetic trees also play an important role in the microbiome field. The TreeSummarizedExperiment class can keep track of features and node relations via two functions, rowTree and rowLinks.\nA tree can be accessed via rowTree as phylo object.\n\nrowTree(tse)\n\nNULL\n\n\nThe links to the individual features are available through rowLinks.\n\nrowLinks(tse)\n\nNULL\n\n\nPlease note that there can be a 1:1 relationship between tree nodes and features, but this is not a must-have. This means there can be features, which are not linked to nodes, and nodes, which are not linked to features. To change the links in an existing object, the changeTree function is available.\n\n\n3.2.5 Alternative experiments\nAlternative experiments complement assays. They can contain complementary data, which is no longer tied to the same dimensions as the assay data. However, the number of samples (columns) must be the same.\nThis can come into play, for instance, when one has taxonomic abundance profiles quantified with different measurement technologies, such as phylogenetic microarrays, amplicon sequencing, or metagenomic sequencing. Another common use case is including abundance tables for different taxonomic ranks. Such alternative experiments concerning the same set of samples can be stored as\n\nSeparate assays assuming that the taxonomic information can be mapped between features directly 1:1; or\nData in the altExp slot of the TreeSummarizedExperiment, if the feature dimensions differ. Each element of the altExp slot is a SummarizedExperiment or an object from a derived class with independent feature data.\n\nThe following shows how to store taxonomic abundance tables agglomerated at different taxonomic levels. However, the data could as well originate from entirely different measurement sources as long as the samples match.\nLet us first agglomerate the data to Phylum level. This yields a new TreeSE data object.\n\ntse_phylum &lt;- mergeFeaturesByRank(tse, \"Phylum\", na.rm=TRUE)\n# Both have the same number of columns (samples)\ndim(tse)\n\n[1]  130 1151\n\ndim(tse_phylum)\n\n[1]    8 1151\n\n\nThen we can add the new phylum-level data object as an alternative experiment in the original data.\n\n# Add the new data object to the original data object as an alternative experiment with the name \"Phylum\"\naltExp(tse, \"Phylum\") &lt;- tse_phylum\n\n# Check the alternative experiment names available in the data\naltExpNames(tse)\n\n[1] \"Phylum\"\n\n\nWe can now subset the data, for instance, and this acts on both altExp and assay data.\n\ntse[,1:10]\n\nclass: TreeSummarizedExperiment \ndim: 130 10 \nmetadata(0):\nassays(2): counts relabundance\nrownames(130): Actinomycetaceae Aerococcus ... Xanthomonadaceae\n  Yersinia et rel.\nrowData names(3): Phylum Family Genus\ncolnames(10): Sample-1 Sample-2 ... Sample-9 Sample-10\ncolData names(10): age sex ... time sample\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(1): Phylum\nrowLinks: NULL\nrowTree: NULL\ncolLinks: NULL\ncolTree: NULL\n\ndim(altExp(tse[,1:10],\"Phylum\"))\n\n[1]  8 10\n\n\nFor more details on altExp, you can check the introduction to the SingleCellExperiment package [@R_SingleCellExperiment].\n\n\n3.2.6 MultiAssayExperiments\nMultiple experiments relate to complementary measurement types, such as transcriptomic or metabolomic profiling of the microbiome or the host. Multiple experiments can be represented using the same options as alternative experiments, or by using the MultiAssayExperiment class [@Ramos2017]. Depending on how the datasets relate to each other the data can be stored as:\n\nSeparate altExp if the samples can be matched directly 1:1; or\nAs MultiAssayExperiment objects, in which the connections between samples are defined through a sampleMap. Each element on the experimentsList of an MultiAssayExperiment is matrix or matrix-like objects, including SummarizedExperiment objects, and the number of samples can differ between the elements.\n\n\nFor information have a look at the intro vignette of the MultiAssayExperiment package.\n\n(#tab:options) Recommended options for storing multiple data tables in microbiome studies The assays are best suited for data transformations (one-to-one match between samples and columns across the assays). The alternative experiments are particularly suitable for alternative versions of the data that are of same type but may have a different number of features (e.g. taxonomic groups); this is for instance the case with taxonomic abundance tables agglomerated at different levels (e.g. genus vs. phyla) or alternative profiling technologies (e.g. amplicon sequencing vs. shallow shotgun metagenomics). For alternative experiments one-to-one match between samples (cols) is libraryd but the alternative experiment tables can have different numbers of features (rows). Finally, elements of the MultiAssayExperiment provide the most flexible way to incorporate multi-omic data tables with flexible numbers of samples and features. We recommend these conventions as the basis for methods development and application in microbiome studies.\n\n\nOption\nRows (features)\nCols (samples)\nRecommended\n\n\n\n\nassays\nmatch\nmatch\nData transformations\n\n\naltExp\nfree\nmatch\nAlternative experiments\n\n\nMultiAssay\nfree\nfree (mapping)\nMulti-omic experiments"
  },
  {
    "objectID": "04_containers.html#example-data",
    "href": "04_containers.html#example-data",
    "title": "3  Microbiome Data",
    "section": "3.3 Demonstration data",
    "text": "3.3 Demonstration data\nOpen demonstration data for testing and benchmarking purposes is available from multiple locations. This chapter introduces some options. The other chapters of this book provide ample examples about the use of the data.\n\n3.3.1 Package data\nThe mia R package contains example datasets that are direct conversions from the alternative phyloseq container to the TreeSummarizedExperiment container.\nList the available datasets in the mia package:\n\nlibrary(mia)\ndata(package=\"mia\")\n\nLoad the GlobalPatterns data from the mia package:\n\ndata(\"GlobalPatterns\", package=\"mia\")\nGlobalPatterns\n\nclass: TreeSummarizedExperiment \ndim: 19216 26 \nmetadata(0):\nassays(1): counts\nrownames(19216): 549322 522457 ... 200359 271582\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(26): CL3 CC1 ... Even2 Even3\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (19216 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\n3.3.1.1 Tengeler2020\nTengeler2020 is derived from a randomised blinded study on the effects of gut microbiome on attention-deficit/hyperactivity disorder (ADHD) in humanised mice [@Tengeler2020]. The dataset is briefly presented in these slides.\n\n\n3.3.1.2 HintikkaXOData\nHintikkaXOData is derived from a study about the effects of fat diet and prebiotics on the microbiome of rat models [@Hintikka2021]. It is available in the MAE data container for R. The dataset is briefly summarized in these slides.\n\n\n\n3.3.2 ExperimentHub data\nExperimentHub provides a variety of data resources, including the microbiomeDataSets package [@Morgan2021; @microlahti2021].\nA table of the available datasets is available through the availableDataSets function.\n\nlibrary(microbiomeDataSets)\navailableDataSets()\n\n            Dataset\n1  GrieneisenTSData\n2    HintikkaXOData\n3       LahtiMLData\n4        LahtiMData\n5       LahtiWAData\n6      OKeefeDSData\n7 SilvermanAGutData\n8        SongQAData\n9   SprockettTHData\n\n\nAll data are downloaded from ExperimentHub and cached for local re-use. Check the man pages of each function for a detailed documentation of the data contents and references. Let us retrieve a MultiAssayExperiment dataset:\n\n# mae &lt;- HintikkaXOData()\n# Since HintikkaXOData is now added to mia, we can load it directly from there\n# We suggest to check other datasets from microbiomeDataSets\ndata(HintikkaXOData, package = \"mia\")\nmae &lt;- HintikkaXOData\n\nData is available in SummarizedExperiment, r Biocpkg(\"TreeSummarizedExperiment\") and r Biocpkg(\"MultiAssayExperiment\") data containers; see the separate page on alternative containers for more details.\n\n\n3.3.3 Curated metagenomic data\ncuratedMetagenomicData is a large collection of curated human microbiome datasets, provided as (Tree)SummarizedExperiment objects [@Pasolli2017]. The resource provides curated human microbiome data including gene families, marker abundance, marker presence, pathway abundance, pathway coverage, and relative abundance for samples from different body sites. See the package homepage for more details on data availability and access.\nAs one example, let us retrieve the Vatanen (2016) [@Vatanen2016] data set. This is a larger collection with a bit longer download time.\n\nlibrary(curatedMetagenomicData)\ntse &lt;- curatedMetagenomicData(\"Vatanen*\", dryrun = FALSE, counts = TRUE)\n\n\n\n3.3.4 Other data sources\nThe current collections provide access to vast microbiome data resources. The output has to be converted into TreeSE/MAE separately.\n\nMGnifyR provides access to EBI/MGnify\nqiitr provides access to QIITA"
  },
  {
    "objectID": "04_containers.html#loading-experimental-microbiome-data",
    "href": "04_containers.html#loading-experimental-microbiome-data",
    "title": "3  Microbiome Data",
    "section": "3.4 Loading experimental microbiome data",
    "text": "3.4 Loading experimental microbiome data\n\n3.4.1 16S workflow\nResult of amplicon sequencing is a large number of files that include all the sequences that were read from samples. Those sequences need to be matched with taxa. Additionally, we need to know how many times each taxa were found from each sample.\nThere are several algorithms to do that, and DADA2 is one of the most common. You can find DADA2 pipeline tutorial, for example, here. After the DADA2 portion of the tutorial is completed, the data is stored into phyloseq object (Bonus: Handoff to phyloseq). To store the data to TreeSummarizedExperiment, follow the example below.\nYou can find full workflow script without further explanations and comments from here\nLoad required packages.\n\nlibrary(mia)\nlibrary(ggplot2)\nlibrary(BiocManager)\nlibrary(Biostrings)\n\nCreate arbitrary example sample metadata like it was done in the tutorial. Usually, sample metadata is imported as a file.\n\nsamples.out &lt;- rownames(seqtab.nochim)\nsubject &lt;- sapply(strsplit(samples.out, \"D\"), `[`, 1)\ngender &lt;- substr(subject,1,1)\nsubject &lt;- substr(subject,2,999)\nday &lt;- as.integer(sapply(strsplit(samples.out, \"D\"), `[`, 2))\nsamdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)\nsamdf$When &lt;- \"Early\"\nsamdf$When[samdf$Day&gt;100] &lt;- \"Late\"\nrownames(samdf) &lt;- samples.out\n\nConvert data into right format and create a TreeSE object.\n\n# Create a list that contains assays\ncounts &lt;- t(seqtab.nochim)\ncounts &lt;- as.matrix(counts)\nassays &lt;- SimpleList(counts = counts)\n\n# Convert colData and rowData into DataFrame\nsamdf &lt;- DataFrame(samdf)\ntaxa &lt;- DataFrame(taxa)\n\n# Create TreeSE\ntse &lt;- TreeSummarizedExperiment(assays = assays,\n                                colData = samdf,\n                                rowData = taxa\n                                )\n\n# Remove mock sample like it is also done in DADA2 pipeline tutorial\ntse &lt;- tse[ , colnames(tse) != \"mock\"]\n\nAdd sequences into referenceSeq slot and convert rownames into simpler format.\n\n# Convert sequences into right format\ndna &lt;- Biostrings::DNAStringSet( rownames(tse) )\n# Add sequences into referenceSeq slot\nreferenceSeq(tse) &lt;- dna\n# Convert rownames into ASV_number format\nrownames(tse) &lt;- paste0(\"ASV\", seq( nrow(tse) ))\ntse\n\nclass: TreeSummarizedExperiment \ndim: 232 20 \nmetadata(0):\nassays(1): counts\nrownames(232): ASV1 ASV2 ... ASV231 ASV232\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(20): F3D0 F3D1 ... F3D9 Mock\ncolData names(4): Subject Gender Day When\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: NULL\nrowTree: NULL\ncolLinks: NULL\ncolTree: NULL\nreferenceSeq: a DNAStringSet (232 sequences)\n\n\n\n\n3.4.2 Import from external files\nMicrobiome (taxonomic) profiling data is commonly distributed in various file formats. You can import such external data files as a (Tree)SummarizedExperiment object, but the details depend on the file format. Here, we provide examples for common formats. Some datasets and raw files to learn how to import raw data and construct TreeSE/MAE containers are available in the microbiome data repository.\n\n3.4.2.1 CSV import\nCSV data tables can be imported with the standard R functions, then converted to the desired format. For detailed examples, you can check the Bioconductor course material by Martin Morgan. You can also check the example files and construct your own CSV files accordingly.\nRecommendations for the CSV files are the following. File names are arbitrary; we refer here to the same names as in the examples:\n\nAbundance table (assay_taxa.csv): data matrix (features x samples); first column provides feature IDs, the first row provides sample IDs; other values should be numeric (abundances).\nRow data (rowdata_taxa.csv): data table (features x info); first column provides feature IDs, the first row provides column headers; this file usually contains the taxonomic mapping between different taxonomic levels. Ideally, the feature IDs (row names) match one-to-one with the abundance table row names.\nColumn data (coldata.csv): data table (samples x info); first column provides sample IDs, the first row provides column headers; this file usually contains the sample metadata/phenodata (such as subject age, health etc). Ideally, the sample IDs match one-to-one with the abundance table column names.\n\nAfter you have set up the CSV files, you can read them in R:\n\ncount_file  &lt;- \"data/assay_taxa.csv\"\ntax_file    &lt;- \"data/rowdata_taxa.csv\"\nsample_file &lt;- \"data/coldata.csv\"\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)   # Abundance table (e.g. ASV data; to assay data)\ntax     &lt;- read.csv(tax_file, row.names=1)     # Taxonomy table (to rowData)\nsamples &lt;- read.csv(sample_file, row.names=1)  # Sample data (to colData)\n\nAfter reading the data in R, ensure the following:\n\nabundance table (counts): numeric matrix, with feature IDs as rownames and sample IDs as column names\nrowdata (tax): DataFrame, with feature IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free but in microbiome analysis they usually they refer to taxonomic ranks. The rownames in rowdata should match with rownames in abundance table.\ncoldata (samples): DataFrame, with sample IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free. The rownames in coldata should match with colnames in abundance table.\n\nAlways ensure that the tables have rownames! The TreeSE constructor compares rownames and ensures that, for example, right samples are linked with right patient.\nAlso ensure that the row and column names match one-to-one between abundance table, rowdata, and coldata:\n\n# Match rows and columns\ncounts &lt;- counts[rownames(tax), rownames(samples)]\n\n# Let us ensure that the data is in correct (numeric matrix) format:\ncounts &lt;- as.matrix(counts)\n\nIf you hesitate about the format of the data, you can compare to one of the available demonstration datasets, and make sure that your data components have the same format.\nThere are many different source files and many different ways to read data in R. One can do data manipulation in R as well. Investigate the entries as follows.\n\n# coldata rownames match assay colnames\nall(rownames(samples) == colnames(counts)) # our dataset\n\n[1] TRUE\n\nclass(samples) # should be data.frame or DataFrame\n\n[1] \"data.frame\"\n\n# rowdata rownames match assay rownames\nall(rownames(tax) == rownames(counts)) # our dataset\n\n[1] TRUE\n\nclass(tax) # should be data.frame or DataFrame\n\n[1] \"data.frame\"\n\n# Counts \nclass(counts) # should be a numeric matrix\n\n[1] \"matrix\" \"array\" \n\n\n\n\n\n3.4.3 Constructing TreeSummarizedExperiment\nNow let us create the TreeSE object from the input data tables. Here we also convert the data objects in their preferred formats:\n\ncounts –&gt; numeric matrix\nrowData –&gt; DataFrame\ncolData –&gt; DataFrame\n\nThe SimpleList could be used to include multiple alternative assays, if necessary.\n\n# Create a TreeSE\ntse_taxa &lt;- TreeSummarizedExperiment(assays =  SimpleList(counts = counts),\n                                     colData = DataFrame(samples),\n                                     rowData = DataFrame(tax))\n\ntse_taxa\n\nclass: TreeSummarizedExperiment \ndim: 12706 40 \nmetadata(0):\nassays(1): counts\nrownames(12706): GAYR01026362.62.2014 CVJT01000011.50.2173 ...\n  JRJTB:03787:02429 JRJTB:03787:02478\nrowData names(7): Phylum Class ... Species OTU\ncolnames(40): C1 C2 ... C39 C40\ncolData names(6): Sample Rat ... Fat XOS\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: NULL\nrowTree: NULL\ncolLinks: NULL\ncolTree: NULL\n\n\nNow you should have a ready-made TreeSE data object that can be used in downstream analyses.\n\n\n3.4.4 Constructing MultiAssayExperiment\nTo construct a MultiAssayExperiment object, just combine multiple TreeSE data containers. Here we import metabolite data from the same study.\n\ncount_file &lt;- \"data/assay_metabolites.csv\"\nsample_file &lt;- \"data/coldata.csv\"\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)  \nsamples &lt;- read.csv(sample_file, row.names=1)\n\n# Create a TreeSE for the metabolite data\ntse_metabolite &lt;- TreeSummarizedExperiment(assays = SimpleList(concs = as.matrix(counts)),\n                                           colData = DataFrame(samples))\n\ntse_metabolite\n\nclass: TreeSummarizedExperiment \ndim: 38 40 \nmetadata(0):\nassays(1): concs\nrownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone\nrowData names(0):\ncolnames(40): C1 C2 ... C39 C40\ncolData names(6): Sample Rat ... Fat XOS\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: NULL\nrowTree: NULL\ncolLinks: NULL\ncolTree: NULL\n\n\nNow we can combine these two experiments into MAE.\n\n# Create an ExperimentList that includes experiments\nexperiments &lt;- ExperimentList(microbiome = tse_taxa, \n                              metabolite = tse_metabolite)\n\n# Create a MAE\nmae &lt;- MultiAssayExperiment(experiments = experiments)\n\nmae\n\nA MultiAssayExperiment object of 2 listed\n experiments with user-defined names and respective classes.\n Containing an ExperimentList class object of length 2:\n [1] microbiome: TreeSummarizedExperiment with 12706 rows and 40 columns\n [2] metabolite: TreeSummarizedExperiment with 38 rows and 40 columns\nFunctionality:\n experiments() - obtain the ExperimentList instance\n colData() - the primary/phenotype DataFrame\n sampleMap() - the sample coordination DataFrame\n `$`, `[`, `[[` - extract colData columns, subset, or experiment\n *Format() - convert into a long or wide DataFrame\n assays() - convert ExperimentList to a SimpleList of matrices\n exportClass() - save data to flat files\n\n\n\n\n3.4.5 Import functions for standard formats\nSpecific import functions are provided for:\n\nBiom files (see help(mia::loadFromBiom))\nQIIME2 files (see help(mia::loadFromQIIME2))\nMothur files (see help(mia::loadFromMothur))\n\n\n3.4.5.1 Biom import\nHere we show how Biom files are imported into a TreeSE object using as an example Tengeler2020, which is further described in section @ref(tengeler-desc). This dataset consists of 3 files, which can be fetched or downloaded from this repository:\n\nbiom file: abundance table and taxonomy information\ncsv file: sample metadata\ntree file: phylogenetic tree\n\nTo begin with, we store the data in a local directory within the working directory, such as data/, and define the source file paths.\n\nbiom_file_path &lt;- \"data/Aggregated_humanization2.biom\"\nsample_meta_file_path &lt;- \"data/Mapping_file_ADHD_aggregated.csv\"\ntree_file_path &lt;- \"data/Data_humanization_phylo_aggregation.tre\"\n\nNow we can read in the biom file and convert it into a TreeSE object. In addition, we retrieve the rank names from the prefixes of the feature names and then remove them with the rankFromPrefix and removeTaxaPrefixes optional arguments.\n\nlibrary(mia)\n\n# read biom and convert it to TreeSE\ntse &lt;- loadFromBiom(biom_file_path,\n                    rankFromPrefix = TRUE,\n                    removeTaxaPrefixes = TRUE)\n\n# Check\ntse\n\nclass: TreeSummarizedExperiment \ndim: 151 27 \nmetadata(0):\nassays(1): counts\nrownames(151): 1726470 1726471 ... 17264756 17264757\nrowData names(6): taxonomy1 Phylum ... Family Genus\ncolnames(27): A110 A111 ... A38 A39\ncolData names(0):\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: NULL\nrowTree: NULL\ncolLinks: NULL\ncolTree: NULL\n\n\nThe assays slot includes a list of abundance tables. The imported abundance table is named as “counts”. Let us inspect only the first cols and rows.\n\nassay(tse, \"counts\")[1:3, 1:3]\n\n          A110  A111  A12\n1726470  17722 11630    0\n1726471  12052     0 2679\n17264731     0   970    0\n\n\nThe rowdata includes taxonomic information from the biom file. The head() command shows just the beginning of the data table for an overview.\nknitr::kable() helps print the information more nicely.\n\nhead(rowData(tse))\n\nDataFrame with 6 rows and 6 columns\n           taxonomy1          Phylum            Class              Order\n         &lt;character&gt;     &lt;character&gt;      &lt;character&gt;        &lt;character&gt;\n1726470    \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n1726471    \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n17264731   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n17264726   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n1726472    \"Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales\n17264724   \"Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n                      Family            Genus\n                 &lt;character&gt;      &lt;character&gt;\n1726470       Bacteroidaceae     Bacteroides\"\n1726471       Bacteroidaceae     Bacteroides\"\n17264731  Porphyromonadaceae Parabacteroides\"\n17264726      Bacteroidaceae     Bacteroides\"\n1726472  Verrucomicrobiaceae     Akkermansia\"\n17264724      Bacteroidaceae     Bacteroides\"\n\n\nWe further polish the feature names by removing unnecessary characters and then replace the original rowData with its updated version.\n\n# Genus level has additional '\\\"', so let's delete that also\nrowdata_modified &lt;- BiocParallel::bplapply(rowData(tse), \n                                           FUN = stringr::str_remove, \n                                           pattern = '\\\"')\n\n# rowdata_modified is a list, so convert this back to DataFrame format. \n# and assign the cleaned data back to the TSE rowData\nrowData(tse) &lt;- DataFrame(rowdata_modified)\n\n# Now we have a nicer table\nhead(rowData(tse))\n\nDataFrame with 6 rows and 6 columns\n           taxonomy1          Phylum            Class              Order\n         &lt;character&gt;     &lt;character&gt;      &lt;character&gt;        &lt;character&gt;\n1726470     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n1726471     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n17264731    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n17264726    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n1726472     Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales\n17264724    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n                      Family           Genus\n                 &lt;character&gt;     &lt;character&gt;\n1726470       Bacteroidaceae     Bacteroides\n1726471       Bacteroidaceae     Bacteroides\n17264731  Porphyromonadaceae Parabacteroides\n17264726      Bacteroidaceae     Bacteroides\n1726472  Verrucomicrobiaceae     Akkermansia\n17264724      Bacteroidaceae     Bacteroides\n\n\nWe notice that the imported biom file did not contain any colData yet, so only an empty dataframe appears in this slot.\n\nhead(colData(tse))\n\nDataFrame with 6 rows and 0 columns\n\n\nLet us add colData from the sample metadata, which is stored in a CSV file.\n\n# CSV file with colnames in the first row and rownames in the first column\nsample_meta &lt;- read.csv(sample_meta_file_path,\n                        sep = \",\", row.names = 1)\n\n# Add this sample data to colData of the taxonomic data object\n# Note that the data must be given in a DataFrame format (required for our purposes)\ncolData(tse) &lt;- DataFrame(sample_meta)\n\nNow the colData includes the sample metadata.\n\nhead(colData(tse))\n\nDataFrame with 6 rows and 4 columns\n       Treatment      Cohort TreatmentxCohort Description\n     &lt;character&gt; &lt;character&gt;      &lt;character&gt; &lt;character&gt;\nA110        ADHD    Cohort_1    ADHD_Cohort_1        A110\nA12         ADHD    Cohort_1    ADHD_Cohort_1         A12\nA15         ADHD    Cohort_1    ADHD_Cohort_1         A15\nA19         ADHD    Cohort_1    ADHD_Cohort_1         A19\nA21         ADHD    Cohort_2    ADHD_Cohort_2         A21\nA23         ADHD    Cohort_2    ADHD_Cohort_2         A23\n\n\nFinally, we add a phylogenetic tree to the rowData slot. Such feature is available only in TreeSE objects. Similarly, Trees specifying the sample hierarchy can be stored in the colTree slot.\nHere, we read in the file containing the phylogenetic tree and insert it in corresponding slot of the TreeSE object.\n\n# Reads the tree file\ntree &lt;- ape::read.tree(tree_file_path)\n\n# Add tree to rowTree\nrowTree(tse) &lt;- tree\n\n# Check\ntse\n\nclass: TreeSummarizedExperiment \ndim: 151 27 \nmetadata(0):\nassays(1): counts\nrownames(151): 1726470 1726471 ... 17264756 17264757\nrowData names(6): taxonomy1 Phylum ... Family Genus\ncolnames(27): A110 A12 ... A35 A38\ncolData names(4): Treatment Cohort TreatmentxCohort Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (151 rows)\nrowTree: 1 phylo tree(s) (151 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\nNow the rowTree slot contains the phylogenetic tree:\n\nhead(rowTree(tse))\n\n\n\n\n3.4.6 Conversions between data formats in R\nIf the data has already been imported in R in another format, it can be readily converted into TreeSummarizedExperiment, as shown in our next example. Note that similar conversion functions to TreeSummarizedExperiment are available for multiple data formats via the mia package (see makeTreeSummarizedExperimentFrom* for phyloseq, Biom, and DADA2).\n\nlibrary(mia)\n\n# phyloseq example data\ndata(GlobalPatterns, package=\"phyloseq\") \nGlobalPatterns_phyloseq &lt;- GlobalPatterns\nGlobalPatterns_phyloseq\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\nsample_data() Sample Data:       [ 26 samples by 7 sample variables ]\ntax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n\n\n\n# convert phyloseq to TSE\nGlobalPatterns_TSE &lt;- makeTreeSummarizedExperimentFromPhyloseq(GlobalPatterns_phyloseq) \nGlobalPatterns_TSE\n\nclass: TreeSummarizedExperiment \ndim: 19216 26 \nmetadata(0):\nassays(1): counts\nrownames(19216): 549322 522457 ... 200359 271582\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(26): CL3 CC1 ... Even2 Even3\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (19216 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\nWe can also convert TreeSummarizedExperiment objects into phyloseq with respect to the shared components that are supported by both formats (i.e. taxonomic abundance table, sample metadata, taxonomic table, phylogenetic tree, sequence information). This is useful for instance when additional methods are available for phyloseq.\n\n# convert TSE to phyloseq\nGlobalPatterns_phyloseq2 &lt;- makePhyloseqFromTreeSummarizedExperiment(GlobalPatterns_TSE) \nGlobalPatterns_phyloseq2\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\nsample_data() Sample Data:       [ 26 samples by 7 sample variables ]\ntax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n\n\nConversion is possible between other data formats. Interested readers can refer to the following functions: * makeTreeSummarizedExperimentFromDADA2 * makeSummarizedExperimentFromBiom * loadFromMetaphlan * readQZA"
  },
  {
    "objectID": "10_manipulation.html",
    "href": "10_manipulation.html",
    "title": "(PART) Focus Topics",
    "section": "",
    "text": "Data Manipulation"
  },
  {
    "objectID": "10_manipulation.html#tidying-and-subsetting",
    "href": "10_manipulation.html#tidying-and-subsetting",
    "title": "(PART) Focus Topics",
    "section": "Tidying and subsetting",
    "text": "Tidying and subsetting\n\nTidy data\nFor several custom analysis and visualization packages, such as those from tidyverse, the SE data can be converted to a long data.frame format with meltAssay.\n\nlibrary(mia)\ndata(GlobalPatterns, package=\"mia\")\ntse &lt;- GlobalPatterns\ntse &lt;- transformAssay(tse, MARGIN = \"samples\", method=\"relabundance\")\nmolten_tse &lt;- mia::meltAssay(tse,\n                        add_row_data = TRUE,\n                        add_col_data = TRUE,\n                        assay.type = \"relabundance\")\nmolten_tse\n\n# A tibble: 499,616 × 17\n   FeatureID SampleID relabundance Kingdom Phylum       Class Order Family Genus\n   &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n 1 549322    CL3                 0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 2 549322    CC1                 0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 3 549322    SV1                 0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 4 549322    M31Fcsw             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 5 549322    M11Fcsw             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 6 549322    M31Plmr             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 7 549322    M11Plmr             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 8 549322    F21Plmr             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n 9 549322    M31Tong             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n10 549322    M11Tong             0 Archaea Crenarchaeo… Ther… &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; \n# ℹ 499,606 more rows\n# ℹ 8 more variables: Species &lt;chr&gt;, X.SampleID &lt;fct&gt;, Primer &lt;fct&gt;,\n#   Final_Barcode &lt;fct&gt;, Barcode_truncated_plus_T &lt;fct&gt;,\n#   Barcode_full_length &lt;fct&gt;, SampleType &lt;fct&gt;, Description &lt;fct&gt;\n\n\n\n\nSubsetting\nSubsetting data helps to draw the focus of analysis on particular sets of samples and / or features. When dealing with large datasets, the subset of interest can be extracted and investigated separately. This might improve performance and reduce the computational load.\nLoad:\n\nmia\ndplyr\nknitr\ndata GlobalPatterns\n\nLet us store GlobalPatterns into tse and check its original number of features (rows) and samples (columns). Note: when subsetting by sample, expect the number of columns to decrease; when subsetting by feature, expect the number of rows to decrease.\n\n# Store data into se and check dimensions\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns\n# Show dimensions (features x samples)\ndim(tse) \n\n[1] 19216    26\n\n\n\nSubset by sample (column-wise)\nFor the sake of demonstration, here we will extract a subset containing only the samples of human origin (feces, skin or tongue), stored as SampleType within colData(tse) and also in tse.\nFirst, we would like to see all the possible values that SampleType can take on and how frequent those are:\n\n# Inspect possible values for SampleType\nunique(tse$SampleType)\n\n[1] Soil               Feces              Skin               Tongue            \n[5] Freshwater         Freshwater (creek) Ocean              Sediment (estuary)\n[9] Mock              \n9 Levels: Feces Freshwater Freshwater (creek) Mock ... Tongue\n\n\n\n# Show the frequency of each value\ntse$SampleType %&gt;% table()\n\n\n\n\n\n\n\n.\nFreq\n\n\n\n\nFeces\n4\n\n\nFreshwater\n2\n\n\nFreshwater (creek)\n3\n\n\nMock\n3\n\n\nOcean\n3\n\n\nSediment (estuary)\n3\n\n\nSkin\n3\n\n\nSoil\n3\n\n\nTongue\n2\n\n\n\n\n\n\n\nNote: after subsetting, expect the number of columns to equal the sum of the frequencies of the samples that you are interested in. For instance, ncols = Feces + Skin + Tongue = 4 + 3 + 2 = 9.\nNext, we logical index across the columns of tse (make sure to leave the first index empty to select all rows) and filter for the samples of human origin. For this, we use the information on the samples from the meta data colData(tse).\n\n# Subset by sample\ntse_subset_by_sample &lt;- tse[ , tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\n# Show dimensions\ndim(tse_subset_by_sample)\n\n[1] 19216     9\n\n\nAs a sanity check, the new object tse_subset_by_sample should have the original number of features (rows) and a number of samples (columns) equal to the sum of the samples of interest (in this case 9).\nSeveral characteristics can be used to subset by sample:\n\norigin\nsampling time\nsequencing method\nDNA / RNA barcode\ncohort\n\n\n\nSubset by feature (row-wise)\nSimilarly, here we will extract a subset containing only the features that belong to the phyla Actinobacteria and Chlamydiae, stored as Phylum within rowData(tse). However, subsetting by feature implies a few more obstacles, such as the presence of NA elements and the possible need for agglomeration.\nAs previously, we would first like to see all the possible values that Phylum can take on and how frequent those are:\n\n# Inspect possible values for phylum\nunique(rowData(tse)$Phylum)\n\n [1] \"Crenarchaeota\"    \"Euryarchaeota\"    \"Actinobacteria\"   \"Spirochaetes\"    \n [5] \"MVP-15\"           \"Proteobacteria\"   \"SBR1093\"          \"Fusobacteria\"    \n [9] \"Tenericutes\"      \"ZB3\"              \"Cyanobacteria\"    \"GOUTA4\"          \n[13] \"TG3\"              \"Chlorobi\"         \"Bacteroidetes\"    \"Caldithrix\"      \n[17] \"KSB1\"             \"SAR406\"           \"LCP-89\"           \"Thermi\"          \n[21] \"Gemmatimonadetes\" \"Fibrobacteres\"    \"GN06\"             \"AC1\"             \n[25] \"TM6\"              \"OP8\"              \"Elusimicrobia\"    \"NC10\"            \n[29] \"SPAM\"             NA                 \"Acidobacteria\"    \"CCM11b\"          \n[33] \"Nitrospirae\"      \"NKB19\"            \"BRC1\"             \"Hyd24-12\"        \n[37] \"WS3\"              \"PAUC34f\"          \"GN04\"             \"GN12\"            \n[41] \"Verrucomicrobia\"  \"Lentisphaerae\"    \"LD1\"              \"Chlamydiae\"      \n[45] \"OP3\"              \"Planctomycetes\"   \"Firmicutes\"       \"OP9\"             \n[49] \"WPS-2\"            \"Armatimonadetes\"  \"SC3\"              \"TM7\"             \n[53] \"GN02\"             \"SM2F11\"           \"ABY1_OD1\"         \"ZB2\"             \n[57] \"OP11\"             \"Chloroflexi\"      \"SC4\"              \"WS1\"             \n[61] \"GAL15\"            \"AD3\"              \"WS2\"              \"Caldiserica\"     \n[65] \"Thermotogae\"      \"Synergistetes\"    \"SR1\"             \n\n\n\n# Show the frequency of each value\nrowData(tse)$Phylum %&gt;% table()\n\n\n\n\n\n\n\n.\nFreq\n\n\n\n\nABY1_OD1\n7\n\n\nAC1\n1\n\n\nAcidobacteria\n1021\n\n\nActinobacteria\n1631\n\n\nAD3\n9\n\n\nArmatimonadetes\n61\n\n\nBacteroidetes\n2382\n\n\nBRC1\n13\n\n\nCaldiserica\n3\n\n\nCaldithrix\n10\n\n\nCCM11b\n2\n\n\nChlamydiae\n21\n\n\nChlorobi\n64\n\n\nChloroflexi\n437\n\n\nCrenarchaeota\n106\n\n\nCyanobacteria\n393\n\n\nElusimicrobia\n31\n\n\nEuryarchaeota\n102\n\n\nFibrobacteres\n7\n\n\nFirmicutes\n4356\n\n\nFusobacteria\n37\n\n\nGAL15\n2\n\n\nGemmatimonadetes\n191\n\n\nGN02\n8\n\n\nGN04\n7\n\n\nGN06\n2\n\n\nGN12\n1\n\n\nGOUTA4\n11\n\n\nHyd24-12\n4\n\n\nKSB1\n6\n\n\nLCP-89\n2\n\n\nLD1\n2\n\n\nLentisphaerae\n21\n\n\nMVP-15\n5\n\n\nNC10\n9\n\n\nNitrospirae\n74\n\n\nNKB19\n16\n\n\nOP11\n6\n\n\nOP3\n30\n\n\nOP8\n27\n\n\nOP9\n4\n\n\nPAUC34f\n3\n\n\nPlanctomycetes\n638\n\n\nProteobacteria\n6416\n\n\nSAR406\n21\n\n\nSBR1093\n9\n\n\nSC3\n8\n\n\nSC4\n8\n\n\nSM2F11\n5\n\n\nSPAM\n22\n\n\nSpirochaetes\n124\n\n\nSR1\n5\n\n\nSynergistetes\n7\n\n\nTenericutes\n143\n\n\nTG3\n5\n\n\nThermi\n46\n\n\nThermotogae\n1\n\n\nTM6\n27\n\n\nTM7\n32\n\n\nVerrucomicrobia\n470\n\n\nWPS-2\n20\n\n\nWS1\n5\n\n\nWS2\n2\n\n\nWS3\n70\n\n\nZB2\n2\n\n\nZB3\n2\n\n\n\n\n\n\n\nNote: after subsetting, expect the number of columns to equal the sum of the frequencies of the feature(s) that you are interested in. For instance, nrows = Actinobacteria + Chlamydiae = 1631 + 21 =   1652.\nDepending on your research question, you might or might not need to agglomerate the data in the first place: if you want to find the abundance of each and every feature that belongs to Actinobacteria and Chlamydiae, agglomeration is not needed; if you want to find the total abundance of all features that belong to Actinobacteria or Chlamydiae, agglomeration is recommended.\n\nNon-agglomerated data\nNext, we logical index across the rows of tse (make sure to leave the second index empty to select all columns) and filter for the features that fall in either Actinobacteria or Chlamydiae group. For this, we use the information on the samples from the metadata rowData(tse).\nThe first term with the %in% operator includes all the features of interest, whereas the second term after the AND operator & filters out all features that have an NA in place of the phylum variable.\n\n# Subset by feature\ntse_subset_by_feature &lt;- tse[rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse)$Phylum), ]\n\n# Show dimensions\ndim(tse_subset_by_feature)\n\n[1] 1652   26\n\n\nAs a sanity check, the new object, tse_subset_by_feature, should have the original number of samples (columns) and a number of features (rows) equal to the sum of the features of interest (in this case, 1652).\n\n\nAgglomerated data\nWhen total abundances of certain phyla are of relevance, the data is initially agglomerated by Phylum. Then, similar steps as in the case of non-agglomerated data are followed.\n\n# Agglomerate by phylum\ntse_phylum &lt;- tse %&gt;% mergeFeaturesByRank(rank = \"Phylum\")\n\n# Subset by feature and remove NAs\ntse_phylum_subset_by_feature &lt;- tse_phylum[rowData(tse_phylum)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse_phylum)$Phylum), ]\n\n# Show dimensions\ndim(tse_phylum_subset_by_feature)\n\n[1]  2 26\n\n\nNote: as data was agglomerated, the number of rows should equal the number of phyla used to index (in this case, just 2).\nAlternatively:\n\n# Store features of interest into phyla\nphyla &lt;- c(\"Phylum:Actinobacteria\", \"Phylum:Chlamydiae\")\n# subset by feature\ntse_phylum_subset_by_feature &lt;- tse_phylum[phyla, ]\n# Show dimensions\ndim(tse_subset_by_feature)\n\n[1] 1652   26\n\n\nThe code above returns the non-agglomerated version of the data.\nFewer characteristics can be used to subset by feature:\n\nTaxonomic rank\nMeta-taxonomic group\n\nFor subsetting by kingdom, agglomeration does not apply, whereas for the other ranks it can be applied if necessary.\n\n\n\nSubset by sample and feature\nFinally, we can subset data by sample and feature at once. The resulting subset contains all the samples of human origin and all the features of phyla Actinobacteria or Chlamydiae.\n\n# Subset by sample and feature and remove NAs\ntse_subset_by_sample_feature &lt;- tse[rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") & !is.na(rowData(tse)$Phylum), tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\n# Show dimensions\ndim(tse_subset_by_sample_feature)\n\n[1] 1652    9\n\n\nNote: the dimensions of tse_subset_by_sample_feature agree with those of the previous subsets (9 columns filtered by sample and 1652 rows filtered by feature).\nIf a study was to consider and quantify the presence of Actinobacteria as well as Chlamydiae in different sites of the human body, tse_subset_by_sample_feature might be a suitable subset to start with.\n\n\nRemove empty columns and rows\nSometimes data might contain, e.g., features that are not present in any of the samples. This can occur, for example, after the data subsetting. In certain analyses, we might want to remove those instances.\n\n# Agglomerate data at Genus level \ntse_genus &lt;- mergeFeaturesByRank(tse, rank = \"Genus\")\n# List bacteria that we want to include\ngenera &lt;- c(\"Class:Thermoprotei\", \"Genus:Sulfolobus\", \"Genus:Sediminicola\")\n# Subset data\ntse_genus_sub &lt;- tse_genus[genera, ]\n\ntse_genus_sub\n\nclass: TreeSummarizedExperiment \ndim: 3 26 \nmetadata(1): agglomerated_by_rank\nassays(1): counts\nrownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(26): CL3 CC1 ... Even2 Even3\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (3 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\n# List total counts of each sample\ncolSums(assay(tse_genus_sub, \"counts\"))\n\n     CL3      CC1      SV1  M31Fcsw  M11Fcsw  M31Plmr  M11Plmr  F21Plmr \n       1        0        0        1        1        0        4        1 \n M31Tong  M11Tong LMEpi24M SLEpi20M   AQC1cm   AQC4cm   AQC7cm      NP2 \n       7        3        0        2       64      105      136      222 \n     NP3      NP5  TRRsed1  TRRsed2  TRRsed3     TS28     TS29    Even1 \n    6433     1154        2        2        2        0        0        0 \n   Even2    Even3 \n       2        0 \n\n\nNow we can see that certain samples do not include any bacteria. We can remove those.\n\n# Remove samples that do not contain any bacteria\ntse_genus_sub &lt;- tse_genus_sub[ , colSums(assay(tse_genus_sub, \"counts\")) != 0 ]\ntse_genus_sub\n\nclass: TreeSummarizedExperiment \ndim: 3 18 \nmetadata(1): agglomerated_by_rank\nassays(1): counts\nrownames(3): Class:Thermoprotei Genus:Sulfolobus Genus:Sediminicola\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(18): CL3 M31Fcsw ... TRRsed3 Even2\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (3 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\nThe same action can also be applied to the features.\n\n# Take only those samples that are collected from feces, skin, or tongue\ntse_genus_sub &lt;- tse_genus[ , tse_genus$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\ntse_genus_sub\n\nclass: TreeSummarizedExperiment \ndim: 1516 9 \nmetadata(1): agglomerated_by_rank\nassays(1): counts\nrownames(1516): Class:Thermoprotei Genus:Sulfolobus ...\n  Genus:Coprothermobacter Phylum:SR1\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(9): M31Fcsw M11Fcsw ... TS28 TS29\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (1516 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\n# What is the number of bacteria that are not present?\nsum(rowSums(assay(tse_genus_sub, \"counts\")) == 0)\n\n[1] 435\n\n\nWe can see that there are bacteria that are not present in these samples we chose. We can remove those bacteria from the data.\n\n# Take only those bacteria that are present\ntse_genus_sub &lt;- tse_genus_sub[rowSums(assay(tse_genus_sub, \"counts\")) &gt; 0, ]\n\ntse_genus_sub\n\nclass: TreeSummarizedExperiment \ndim: 1081 9 \nmetadata(1): agglomerated_by_rank\nassays(1): counts\nrownames(1081): Genus:Sulfolobus Order:NRP-J ...\n  Genus:Coprothermobacter Phylum:SR1\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(9): M31Fcsw M11Fcsw ... TS28 TS29\ncolData names(7): X.SampleID Primer ... SampleType Description\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (1081 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\n\n\nSplitting\nYou can split the data based on variables by using the functions splitByRanks and splitOn.\nsplitByRanks splits the data based on taxonomic ranks. Since the elements of the output list share columns, they can be stored into altExp.\n\naltExps(tse) &lt;- splitByRanks(tse)\naltExps(tse)\n\nList of length 7\nnames(7): Kingdom Phylum Class Order Family Genus Species\n\n\nIf you want to split the data based on another variable than taxonomic rank, use splitOn. It works for row-wise and column-wise splitting.\n\nsplitOn(tse, \"SampleType\")\n\nList of length 9\nnames(9): Soil Feces Skin Tongue ... Ocean Sediment (estuary) Mock"
  },
  {
    "objectID": "10_manipulation.html#add-or-modify-data",
    "href": "10_manipulation.html#add-or-modify-data",
    "title": "(PART) Focus Topics",
    "section": "Add or modify data",
    "text": "Add or modify data\nThe information contained by the colData of a TreeSE can be modified by accessing the desired variables.\n\n# modify the Description entries\ncolData(tse)$Description &lt;- paste(colData(tse)$Description, \"modified description\")\n\n# view modified variable\nhead(tse$Description)\n\n[1] \"Calhoun South Carolina Pine soil, pH 4.9 modified description\"  \n[2] \"Cedar Creek Minnesota, grassland, pH 6.1 modified description\"  \n[3] \"Sevilleta new Mexico, desert scrub, pH 8.3 modified description\"\n[4] \"M3, Day 1, fecal swab, whole body study modified description\"   \n[5] \"M1, Day 1, fecal swab, whole body study  modified description\"  \n[6] \"M3, Day 1, right palm, whole body study modified description\"   \n\n\nNew information can also be added to the experiment by creating a new variable.\n\n# simulate new data\nnew_data &lt;- runif(ncol(tse))\n\n# store new data as new variable in colData\ncolData(tse)$NewVariable &lt;- new_data\n\n# view new variable\nhead(tse$NewVariable)\n\n[1] 0.05457 0.97363 0.44659 0.14481 0.87976 0.32265"
  },
  {
    "objectID": "10_manipulation.html#merge-data",
    "href": "10_manipulation.html#merge-data",
    "title": "(PART) Focus Topics",
    "section": "Merge data",
    "text": "Merge data\nmia package has mergeSEs function that merges multiple SummarizedExperiment objects. For example, it is possible to combine multiple TreeSE objects which each includes one sample.\nmergeSEs works like dplyr joining functions. In fact, there are available dplyr-like aliases of mergeSEs, such as full_join.\n\n# Take subsets for demonstration purposes\ntse1 &lt;- tse[, 1]\ntse2 &lt;- tse[, 2]\ntse3 &lt;- tse[, 3]\ntse4 &lt;- tse[1:100, 4]\n\n\n# With inner join, we want to include all shared rows. When using mergeSEs function\n# all samples are always preserved.\ntse &lt;- mergeSEs(list(tse1, tse2, tse3, tse4), join = \"inner\")\ntse\n\nclass: TreeSummarizedExperiment \ndim: 100 4 \nmetadata(0):\nassays(1): counts\nrownames(100): 239672 243675 ... 549322 951\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(4): CC1 CL3 M31Fcsw SV1\ncolData names(8): X.SampleID Primer ... Description NewVariable\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (100 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\n# Left join preserves all rows of the 1st object\ntse &lt;- mia::left_join(tse1, tse4, missing_values = 0)\ntse\n\nclass: TreeSummarizedExperiment \ndim: 19216 2 \nmetadata(0):\nassays(1): counts\nrownames(19216): 239672 243675 ... 239967 254851\nrowData names(7): Kingdom Phylum ... Genus Species\ncolnames(2): CL3 M31Fcsw\ncolData names(8): X.SampleID Primer ... Description NewVariable\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\nrowLinks: a LinkDataFrame (19216 rows)\nrowTree: 1 phylo tree(s) (19216 leaves)\ncolLinks: NULL\ncolTree: NULL\n\n\n\nAdditional functions\n\nmapTaxonomy\nmergeFeatures/mergeSamples"
  },
  {
    "objectID": "12_quality_control.html#abundance",
    "href": "12_quality_control.html#abundance",
    "title": "4  Exploration and Quality Control",
    "section": "4.1 Abundance",
    "text": "4.1 Abundance\nAbundance visualization is an important data exploration approach. miaViz offers the function plotAbundanceDensity to plot the most abundant taxa with several options.\nNext, a few demonstrations are shown, using the [@Lahti2014] dataset. A Jitter plot based on relative abundance data, similar to the one presented at [@Salosensaari2021] supplementary figure 1, could be visualized as follows:\n\n# Load example data\nlibrary(miaTime)\nlibrary(miaViz)\ndata(hitchip1006)\ntse &lt;- hitchip1006\n\n# Add relative abundances\ntse &lt;- transformAssay(tse, MARGIN = \"samples\", method = \"relabundance\")\n\n# Use argument names\n# assay.type / assay.type / assay.type\n# depending on the mia package version\nplotAbundanceDensity(tse, layout = \"jitter\", assay.type = \"relabundance\",\n                     n = 40, point_size=1, point_shape=19, point_alpha=0.1) + \n                     scale_x_log10(label=scales::percent)\n\n\n\n\nThe relative abundance values for the top-5 taxonomic features can be visualized as a density plot over a log scaled axis, with “nationality” indicated by colors:\n\nplotAbundanceDensity(tse, layout = \"density\", assay.type = \"relabundance\",\n                     n = 5, colour_by=\"nationality\", point_alpha=1/10) +\n    scale_x_log10()"
  },
  {
    "objectID": "12_quality_control.html#prevalence",
    "href": "12_quality_control.html#prevalence",
    "title": "4  Exploration and Quality Control",
    "section": "4.2 Prevalence",
    "text": "4.2 Prevalence\nPrevalence quantifies the frequency of samples where certain microbes were detected (above a given detection threshold). The prevalence can be given as sample size (N) or percentage (unit interval).\nInvestigating prevalence allows you either to focus on changes which pertain to the majority of the samples, or identify rare microbes, which may be conditionally abundant in a small number of samples.\nThe population prevalence (frequency) at a 1% relative abundance threshold (detection = 1/100 and as_relative = TRUE), can look like this.\n\nhead(getPrevalence(tse, detection = 1/100, sort = TRUE, as_relative = TRUE))\n\nFaecalibacterium prausnitzii et rel.           Ruminococcus obeum et rel. \n                              0.9522                               0.9140 \n  Oscillospira guillermondii et rel.        Clostridium symbiosum et rel. \n                              0.8801                               0.8714 \n    Subdoligranulum variable at rel.     Clostridium orbiscindens et rel. \n                              0.8358                               0.8315 \n\n\nThe function arguments detection and as_relative can also be used to access, how many samples do pass a threshold for raw counts. Here, the population prevalence (frequency) at the absolute abundance threshold (as_relative = FALSE) at read count 1 (detection = 1) is accessed.\n\nhead(getPrevalence(tse, detection = 1, sort = TRUE, assay.type = \"counts\",\n                   as_relative = FALSE))\n\n           Uncultured Mollicutes      Uncultured Clostridiales II \n                               1                                1 \n      Uncultured Clostridiales I               Tannerella et rel. \n                               1                                1 \n  Sutterella wadsworthia et rel. Subdoligranulum variable at rel. \n                               1                                1 \n\n\nIf the output should be used for subsetting or storing the data in the rowData, set sort = FALSE.\n\n4.2.1 Prevalence analysis\nTo investigate microbiome prevalence at a selected taxonomic level, two approaches are available.\nFirst the data can be agglomerated to the taxonomic level and getPrevalence applied on the resulting object.\n\n# Agglomerate taxa abundances to Phylum level, and add the new table\n# to the altExp slot\naltExp(tse,\"Phylum\") &lt;- mergeFeaturesByRank(tse, \"Phylum\")\n# Check prevalence for the Phylum abundance table from the altExp slot\nhead(getPrevalence(altExp(tse,\"Phylum\"), detection = 1/100, sort = TRUE,\n                   assay.type = \"counts\", as_relative = TRUE))\n\n     Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria Verrucomicrobia \n      1.0000000       0.9852302       0.4821894       0.2988705       0.1277150 \n  Cyanobacteria \n      0.0008688 \n\n\nAlternatively, the rank argument could be set to perform the agglomeration on the fly.\n\nhead(getPrevalence(tse, rank = \"Phylum\", detection = 1/100, sort = TRUE,\n                   assay.type = \"counts\", as_relative = TRUE))\n\n     Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria Verrucomicrobia \n      1.0000000       0.9852302       0.4821894       0.2988705       0.1277150 \n  Cyanobacteria \n      0.0008688 \n\n\nNote that, by default, na.rm = TRUE is used for agglomeration in getPrevalence, whereas the default for mergeFeaturesByRank is FALSE to prevent accidental data loss.\nIf you only need the names of the prevalent taxa, getPrevalentFeatures is available. This returns the taxa that exceed the given prevalence and detection thresholds.\n\ngetPrevalentFeatures(tse, detection = 0, prevalence = 50/100)\nprev &lt;- getPrevalentFeatures(tse, detection = 0, prevalence = 50/100,\n                         rank = \"Phylum\", sort = TRUE)\nprev\n\nNote that the detection and prevalence thresholds are not the same, since detection can be applied to relative counts or absolute counts depending on whether as_relative is set TRUE or FALSE\nThe function ‘getPrevalentAbundance’ can be used to check the total relative abundance of the prevalent taxa (between 0 and 1).\n\n\n4.2.2 Rare taxa\nRelated functions are available for the analysis of rare taxa (rareMembers; rareAbundance; lowAbundance, getRareFeatures, subsetByRareFeatures).\n\n\n4.2.3 Plotting prevalence\nTo plot the prevalence, add the prevalence of each taxon to rowData. Here, we are analysing the Phylum level abundances, which are stored in the altExp slot.\n\nrowData(altExp(tse,\"Phylum\"))$prevalence &lt;- \n    getPrevalence(altExp(tse,\"Phylum\"), detection = 1/100, sort = FALSE,\n                  assay.type = \"counts\", as_relative = TRUE)\n\nThe prevalences can then be plotted using the plotting functions from the scater package.\n\nlibrary(scater)\nplotRowData(altExp(tse,\"Phylum\"), \"prevalence\", colour_by = \"Phylum\")\n\n\n\n\nThe prevalence can also be visualized on the taxonomic tree with the miaViz package.\n\naltExps(tse) &lt;- splitByRanks(tse)\naltExps(tse) &lt;-\n   lapply(altExps(tse),\n          function(y){\n              rowData(y)$prevalence &lt;- \n                  getPrevalence(y, detection = 1/100, sort = FALSE,\n                                assay.type = \"counts\", as_relative = TRUE)\n              y\n          })\ntop_phyla &lt;- getTopFeatures(altExp(tse,\"Phylum\"),\n                        method=\"prevalence\",\n                        top=5L,\n                        assay.type=\"counts\")\ntop_phyla_mean &lt;- getTopFeatures(altExp(tse,\"Phylum\"),\n                             method=\"mean\",\n                             top=5L,\n                             assay.type=\"counts\")\nx &lt;- unsplitByRanks(tse, ranks = taxonomyRanks(tse)[1:6])\nx &lt;- addTaxonomyTree(x)\n\nAfter some preparation, the data is assembled and can be plotted with plotRowTree.\n\nlibrary(miaViz)\nplotRowTree(x[rowData(x)$Phylum %in% top_phyla,],\n            edge_colour_by = \"Phylum\",\n            tip_colour_by = \"prevalence\",\n            node_colour_by = \"prevalence\")\n\n\n\n\nPrevalence of top phyla as judged by prevalence\n\n\n\n\n\nplotRowTree(x[rowData(x)$Phylum %in% top_phyla_mean,],\n            edge_colour_by = \"Phylum\",\n            tip_colour_by = \"prevalence\",\n            node_colour_by = \"prevalence\")\n\n\n\n\nPrevalence of top phyla as judged by mean abundance"
  },
  {
    "objectID": "12_quality_control.html#qc",
    "href": "12_quality_control.html#qc",
    "title": "4  Exploration and Quality Control",
    "section": "4.3 Quality control",
    "text": "4.3 Quality control\nNext, let us load the GlobalPatterns dataset to illustrate standard microbiome data summaries.\n\nlibrary(mia)\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns \n\n\n4.3.1 Top taxa\nThe getTopFeatures identifies top taxa in the data.\n\n# Pick the top taxa\ntop_features &lt;- getTopFeatures(tse, method=\"median\", top=10)\n\n# Check the information for these\nrowData(tse)[top_features, taxonomyRanks(tse)]\n\nDataFrame with 10 rows and 7 columns\n           Kingdom         Phylum               Class             Order\n       &lt;character&gt;    &lt;character&gt;         &lt;character&gt;       &lt;character&gt;\n549656    Bacteria  Cyanobacteria         Chloroplast     Stramenopiles\n331820    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n317182    Bacteria  Cyanobacteria         Chloroplast     Stramenopiles\n94166     Bacteria Proteobacteria Gammaproteobacteria    Pasteurellales\n279599    Bacteria  Cyanobacteria    Nostocophycideae        Nostocales\n158660    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n329744    Bacteria Actinobacteria      Actinobacteria   Actinomycetales\n326977    Bacteria Actinobacteria      Actinobacteria Bifidobacteriales\n248140    Bacteria  Bacteroidetes         Bacteroidia     Bacteroidales\n550960    Bacteria Proteobacteria Gammaproteobacteria Enterobacteriales\n                   Family           Genus                Species\n              &lt;character&gt;     &lt;character&gt;            &lt;character&gt;\n549656                 NA              NA                     NA\n331820     Bacteroidaceae     Bacteroides                     NA\n317182                 NA              NA                     NA\n94166     Pasteurellaceae     Haemophilus Haemophilusparainflu..\n279599        Nostocaceae  Dolichospermum                     NA\n158660     Bacteroidaceae     Bacteroides                     NA\n329744             ACK-M1              NA                     NA\n326977 Bifidobacteriaceae Bifidobacterium Bifidobacteriumadole..\n248140     Bacteroidaceae     Bacteroides      Bacteroidescaccae\n550960 Enterobacteriaceae     Providencia                     NA\n\n\n\n\n4.3.2 Library size / read count\nThe total counts/sample can be calculated using perCellQCMetrics/addPerCellQC from the scater package. The former one just calculates the values, whereas the latter one directly adds them to colData.\n\nlibrary(scater)\nperCellQCMetrics(tse)\n\nDataFrame with 26 rows and 3 columns\n              sum  detected     total\n        &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\nCL3        864077      6964    864077\nCC1       1135457      7679   1135457\nSV1        697509      5729    697509\nM31Fcsw   1543451      2667   1543451\nM11Fcsw   2076476      2574   2076476\n...           ...       ...       ...\nTS28       937466      2679    937466\nTS29      1211071      2629   1211071\nEven1     1216137      4213   1216137\nEven2      971073      3130    971073\nEven3     1078241      2776   1078241\n\ntse &lt;- addPerCellQC(tse)\ncolData(tse)\n\nDataFrame with 26 rows and 10 columns\n        X.SampleID   Primer Final_Barcode Barcode_truncated_plus_T\n          &lt;factor&gt; &lt;factor&gt;      &lt;factor&gt;                 &lt;factor&gt;\nCL3        CL3      ILBC_01        AACGCA                   TGCGTT\nCC1        CC1      ILBC_02        AACTCG                   CGAGTT\nSV1        SV1      ILBC_03        AACTGT                   ACAGTT\nM31Fcsw    M31Fcsw  ILBC_04        AAGAGA                   TCTCTT\nM11Fcsw    M11Fcsw  ILBC_05        AAGCTG                   CAGCTT\n...            ...      ...           ...                      ...\nTS28         TS28   ILBC_25        ACCAGA                   TCTGGT\nTS29         TS29   ILBC_26        ACCAGC                   GCTGGT\nEven1        Even1  ILBC_27        ACCGCA                   TGCGGT\nEven2        Even2  ILBC_28        ACCTCG                   CGAGGT\nEven3        Even3  ILBC_29        ACCTGT                   ACAGGT\n        Barcode_full_length SampleType\n                   &lt;factor&gt;   &lt;factor&gt;\nCL3             CTAGCGTGCGT      Soil \nCC1             CATCGACGAGT      Soil \nSV1             GTACGCACAGT      Soil \nM31Fcsw         TCGACATCTCT      Feces\nM11Fcsw         CGACTGCAGCT      Feces\n...                     ...        ...\nTS28            GCATCGTCTGG      Feces\nTS29            CTAGTCGCTGG      Feces\nEven1           TGACTCTGCGG      Mock \nEven2           TCTGATCGAGG      Mock \nEven3           AGAGAGACAGG      Mock \n                                       Description       sum  detected\n                                          &lt;factor&gt; &lt;numeric&gt; &lt;numeric&gt;\nCL3     Calhoun South Carolina Pine soil, pH 4.9      864077      6964\nCC1     Cedar Creek Minnesota, grassland, pH 6.1     1135457      7679\nSV1     Sevilleta new Mexico, desert scrub, pH 8.3    697509      5729\nM31Fcsw M3, Day 1, fecal swab, whole body study      1543451      2667\nM11Fcsw M1, Day 1, fecal swab, whole body study      2076476      2574\n...                                            ...       ...       ...\nTS28                                       Twin #1    937466      2679\nTS29                                       Twin #2   1211071      2629\nEven1                                      Even1     1216137      4213\nEven2                                      Even2      971073      3130\nEven3                                      Even3     1078241      2776\n            total\n        &lt;numeric&gt;\nCL3        864077\nCC1       1135457\nSV1        697509\nM31Fcsw   1543451\nM11Fcsw   2076476\n...           ...\nTS28       937466\nTS29      1211071\nEven1     1216137\nEven2      971073\nEven3     1078241\n\n\nThe distribution of calculated library sizes can be visualized as a histogram (left), or by sorting the samples by library size (right).\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot(as.data.frame(colData(tse))) +\n        geom_histogram(aes(x = sum), color = \"black\", fill = \"gray\", bins = 30) +\n        labs(x = \"Library size\", y = \"Frequency (n)\") + \n        # scale_x_log10(breaks = scales::trans_breaks(\"log10\", function(x) 10^x), \n        # labels = scales::trans_format(\"log10\", scales::math_format(10^.x))) +\n        theme_bw() +\n        theme(panel.grid.major = element_blank(), # Removes the grid\n          panel.grid.minor = element_blank(),\n          panel.border = element_blank(),\n          panel.background = element_blank(),\n          axis.line = element_line(colour = \"black\")) # Adds y-axis\n\nlibrary(dplyr)\ndf &lt;- as.data.frame(colData(tse)) %&gt;%\n        arrange(sum) %&gt;%\n        mutate(index = 1:n())\np2 &lt;- ggplot(df, aes(y = index, x = sum/1e6)) +\n        geom_point() +  \n        labs(x = \"Library size (million reads)\", y = \"Sample index\") +  \n        theme_bw() +\n        theme(panel.grid.major = element_blank(), # Removes the grid\n          panel.grid.minor = element_blank(),\n          panel.border = element_blank(),\n          panel.background = element_blank(),\n          axis.line = element_line(colour = \"black\")) # Adds y-axis\n\nlibrary(patchwork)\np1 + p2\n\n\n\n\nLibrary size distribution.\n\n\n\n\nLibrary sizes other variables from colData can be visualized by using specified function called plotColData.\n\nlibrary(ggplot2)\n# Sort samples by read count, order the factor levels, and store back to tse as DataFrame\n# TODO: plotColData could include an option for sorting samples based on colData variables\ncolData(tse) &lt;- as.data.frame(colData(tse)) %&gt;%\n                 arrange(X.SampleID) %&gt;%\n             mutate(X.SampleID = factor(X.SampleID, levels=X.SampleID)) %&gt;%\n         DataFrame\nplotColData(tse,\"sum\",\"X.SampleID\", colour_by = \"SampleType\") + \n    theme(axis.text.x = element_text(angle = 45, hjust=1)) +\n    labs(y = \"Library size (N)\", x = \"Sample ID\")       \n\n\n\n\nLibrary sizes per sample.\n\n\n\n\n\nplotColData(tse,\"sum\",\"SampleType\", colour_by = \"SampleType\") + \n    theme(axis.text.x = element_text(angle = 45, hjust=1))\n\n\n\n\nLibrary sizes per sample type.\n\n\n\n\nIn addition, data can be rarefied with subsampleCounts, which normalises the samples to an equal number of reads. However, this practice has been discouraged for the analysis of differentially abundant microorganisms (see [@mcmurdie2014waste]).\n\n\n4.3.3 Contaminant sequences\nSamples might be contaminated with exogenous sequences. The impact of each contaminant can be estimated based on their frequencies and concentrations across the samples.\nThe following decontam functions are based on the [@davis2018simple] and support such functionality:\n\nisContaminant, isNotContaminant\naddContaminantQC, addNotContaminantQC"
  },
  {
    "objectID": "14_alpha_diversity.html#estimation",
    "href": "14_alpha_diversity.html#estimation",
    "title": "5  Community Diversity",
    "section": "5.1 Estimation",
    "text": "5.1 Estimation\nAlpha diversity can be estimated with wrapper functions that interact with other packages implementing the calculation, such as vegan [@R_vegan].\n\n5.1.1 Richness\nRichness gives the number of features present within a community and can be calculated with estimateRichness. Each of the estimate diversity/richness/evenness/dominance functions adds the calculated measure(s) to the colData of the SummarizedExperiment under the given column name. Here, we calculate observed features as a measure of richness.\n\ntse &lt;- mia::estimateRichness(tse, \n                             assay.type = \"counts\", \n                             index = \"observed\", \n                             name=\"observed\")\n\nhead(tse$observed)\n\n    CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n   6964    7679    5729    2667    2574    3214 \n\n\nThis allows access to the values to be analyzed directly from the colData, for example by plotting them using plotColData from the scater package [@R_scater].\n\nlibrary(scater)\nplotColData(tse, \n            \"observed\", \n            \"SampleType\", \n            colour_by = \"Final_Barcode\") +\n    theme(axis.text.x = element_text(angle=45,hjust=1)) + \n  ylab(expression(Richness[Observed]))\n\n\n\n\nShannon diversity estimates plotted grouped by sample type with colour-labeled barcode.\n\n\n\n\n\n\n5.1.2 Diversity\nThe main function, estimateDiversity, calculates the selected diversity index based on the selected assay data.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"shannon\", \n                              name = \"shannon\")\nhead(tse$shannon)\n\n    CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n  6.577   6.777   6.498   3.828   3.288   4.289 \n\n\nAlpha diversities can be visualized with boxplot. Here, Shannon index is compared between different sample type groups. Individual data points are visualized by plotting them as points with geom_jitter.\ngeom_signif is used to test whether these differences are statistically significant. It adds p-values to plot.\n\nlibrary(ggsignif)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(ggsignif)\n\n# Subsets the data. Takes only those samples that are from feces, skin, or tongue,\n# and creates data frame from the collected data\ndf &lt;- as.data.frame(colData(tse)[tse$SampleType %in% \n                 c(\"Feces\", \"Skin\", \"Tongue\"), ])\n\n# Changes old levels with new levels\ndf$SampleType &lt;- factor(df$SampleType)\n\n# For significance testing, all different combinations are determined\ncomb &lt;- split(t(combn(levels(df$SampleType), 2)), \n           seq(nrow(t(combn(levels(df$SampleType), 2)))))\n\nggplot(df, aes(x = SampleType, y = shannon)) +\n  # Outliers are removed, because otherwise each data point would be plotted twice; \n  # as an outlier of boxplot and as a point of dotplot.\n  geom_boxplot(outlier.shape = NA) + \n  geom_jitter(width = 0.2) + \n  geom_signif(comparisons = comb, map_signif_level = FALSE) +\n  theme(text = element_text(size = 10))\n\n\n\n\n\n\n5.1.3 Faith phylogenetic diversity\nThe Faith index is returned by the function estimateFaith.\n\ntse &lt;- mia::estimateFaith(tse,\n                          assay.type = \"counts\")\nhead(tse$faith)\n\n[1] 0 0 0 0 0 0\n\n\nNote: because tse is a TreeSummarizedExperiment object, its phylogenetic tree is used by default. However, the optional argument tree must be provided if tse does not contain one.\nBelow a visual comparison between shannon and faith indices is shown with a violin plot.\n\nplots &lt;- lapply(c(\"shannon\", \"faith\"),\n                plotColData,\n                object = tse, colour_by = \"SampleType\")\nplots[[1]] + plots[[2]] +\n  plot_layout(guides = \"collect\")\n\n\n\n\nAlternatively, the phylogenetic diversity can be calculated by mia::estimateDiversity. This is a faster re-implementation of\nthe widely used function in picante [@R_picante, @Kembel2010].\nLoad picante R package and get the phylo stored in rowTree.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"faith\", \n                              name = \"faith\")\n\n\n\n5.1.4 Evenness\nEvenness can be calculated with estimateEvenness.\n\ntse &lt;- estimateEvenness(tse, \n                        assay.type = \"counts\", \n                        index=\"simpson\")\nhead(tse$simpson)\n\n[1] 0.026871 0.027197 0.047049 0.005179 0.004304 0.005011\n\n\n\n\n5.1.5 Dominance\nDominance can be calculated with estimateDominance. Here, the Relative index is calculated which is the relative abundance of the most dominant species in the sample.\n\ntse &lt;- estimateDominance(tse, \n                         assay.type = \"counts\", \n                         index=\"relative\")\n\nhead(tse$relative)\n\n    CL3     CC1     SV1 M31Fcsw M11Fcsw M31Plmr \n0.03910 0.03226 0.01690 0.22981 0.21778 0.22329 \n\n\n\n\n5.1.6 Rarity\nmia package provides one rarity index called log-modulo skewness. It can be calculated with estimateDiversity.\n\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"log_modulo_skewness\")\n\nhead(tse$log_modulo_skewness)\n\n[1] 2.061 2.061 2.061 2.061 2.061 2.061\n\n\n\n\n5.1.7 Divergence\nDivergence can be evaluated with estimateDivergence. Reference and algorithm for the calculation of divergence can be specified as reference and FUN, respectively.\n\ntse &lt;- mia::estimateDivergence(tse,\n                               assay.type = \"counts\",\n                               reference = \"median\",\n                               FUN = vegan::vegdist)"
  },
  {
    "objectID": "14_alpha_diversity.html#visualization",
    "href": "14_alpha_diversity.html#visualization",
    "title": "5  Community Diversity",
    "section": "5.2 Visualization",
    "text": "5.2 Visualization\nA plot comparing all the diversity measures calculated above and stored in colData can then be constructed directly.\n\nplots &lt;- lapply(c(\"observed\", \"shannon\", \"simpson\", \"relative\", \"faith\", \"log_modulo_skewness\"),\n                plotColData,\n                object = tse,\n                x = \"SampleType\",\n                colour_by = \"SampleType\")\n\nplots &lt;- lapply(plots, \"+\", \n                theme(axis.text.x = element_blank(),\n                      axis.title.x = element_blank(),\n                      axis.ticks.x = element_blank()))\n\n((plots[[1]] | plots[[2]] | plots[[3]]) / \n(plots[[4]] | plots[[5]] | plots[[6]])) +\n  plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "20_beta_diversity.html#unsupervised-ordination",
    "href": "20_beta_diversity.html#unsupervised-ordination",
    "title": "6  Community Similarity",
    "section": "6.1 Unsupervised ordination",
    "text": "6.1 Unsupervised ordination\nUnsupervised ordination methods variation in the data without additional information on covariates or other supervision of the model. Among the different approaches, Multi-Dimensional Scaling (MDS) and non-metric MDS (NMDS) can be regarded as the standard. They are jointly referred to as PCoA. For this demonstration we will analyse beta diversity in GlobalPatterns, and observe the variation between stool samples and those with a different origin.\n\n# Load mia and import sample dataset\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# Beta diversity metrics like Bray-Curtis are often applied to relabundances\ntse &lt;- transformAssay(tse,\n                      assay.type = \"counts\",\n                      method = \"relabundance\")\n\n# Other metrics like Aitchison to clr-transformed data\ntse &lt;- transformAssay(tse,\n                      assay.type = \"relabundance\",\n                      method = \"clr\",\n                      pseudocount = TRUE)\n\n# Add group information Feces yes/no\ntse$Group &lt;- tse$SampleType == \"Feces\"\n\n\n6.1.1 Comparing communities by beta diversity analysis\nA typical comparison of community compositions starts with a visual representation of the groups by a 2D ordination. Then we estimate relative abundances and MDS ordination based on Bray-Curtis index between the groups, and visualize the results.\nIn the following examples dissimilarity is calculated with the function supplied to the FUN argument. Several metrics of beta diversity are defined by the vegdist function of the vegan package, which is often used in this context. However, such custom functions created by the user also work, as long as they return a dist object. In either case, this function is then applied to calculate reduced dimensions via an ordination method, the results of which can be stored in the reducedDim slot of the TreeSE. This entire process is contained by the runMDS and runNMDS functions.\n\n# Load package to plot reducedDim\nlibrary(scater)\n\n# Run PCoA on relabundance assay with Bray-Curtis distances\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"bray\",\n              assay.type = \"relabundance\",\n              name = \"MDS_bray\")\n\nSample dissimilarity can be visualized on a lower-dimensional display (typically 2D) using the plotReducedDim function from the scater package. This also provides tools to incorporate additional information encoded by color, shape, size and other aesthetics. Can you find any difference between the groups?\n\n# Create ggplot object\np &lt;- plotReducedDim(tse, \"MDS_bray\",\n                    colour_by = \"Group\")\n\n# Calculate explained variance\ne &lt;- attr(reducedDim(tse, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Add explained variance for each axis\np &lt;- p + labs(x = paste(\"PCoA 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n              y = paste(\"PCoA 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\"))\n\np\n\n\n\n\nMDS plot based on the Bray-Curtis distances on the GlobalPattern dataset.\n\n\n\n\nA few combinations of beta diversity metrics and assay types are typically used. For instance, Bray-Curtis dissimilarity and Euclidean distance are often applied to the relative abundance and the clr assays, respectively. Besides beta diversity metric and assay type, the PCoA algorithm is also a variable that should be considered. Below, we show how the choice of these three factors can affect the resulting lower-dimensional data.\n\n# Run NMDS on relabundance assay with Bray-Curtis distances\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               method = \"bray\",\n               assay.type = \"relabundance\",\n               name = \"NMDS_bray\")\n\n# Run MDS on clr assay with Aitchison distances\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"euclidean\",\n              assay.type = \"clr\",\n              name = \"MDS_aitchison\")\n\n# Run NMDS on clr assay with Euclidean distances\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               method = \"euclidean\",\n               assay.type = \"clr\",\n               name = \"NMDS_aitchison\")\n\nMultiple ordination plots are combined into a multi-panel plot with the patchwork package, so that different methods can be compared to find similarities between them or select the most suitable one to visualize beta diversity in the light of the research question.\n\n# Load package for multi-panel plotting\nlibrary(patchwork)\n\n# Generate plots for all 4 reducedDims\nplots &lt;- lapply(c(\"MDS_bray\", \"MDS_aitchison\",\n                  \"NMDS_bray\", \"NMDS_aitchison\"),\n                plotReducedDim,\n                object = tse,\n                colour_by = \"Group\")\n\n# Generate multi-panel plot\nwrap_plots(plots) +\n  plot_layout(guides = \"collect\")\n\n\n\n\nComparison of MDS and NMDS plots based on the Bray-Curtis or Aitchison distances on the GlobalPattern dataset.\n\n\n\n\nThe Unifrac method is a special case, as it requires data on the relationship of features in form on a phylo tree. calculateUnifrac performs the calculation to return a dist object, which can again be used within runMDS.\n\ntse &lt;- runMDS(tse,\n              FUN = mia::calculateUnifrac,\n              name = \"Unifrac\",\n              tree = rowTree(tse),\n              ntop = nrow(tse),\n              assay.type = \"counts\")\n\nplotReducedDim(tse, \"Unifrac\",\n               colour_by = \"Group\")\n\n\n\n\nUnifrac distances scaled by MDS of the GlobalPattern dataset.\n\n\n\n\n\n\n6.1.2 Other ordination methods\nOther dimension reduction methods, such as PCA and UMAP, are inherited from the scater package.\n\ntse &lt;- runPCA(tse,\n              name = \"PCA\",\n              assay.type = \"counts\",\n              ncomponents = 10)\n\nplotReducedDim(tse, \"PCA\",\n               colour_by = \"Group\")\n\n\n\n\nPCA plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\n\nAs mentioned before, applicability of the different methods depends on your sample set and research question.\n\ntse &lt;- runUMAP(tse,\n               name = \"UMAP\",\n               assay.type = \"counts\",\n               ncomponents = 3)\n\nplotReducedDim(tse, \"UMAP\",\n               colour_by = \"Group\",\n               ncomponents = c(1:3))\n\n\n\n\nUMAP plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\n\n\n\n6.1.3 Explained variance\nThe percentage of explained variance is typically shown for PCA ordination plots. This quantifies the proportion of overall variance in the data that is captured by the PCA axes, or how well the ordination axes reflect the original distances.\nSometimes a similar measure is shown for MDS/PCoA. The interpretation is generally different, however, and hence we do not recommend using it. PCA is a special case of PCoA with Euclidean distances. With non-Euclidean dissimilarities PCoA uses a trick where the pointwise dissimilarities are first cast into similarities in a Euclidean space (with some information loss i.e. stress) and then projected to the maximal variance axes. In this case, the maximal variance axes do not directly reflect the correspondence of the projected distances and original distances, as they do for PCA.\nIn typical use cases, we would like to know how well the ordination reflects the original similarity structures; then the quantity of interest is the so-called “stress” function, which measures the difference in pairwise similarities between the data points in the original (high-dimensional) vs. projected (low-dimensional) space.\nHence, we propose that for PCoA and other ordination methods, users would report relative stress, which varies in the unit interval and is better if smaller. This can be calculated as shown below.\n\n# Load vegan package\nlibrary(vegan)\n\n# Quantify dissimilarities in the original feature space\nx &lt;- assay(tse, \"relabundance\") # Pick relabunance assay separately\nd0 &lt;- as.matrix(vegdist(t(x), \"bray\"))\n\n# PCoA Ordination\npcoa &lt;- as.data.frame(cmdscale(d0, k = 2))\nnames(pcoa) &lt;- c(\"PCoA1\", \"PCoA2\")\n\n# Quantify dissimilarities in the ordination space\ndp &lt;- as.matrix(dist(pcoa))\n\n# Calculate stress i.e. relative difference in the original and\n# projected dissimilarities\nstress &lt;- sum((dp - d0)^2) / sum(d0^2)\n\nA Shepard plot visualizes the original versus the ordinated dissimilarity between the observations.\n\nord &lt;- order(as.vector(d0))\ndf &lt;- data.frame(d0 = as.vector(d0)[ord],\n                 dmds = as.vector(dp)[ord])\n\nggplot(df, aes(x = d0, y = dmds)) +\n  geom_smooth() +\n  geom_point() +    \n  labs(title = \"Shepard plot\",\n       x = \"Original distance\",\n       y = \"MDS distance\",   \n       subtitle = paste(\"Stress:\", round(stress, 2))) +\n  theme_bw()"
  },
  {
    "objectID": "20_beta_diversity.html#supervised-ordination",
    "href": "20_beta_diversity.html#supervised-ordination",
    "title": "6  Community Similarity",
    "section": "6.2 Supervised ordination",
    "text": "6.2 Supervised ordination\ndbRDA is a supervised counterpart of PCoA, that is, it takes into account the covariates specified by the user to maximize the variance with respect to the them. The result shows how much each covariate affects beta diversity. The table below illustrates the relation between supervised and unsupervised ordination methods.\n\n\n\n\n\n\n\n\n\nsupervised ordination\nunsupervised ordination\n\n\n\n\nEuclidean distance\nRDA\nPCA\n\n\nnon-Euclidean distance\ndbRDA\nPCoA/MDS, NMDS and UMAP\n\n\n\nWe demonstrate the usage of dbRDA with the enterotype dataset, where samples correspond to patients. The colData contains the clinical status of each patient and a few covariates such as their gender and age.\n\n# Load data\ndata(\"enterotype\", package = \"mia\")\ntse2 &lt;- enterotype\n\n# Apply relative transform\ntse2 &lt;- transformAssay(tse2,\n                       method = \"relabundance\")\n\ndbRDA can be perfomed with the runRDA function. In addition to the arguments previously defined for unsupervised ordination, this function takes a formula to control for variables and an action to treat missing values. Along with clinical status, which is the main outcome, we control for gender and age, and exclude observations where one of these variables is missing.\n\n# Perform RDA\ntse2 &lt;- runRDA(tse2,\n               assay.type = \"relabundance\",\n               formula = assay ~ ClinicalStatus + Gender + Age,\n               distance = \"bray\",\n               na.action = na.exclude)\n\n# Store results of PERMANOVA test\nrda_info &lt;- attr(reducedDim(tse2, \"RDA\"), \"significance\")\n\nThe importance of each variable on the similarity between samples can be assessed from the results of PERMANOVA, automatically provided by the runRDA function. We see that both clinical status and age explain more than 10% of the variance, but only age shows statistical significance.\n\nrda_info$permanova |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSumOfSqs\nF\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\n\nModel\n6\n1.1157\n1.940\n0.030\n3.991\n0.2795\n\n\nClinicalStatus\n4\n0.5837\n1.522\n0.142\n3.991\n0.1463\n\n\nGender\n1\n0.1679\n1.751\n0.102\n3.991\n0.0421\n\n\nAge\n1\n0.5245\n5.471\n0.001\n3.991\n0.1314\n\n\nResidual\n30\n2.8757\nNA\nNA\n3.991\n0.7205\n\n\n\n\n\nTo ensure that the homogeneity assumption holds, we retrieve the corresponding information from the results of RDA. In this case, none of the p-values is lower than the significance threshold, and thus homogeneity is observed.\n\nrda_info$homogeneity |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF\nN.Perm\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\n\nClinicalStatus\n4\n0.2511\n0.0628\n2.7440\n999\n0.131\n1.0288\n0.2440\n\n\nGender\n1\n0.0103\n0.0103\n0.4158\n999\n0.554\n0.9283\n0.0111\n\n\nAge\n29\n0.3272\n0.0113\n17.0256\n999\n0.432\n0.3319\n0.9860\n\n\n\n\n\nNext, we proceed to visualize the weight and significance of each variable on the similarity between samples with an RDA plot, which can be generated with the plotRDA function from the miaViz package.\n\n# Load packages for plotting function\nlibrary(miaViz)\n\n# Generate RDA plot coloured by clinical status\nplotRDA(tse2, \"RDA\", colour_by = \"ClinicalStatus\")\n\n\n\n\nFrom the plot above, we can see that only age significantly describes differences between the microbial profiles of different samples. Such visual approach complements the previous results of PERMANOVA."
  },
  {
    "objectID": "20_beta_diversity.html#case-studies",
    "href": "20_beta_diversity.html#case-studies",
    "title": "6  Community Similarity",
    "section": "6.3 Case studies",
    "text": "6.3 Case studies\n\n6.3.0.1 Visualizing the most dominant genus on PCoA\nIn this section, we visualize the most dominant genus on PCoA. A similar visualization was proposed by [-@Salosensaari2021]. First, we agglomerate the data at the Genus level and get the dominant taxa per sample.\n\n# Agglomerate to genus level\ntse_genus &lt;- mergeFeaturesByRank(tse,\n                                 rank = \"Genus\")\n\n# Convert to relative abundances\ntse_genus &lt;- transformAssay(tse,\n                            method = \"relabundance\",\n                            assay.type = \"counts\")\n\n# Add info on dominant genus per sample\ntse_genus &lt;- addPerSampleDominantFeatures(tse_genus,\n                                          assay.type = \"relabundance\",\n                                          name = \"dominant_taxa\")\n# Overview\ncountDominantFeatures(tse_genus, rank = \"Genus\", digits = 3, name = \"dominant_taxa\")\n\n# A tibble: 17 × 3\n   dominant_taxa                  n rel_freq\n   &lt;chr&gt;                      &lt;int&gt;    &lt;dbl&gt;\n 1 Genus:Bacteroides              5    0.192\n 2 Order:Stramenopiles            4    0.154\n 3 Family:Desulfobulbaceae        2    0.077\n 4 Genus:Streptococcus            2    0.077\n 5 Class:Chloracidobacteria       1    0.038\n 6 Family:ACK-M1                  1    0.038\n 7 Family:Flavobacteriaceae       1    0.038\n 8 Family:Moraxellaceae           1    0.038\n 9 Family:Ruminococcaceae         1    0.038\n10 Genus:CandidatusSolibacter     1    0.038\n11 Genus:Dolichospermum           1    0.038\n12 Genus:Faecalibacterium         1    0.038\n13 Genus:MC18                     1    0.038\n14 Genus:Neisseria                1    0.038\n15 Genus:Prochlorococcus          1    0.038\n16 Genus:Veillonella              1    0.038\n17 Order:Chromatiales             1    0.038\n\n\nNext, we perform PCoA with Bray-Curtis dissimilarity.\n\ntse_genus &lt;- runMDS(tse_genus,\n                    FUN = vegan::vegdist,\n                    name = \"PCoA_BC\",\n                    assay.type = \"relabundance\")\n\nFinally, we get the top taxa and and visualize their abundances on PCoA. Note that A 3D interactive version of the plot below can be found in @ref(extras).\n\n# Getting the top taxa\ntop_taxa &lt;- getTopFeatures(tse_genus,\n                           top = 6,\n                           assay.type = \"relabundance\")\n\n# Naming all the rest of non top-taxa as \"Other\"\nmost_abundant &lt;- lapply(colData(tse_genus)$dominant_taxa,\n                        function(x) {if (x %in% top_taxa) {x} else {\"Other\"}})\n\n# Storing the previous results as a new column within colData\ncolData(tse_genus)$most_abundant &lt;- as.character(most_abundant)\n\n# Calculating percentage of the most abundant\nmost_abundant_freq &lt;- table(as.character(most_abundant))\nmost_abundant_percent &lt;- round(most_abundant_freq / sum(most_abundant_freq) * 100, 1)\n\n# Retrieving the explained variance\ne &lt;- attr(reducedDim(tse_genus, \"PCoA_BC\"), \"eig\")\nvar_explained &lt;- e / sum(e[e &gt; 0]) * 100\n\n# Define colors for visualization\nmy_colors &lt;- c(\"black\", \"blue\", \"lightblue\", \"darkgray\", \"magenta\", \"darkgreen\", \"red\")\n\n# Visualization\nplot &lt;-plotReducedDim(tse_genus, \"PCoA_BC\",\n                      colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(most_abundant_percent), \"(\", most_abundant_percent, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       color = \"\")\n\nplot\n\n\n\n\nSimilarly, we visualize and compare the sub-population.\n\n# Calculating the frequencies and percentages for both categories\nfreq_TRUE &lt;- table(as.character(most_abundant[colData(tse_genus)$Group == TRUE]))\nfreq_FALSE &lt;- table(as.character(most_abundant[colData(tse_genus)$Group == FALSE]))\npercent_TRUE &lt;- round(freq_TRUE / sum(freq_TRUE) * 100, 1)\npercent_FALSE &lt;- round(freq_FALSE / sum(freq_FALSE) * 100, 1)\n\n# Visualization\nplotReducedDim(tse_genus[ , colData(tse_genus)$Group == TRUE], \"PCoA_BC\",\n               colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(percent_TRUE), \"(\", percent_TRUE, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       title = \"Group = TRUE\", color = \"\")\n\n\n\nplotReducedDim(tse_genus[ , colData(tse_genus)$Group == FALSE], \"PCoA_BC\",\n               colour_by = \"most_abundant\") +\n  scale_colour_manual(values = my_colors,\n                      labels = paste0(names(percent_FALSE), \"(\", percent_FALSE, \"%)\")) +\n  labs(x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n       title = \"Group = FALSE\", color = \"\")\n\n\n\n\n\n\n6.3.1 Testing differences in community composition between sample groups\nPermutational Analysis of Variance (PERMANOVA; [-@Anderson2001]) is a widely used non-parametric multivariate method that aims to estimate the actual statistical significance of differences in the observed community composition between two groups of samples.\nPERMANOVA tests the hypothesis that the centroids and dispersion of the community are equivalent between the compared groups. A p-value smaller than the significance threshold indicates that the groups have a different community composition. This method is implemented with the adonis2 function from the vegan package.\nBy default, the argument by is set to \"terms\", in which the order of variables in the formula matters. In this case, each variable is analyzed sequentially, and the result is different when more than 1 variable is introduced and their order differs. Therefore, it is recommended to set by = \"margin\", which specifies that the marginal effect of each variable is analyzed individually. You can view a comparison between the two designs in chapter @ref(compare-permanova).\nWe can perform PERMANOVA either with adonis2 function or by first performing dbRDA and then applying permutational test its results. An advantage of the latter approach is that by doing so we can get coefficients: how much each taxa affects the variation between communities.\n\n# Agglomerate data to Species level\ntse &lt;- mergeFeaturesByRank(tse,\n                           rank = \"Species\")\n\n# Set seed for reproducibility\nset.seed(1576)\n# We choose 99 random permutations. Consider applying more (999 or 9999) in your\n# analysis. \npermanova &lt;- adonis2(t(assay(tse, \"relabundance\")) ~ Group,\n                     by = \"margin\", # each term (here only 'Group') analyzed individually\n                     data = colData(tse),\n                     method = \"euclidean\",\n                     permutations = 99)\n\n# Set seed for reproducibility\nset.seed(1576)\n# Perform dbRDA\ndbrda &lt;- dbrda(t(assay(tse,\"relabundance\")) ~ Group, \n               data = colData(tse))\n# Perform permutational analysis\npermanova2 &lt;- anova.cca(dbrda,\n                        by = \"margin\", # each term (here only 'Group') analyzed individually\n                        method = \"euclidean\",\n                        permutations = 99)\n\n# Get p-values\np_values &lt;- c(permanova[\"Group\", \"Pr(&gt;F)\"], permanova2[\"Group\", \"Pr(&gt;F)\"])\np_values &lt;-as.data.frame(p_values)\nrownames(p_values) &lt;- c(\"adonis2\", \"dbRDA+anova.cca\")\np_values\n\n                p_values\nadonis2             0.02\ndbRDA+anova.cca     0.02\n\n\nAs we can see, the community composition is significantly different between the groups (p &lt; 0.05), and these two methods give equal p-values.\nLet us visualize the model coefficients for species that exhibit the largest differences between the groups. This gives some insights into how the groups tend to differ from each other in terms of community composition.\n\n# Add taxa info\nsppscores(dbrda) &lt;- t(assay(tse, \"relabundance\"))\n# Get coefficients\ncoef &lt;- dbrda$CCA$v\n# Get the taxa with biggest weights\ntop.coef &lt;- head(coef[rev(order(abs(coef))), , drop = FALSE], 20)\n# Sort weights in increasing order\ntop.coef &lt;- top.coef[order(top.coef), ]\n# Get top names\ntop_names &lt;- names(top.coef)[order(abs(top.coef), decreasing = TRUE)]\n\n\ndf &lt;- data.frame(x = top.coef,\n                 y = factor(names(top.coef), unique(names(top.coef))))\n\nggplot(df, aes(x = x, y = y)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"\", y= \"\", title = \"Top Taxa\") +\n  theme_bw()\n\n\n\n\nIn the example above, the largest differences between the two groups can be attributed to Genus:Bacteroides (elevated in the first group) and Family:Ruminococcaceae (elevated in the second group), and many other co-varying species.\n\n\n6.3.2 Checking the homogeneity condition\nIt is important to note that the application of PERMANOVA assumes homogeneous group dispersions (variances). This can be tested with the PERMDISP2 method [@Anderson2006] by using the same assay and distance method than in PERMANOVA.\n\nanova(betadisper(vegdist(t(assay(tse, \"counts\"))), colData(tse)$Group))\n\nAnalysis of Variance Table\n\nResponse: Distances\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)    \nGroups     1 0.2385  0.2385     103 3.6e-10 ***\nResiduals 24 0.0554  0.0023                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the groups have similar dispersion, PERMANOVA can be seen as an appropriate choice for comparing community compositions."
  },
  {
    "objectID": "20_beta_diversity.html#summary",
    "href": "20_beta_diversity.html#summary",
    "title": "6  Community Similarity",
    "section": "6.4 Summary",
    "text": "6.4 Summary\nAs a final note, we provide a comprehensive list of functions for the evaluation of dissimilarity indices available in the mia and scater packages. The calculate methods return a reducedDim object as an output, whereas the run methods store the reducedDim object into the specified TreeSE.\n\nCanonical Correspondence Analysis (CCA): calculateCCA and runCCA\ndbRDA: calculateRDA and runRDA\nDouble Principal Coordinate Analysis (DPCoA): calculateDPCoA and runDPCoA\nJensen-Shannon Divergence (JSD): calculateJSD and runJSD\nMDS: calculateMDS and runMDS\nNMDS: calculateNMDS and runNMDS\nOverlap: calculateOverlap and runOverlap\nt-distributed Stochastic Neighbor Embedding (t-SNE): calculateTSNE and runTSNE\nUMAP: calculateUMAP and runUMAP\n\nFor more information on clustering samples by beta diversity, you can refer to:\n\nHow to extract information from clusters\nChapter @ref(clustering) on community typing"
  },
  {
    "objectID": "21_microbiome_community.html#visual-composition",
    "href": "21_microbiome_community.html#visual-composition",
    "title": "7  Community Composition",
    "section": "7.1 Visualizing taxonomic composition",
    "text": "7.1 Visualizing taxonomic composition\n\n7.1.1 Composition barplot\nA typical way to visualize microbiome composition is by using composition barplot. In the following, relative abundance is calculated and top taxa are retrieved for the Phylum rank. Thereafter, the barplot is visualized ordering rank by abundance values and samples by “Bacteroidetes”:\n\nlibrary(miaViz)\n# Computing relative abundance\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\n# Getting top taxa on a Phylum level\ntse_phylum &lt;- mergeFeaturesByRank(tse, rank =\"Phylum\", onRankOnly=TRUE)\ntop_taxa &lt;- getTopFeatures(tse_phylum,top = 5, assay.type = \"relabundance\")\n\n# Renaming the \"Phylum\" rank to keep only top taxa and the rest to \"Other\"\nphylum_renamed &lt;- lapply(rowData(tse)$Phylum,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\nrowData(tse)$Phylum &lt;- as.character(phylum_renamed)\n\n# Visualizing the composition barplot, with samples order by \"Bacteroidetes\"\nplotAbundance(tse, assay.type=\"relabundance\", rank = \"Phylum\",\n              order_rank_by=\"abund\", \n              order_sample_by = \"Bacteroidetes\")\n\n\n\n\n\n\n7.1.2 Composition heatmap\nCommunity composition can be visualized with heatmap, where the horizontal axis represents samples and the vertical axis the taxa. Color of each intersection point represents abundance of a taxon in a specific sample.\nHere, abundances are first CLR (centered log-ratio) transformed to remove compositionality bias. Then Z transformation is applied to CLR-transformed data. This shifts all taxa to zero mean and unit variance, allowing visual comparison between taxa that have different absolute abundance levels. After these rough visual exploration techniques, we can visualize the abundances at Phylum level.\n\nlibrary(ggplot2)\n\n# Add clr-transformation on samples\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"counts\",\n                              method = \"relabundance\", pseudocount = 1)\n\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"relabundance\",\n                              method = \"clr\", pseudocount = 1)\n\n# Add z-transformation on features (taxa)\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"clr\", \n                              MARGIN = \"features\",\n                              method = \"z\", name = \"clr_z\")\n\nVisualize as heatmap.\n\n# Melt the assay for plotting purposes\ndf &lt;- meltAssay(tse_phylum, assay.type = \"clr_z\")\n\n# Determines the scaling of colours\nmaxval &lt;- round(max(abs(df$clr_z)))\nlimits &lt;- c(-maxval, maxval)\nbreaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5)\ncolours &lt;- c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\")\n\n# Creates a ggplot object\nggplot(df, aes(x = SampleID, y = FeatureID, fill = clr_z)) +\n  geom_tile() +\n  scale_fill_gradientn(name = \"CLR + Z transform\", \n                       breaks = breaks, limits = limits, colours = colours) + \n  theme(text = element_text(size=10),\n        axis.text.x = element_text(angle=45, hjust=1),\n        legend.key.size = unit(1, \"cm\")) +\n  labs(x = \"Samples\", y = \"Taxa\")\n\n\n\n\npheatmap is a package that provides methods to plot clustered heatmaps.\n\nlibrary(pheatmap)\n\n# Takes subset: only samples from feces, skin, or tongue\ntse_phylum_subset &lt;- tse_phylum[ , tse_phylum$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Add clr-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset,\n                         method = \"clr\",\n                 pseudocount = 1)\n\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, assay.type = \"clr\",\n                                     MARGIN = \"features\", \n                                     method = \"z\", name = \"clr_z\")\n\n# Get n most abundant taxa, and subsets the data by them\ntop_taxa &lt;- getTopFeatures(tse_phylum_subset, top = 20)\ntse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ]\n\n# Gets the assay table\nmat &lt;- assay(tse_phylum_subset, \"clr_z\")\n\n# Creates the heatmap\npheatmap(mat)\n\n\n\n\nWe can create clusters by hierarchical clustering and add them to the plot.\n\nlibrary(ape)\n\n# Hierarchical clustering\ntaxa_hclust &lt;- hclust(dist(mat), method = \"complete\")\n\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\n\n\nlibrary(ggtree)\n\n# Plot taxa tree\ntaxa_tree &lt;- ggtree(taxa_tree) + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of taxa in plot\ntaxa_ordered &lt;- get_taxa_name(taxa_tree)\n\ntaxa_tree\n\n\n\n\nBased on phylo tree, we decide to create three clusters.\n\n# Creates clusters\ntaxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3)\n\n# Converts into data frame\ntaxa_clusters &lt;- data.frame(clusters = taxa_clusters)\ntaxa_clusters$clusters &lt;- factor(taxa_clusters$clusters)\n\n# Order data so that it's same as in phylo tree\ntaxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] \n\n# Prints taxa and their clusters\ntaxa_clusters\n\n                 clusters\nChloroflexi             3\nActinobacteria          3\nCrenarchaeota           3\nPlanctomycetes          3\nGemmatimonadetes        3\nThermi                  3\nAcidobacteria           3\nSpirochaetes            2\nFusobacteria            2\nSR1                     2\nCyanobacteria           2\nProteobacteria          2\nSynergistetes           2\nLentisphaerae           1\nBacteroidetes           1\nVerrucomicrobia         1\nTenericutes             1\nFirmicutes              1\nEuryarchaeota           1\nSAR406                  1\n\n\n\n# Adds information to rowData\nrowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ]\n\n# Prints taxa and their clusters\nrowData(tse_phylum_subset)$clusters\n\n [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1\nLevels: 1 2 3\n\n\n\n# Hierarchical clustering\nsample_hclust &lt;- hclust(dist(t(mat)), method = \"complete\")\n\n# Creates a phylogenetic tree\nsample_tree &lt;- as.phylo(sample_hclust)\n\n# Plot sample tree\nsample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of samples in plot\nsamples_ordered &lt;- rev(get_taxa_name(sample_tree))\n\nsample_tree\n\n\n\n\n\n# Creates clusters\nsample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3))\n\n# Converts into data frame\nsample_data &lt;- data.frame(clusters = sample_clusters)\n\n# Order data so that it's same as in phylo tree\nsample_data &lt;- sample_data[samples_ordered, , drop = FALSE] \n\n# Order data based on \ntse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)]\n\n# Add sample type data\nsample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType)\n\nsample_data\n\n        clusters sample_types\nM11Plmr        2         Skin\nM31Plmr        2         Skin\nF21Plmr        2         Skin\nM31Fcsw        1        Feces\nM11Fcsw        1        Feces\nTS28           3        Feces\nTS29           3        Feces\nM31Tong        3       Tongue\nM11Tong        3       Tongue\n\n\nNow we can create heatmap with additional annotations.\n\n# Determines the scaling of colorss\n# Scale colors\nbreaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), \n              length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(mat, annotation_row = taxa_clusters, \n         annotation_col = sample_data,\n         breaks = breaks,\n         color = colors)\n\n\n\n\nIn addition, there are also other packages that provide functions for more complex heatmaps, such as iheatmapr and ComplexHeatmap [@ComplexHeatmap]. sechm package provides wrapper for ComplexHeatmap and its usage is explained in chapter @ref(viz-chapter) along with the pheatmap package for clustered heatmaps."
  },
  {
    "objectID": "30_differential_abundance.html#statistical-challenges-of-microbiome-data",
    "href": "30_differential_abundance.html#statistical-challenges-of-microbiome-data",
    "title": "8  Differential Abundance",
    "section": "8.1 Statistical challenges of microbiome data",
    "text": "8.1 Statistical challenges of microbiome data\nMicrobiome data display unique properties that are exclusively addressed by DAA tools developed for microbiome analysis. Specifically, microbiome data are characterized by high variability, zero-inflation and compositionality. High variability expresses that abundance of taxa often varies by several orders of magnitude from sample to sample. Zero-inflation means that typically more than 70% of the values are zeros, which could be due to either physical absence (structural zeros) or insufficient sampling effort (sampling zeros). Compositionality implies that a change in the absolute abundance of one taxon will lead to apparent variations in the relative abundances of other taxa in the same sample. If neglected, such properties may cause significant bias in the results of DAA. Therefore, several approaches have been developed to address the unique properties of microbiome data and provide statistically useful results.\nThe first approach to target zero-inflated data consists of specialized models, such as over-dispersed count models and zero-inflated mixture models. DESeq2, edgeR and corncorb are based on over-dispersed count models, whereas metagenomeSeq, RAIDA, ZIBB and Omnibus implement zero-inflated mixture models to address zero-inflation. Typically, these models assume a negative binomial, beta-binomial or normal/log-normal distribution. Alternatively, zero imputation also represents a valid approach to deal with zero-inflated data. ALDEx2 and eBay apply a Bayesian model to impute the zeros when working with proportion data, accounting for sampling variability and sequencing depth variation. Other methods, such as MaAsLin2 and ANCOMBC impute the zeros with a pseudo-count strategy.\nRegarding the compositionality of microbiome data, several approaches have been developed to perform robust normalization with methods specifically designed to reduce the bias found in compositional data. Some examples include trimmed mean of M-values (TMM) normalization used by edgeR, relative log expression (RLE) normalization used by DESeq2, cumulative sum scaling (CSS) normalization used by metagenomeSeq, centered log-ratio transformation (CLR) normalization used by ALDEx2 and geometric mean of pairwise ratios (GMPR) normalization used by Omnibus and Wrench normalization [@Kumar2018], which corrects the compositional bias by an empirical Bayes approach. Other methods to deal with compositional data entail reference taxa approach used by DACOMP and RAIDA, analyzing the pattern of pairwise log ratios as done by ANCOM and bias-correction applied by ANCOMBC.\nWe recommend to have a look at @Nearing2022. In this study, multiple DAA methods were applied to 38 different datasets and their results were compared to one another. Because each method follows a slightly different approach in terms of assumptions and normalization techniques, it was shown that results on the same dataset may differ substantially depending on the method. Recently, @Yang2022 comprehensively evaluated DAA methods via a semi-parametric framework and 106 real datasets. This study also concluded that different methods can produce contradictory results, creating the risk of cherry-picking the most favorable options for one’s own hypothesis. Therefore, it is highly recommended to perform DAA with multiple methods to determine whether the findings can be reproduced by different approaches. Built on the findings of @Calgaro2020, the benchdamic [@Calgaro2022] package could offer a valuable support in this regard. Through a comprehensive evaluation process it serves both practitioners by comparing DA methods from existing literature, and method developers by providing an impartial tool to evaluate their new approaches in comparison to what is already available. For details, check its extensive vignette."
  },
  {
    "objectID": "30_differential_abundance.html#using-the-tools",
    "href": "30_differential_abundance.html#using-the-tools",
    "title": "8  Differential Abundance",
    "section": "8.2 Using the tools",
    "text": "8.2 Using the tools\nIn this section we demonstrate the use of four methods that can be recommended based on recent literature (ANCOM-BC [@ancombc2020], ALDEx2 [@Gloor2016], Maaslin2 [@Mallick2020], LinDA [@Zhou2022] and ZicoSeq [@Yang2022]).\nThe purpose of this section is to show how to perform DAA in R, not how to correctly do causal inference. Depending on your experimental setup and your theory, you must determine how to specify any model exactly. E.g., there might be confounding factors that might drive (the absence of) differences between the shown groups that we ignore here for simplicity. Or your dataset is repeated sampling design, matched-pair design or the general longitudianl design. We will demonstrate how to include covariates in those models. We picked a dataset that merely has microbial abundances in a TSE object as well as a grouping variable in the sample data. We simplify the examples by only including two of the three groups.\n\nlibrary(mia)\nlibrary(tidyverse)\n\n# Import dataset\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020\n\n# Show patient status by cohort\ntable(tse$patient_status, tse$cohort) %&gt;%\n  knitr::kable()\n\n\n\n\n\nCohort_1\nCohort_2\nCohort_3\n\n\n\n\nADHD\n4\n5\n4\n\n\nControl\n6\n5\n3\n\n\n\n\n\n\n8.2.1 Preparing the data for DAA\nBefore starting the analysis, it is recommended to reduce the size and complexity of the data to make the results more reproducible. For this purpose, we agglomerate the features by genus and filter them by a prevalence threshold of 10%.\n\n# Agglomerate by genus and subset by prevalence\ntse &lt;- subsetByPrevalentTaxa(tse,\n                             rank = \"Genus\",\n                             prevalence = 10 / 100)\n\n# Transform count assay to relative abundances\ntse &lt;- transformAssay(tse,\n                      assay.type = \"counts\",\n                      method = \"relabundance\")\n\nWhile some DAA tools provide optional arguments for prevalence filtering, here we filtered the tse object directly. This way, we ensure that the input data remains the same when multiple tools are used.\n\n\n8.2.2 ALDEx2\nIn this section, we will show how to perform DAA with ALDEx2, which can be regarded as the method of choice for its consistency, as it normally identifies features that are also found by complementary methods [@Nearing2022]. A more extensive introduction to its functionality is available in the ALDEx2 vignette.\nALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the CLR transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch’s t-test and Wilcoxon test or a one-way ANOVA and Kruskal-Wallis test. For more complex study designs, there is a possibility to utilize the glm functionality within ALDEx2. The Benjamini-Hochberg procedure is applied by default to correct for multiple testing.\n\n# Load package\nlibrary(ALDEx2)\n\n# Generate Monte Carlo samples of the Dirichlet distribution for each sample.\n# Convert each instance using the centered log-ratio transform.\n# This is the input for all further analyses.\nset.seed(123)\nx &lt;- aldex.clr(assay(tse), tse$patient_status)     \n\nThe t-test:\n\n# calculates expected values of the Welch's t-test and Wilcoxon rank\n# test on the data returned by aldex.clr\nx_tt &lt;- aldex.ttest(x, paired.test = FALSE, verbose = FALSE)\n\nEffect sizes:\n\n# Determines the median clr abundance of the feature in all samples and in\n# groups, the median difference between the two groups, the median variation\n# within each group and the effect size, which is the median of the ratio\n# of the between group difference and the larger of the variance within groups\nx_effect &lt;- aldex.effect(x, CI = TRUE, verbose = FALSE)\n\n# combine all outputs \naldex_out &lt;- data.frame(x_tt, x_effect)\n\nNow, we can create a so called Bland-Altman or MA plot (left). It shows the association between the relative abundance and the magnitude of the difference per sample. Next to that, we can also create a plot that shows the dispersion on the x-axis instead of log-ratio abundance. Red dots represent genera that are differentially abundant (\\(q \\leq 0.1\\)) between the 2 groups. Black points are rare taxa and grey ones are abundant taxa. The dashed line represent an effect size of 1. @Gloor2016 provides more information on these plots.\n\npar(mfrow = c(1, 2))\n\naldex.plot(aldex_out,\n           type = \"MA\",\n           test = \"welch\",\n           xlab = \"Log-ratio abundance\",\n           ylab = \"Difference\",\n           cutoff = 0.05)\n\naldex.plot(aldex_out,\n           type = \"MW\",\n           test = \"welch\",\n           xlab = \"Dispersion\",\n           ylab = \"Difference\",\n           cutoff = 0.05)\n\n\n\n\nThe evaluation as differential abundant in above plots is based on the corrected p-value. According to the ALDEx2 developers, the safest approach is to identify those features where the 95% CI of the effect size does not cross 0. As we can see in below table, this is not the case for any of the identified genera (see overlap column, which indicates the proportion of overlap). Also, the authors recommend to focus on effect sizes and CIs rather than interpreting the p-value. To keep the comparison simple, we will here use the p-value as decision criterion. But please be aware that the effect size together with the CI is a better answer to the question we are typically interested in.\n\naldex_out %&gt;%\n  rownames_to_column(var = \"Genus\") %&gt;%\n  # here we choose the wilcoxon output rather than t-test output\n  filter(wi.eBH &lt;= 0.05)  %&gt;%\n  dplyr::select(Genus, we.eBH, wi.eBH, effect, overlap) %&gt;%\n  knitr::kable()\n\n\n\n\nGenus\nwe.eBH\nwi.eBH\neffect\noverlap\n\n\n\n\n[Ruminococcus]_gauvreauii_group\n0.0664\n0.0345\n0.8184\n0.1142\n\n\n\n\n\n\n\n8.2.3 ANCOM-BC\nThe analysis of composition of microbiomes with bias correction (ANCOM-BC) [@ancombc2020] is a recently developed method for differential abundance testing. It is based on an earlier published approach [@Mandal2015]. The previous version of ANCOM was among the methods that produced the most consistent results and is probably a conservative approach [@Nearing2022]. However, the new ANCOM-BC method operates quite differently compared to the former ANCOM method.\nAs the only method, ANCOM-BC incorporates the so called sampling fraction into the model. The latter term could be empirically estimated by the ratio of the library size to the microbial load. According to the authors, ignoring variations in this sampling fraction would bias DAA results. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement.\nNote that the original method was implemented in the ancombc() function (see extended tutorial). The method has since then been updated and new features have been added to enable multi-group comparisons and repeated measurements among other improvements. We do not cover the more advanced features of ANCOMBC in this tutorial as these features are documented in detail in this tutorial.\nWe now proceed with a simple example. First, we specify a formula. In this formula, other covariates could potentially be included to adjust for confounding. We show this further below. Again, please make sure to check the function documentation as well as the linked tutorials to learn about the additional arguments that we specify.\n\n# Load package\nlibrary(ANCOMBC)\n\n# Run ANCOM-BC at the genus level and only including the prevalent genera\nancombc2_out &lt;- ancombc2(data = tse,\n                         assay_name = \"counts\",\n                         fix_formula = \"patient_status\",\n                         p_adj_method = \"fdr\",\n                         prv_cut = 0,\n                         group = \"patient_status\",\n                         struc_zero = TRUE,\n                         neg_lb = TRUE,\n                         # multi group comparison is deactivated automatically\n                         global = TRUE)\n\nThe object out contains all model output. Again, see the documentation of the function under Value for details. Our question whether taxa are differentially abundant can be answered by looking at the res object, which contains dataframes with the coefficients, standard errors, p-values and q-values. Below we show the first entries of this dataframe.\n\n# store the FDR adjusted results \nancombc2_out$res %&gt;%\n  dplyr::select(taxon, lfc_patient_statusControl, q_patient_statusControl) %&gt;%\n  filter(q_patient_statusControl &lt; 0.05) %&gt;%\n  arrange(q_patient_statusControl) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\ntaxon\nlfc_patient_statusControl\nq_patient_statusControl\n\n\n\n\nSubdoligranulum\n1.909\n0.0010\n\n\nRuminococcus_1\n2.915\n0.0010\n\n\n[Ruminococcus]_gauvreauii_group\n1.520\n0.0014\n\n\n[Eubacterium]_rectale_group\n1.361\n0.0050\n\n\n[Clostridium]_innocuum_group\n1.455\n0.0052\n\n\nDielma\n1.166\n0.0052\n\n\n\n\n\n\n\n8.2.4 MaAsLin2\nLet us next illustrate MaAsLin2 [@Mallick2020]. This method is based on generalized linear models and flexible for different study designs and covariate structures. For details, check their Biobakery tutorial.\n\n# Load package\nlibrary(Maaslin2)\n\n# maaslin expects features as columns and samples as rows \n# for both the abundance table as well as metadata \n\n# We can specify different GLMs/normalizations/transforms.\n# specifying a ref is especially important if you have more than 2 levels\nmaaslin2_out &lt;- Maaslin2(input_data = as.data.frame(t(assay(tse))),\n                         input_metadata = as.data.frame(colData(tse)),\n                         output = \"DAA example\",\n                         transform = \"AST\",\n                         fixed_effects = \"patient_status\",\n                         # you can also fit MLM by specifying random effects\n                         # random_effects = c(...),\n                         reference = \"patient_status,Control\",\n                         normalization = \"TSS\",\n                         standardize = FALSE,\n                         # filtering was previously performed\n                         min_prevalence = 0)\n\nWhich genera are identified as differentially abundant? (leave out “head” to see all).\n\nmaaslin2_out$results %&gt;%\n  filter(qval &lt; 0.05) %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeature\nmetadata\nvalue\ncoef\nstderr\npval\nname\nqval\nN\nN.not.zero\n\n\n\n\nX.Ruminococcus._gauvreauii_group\npatient_status\nADHD\n-0.0674\n0.0133\n0.0000\npatient_statusADHD\n0.0015\n27\n21\n\n\nFaecalibacterium\npatient_status\nADHD\n0.1223\n0.0372\n0.0030\npatient_statusADHD\n0.0448\n27\n11\n\n\nX.Clostridium._innocuum_group\npatient_status\nADHD\n-0.0692\n0.0213\n0.0033\npatient_statusADHD\n0.0448\n27\n25\n\n\nCatabacter\npatient_status\nADHD\n0.0295\n0.0092\n0.0037\npatient_statusADHD\n0.0448\n27\n9\n\n\n\n\n\nThis will create a folder that is called like in the output specified above. It contains also figures to visualize difference between significant taxa.\n\n\n8.2.5 LinDA\nLastly, we cover linear models for differential abundance analysis of microbiome compositional data (@Zhou2022). This is very similar to ANCOMBC with few differences: 1) LinDA corrects for the compositional bias differently using the mode of all regression coefficients. 2) it is faster (100x-1000x than ANCOMBC and according to the authors); 3) it supports hierarchical models. The latest ANCOMBC versions are also supporting hierarchical models. Nevertheless, LinDA seems a promising tool that achieves a very good power/fdr trade-off together with ANCOMBC according to the review. The speed improvements might make it critical especially for datasets that have higher sample or feature set sizes.\n\n# Load package\nlibrary(MicrobiomeStat)\n\n# Run LinDA\nlinda_out &lt;- linda(feature.dat = as.data.frame(assay(tse)),\n                   meta.dat = as.data.frame(colData(tse)),\n                   formula = \"~ patient_status\",\n                   alpha = 0.05,\n                   prev.filter = 0,\n                   mean.abund.filter = 0)\n\n0  features are filtered!\nThe filtered data has  27  samples and  49  features will be tested!\nPseudo-count approach is used.\nFit linear models ...\nCompleted.\n\n\n\n# List genera for which H0 could be rejected:\nlinda_out$output$patient_statusControl %&gt;%\n  filter(reject) %&gt;%\n  dplyr::select(stat, padj) %&gt;%\n  rownames_to_column(var = \"feature\") %&gt;%\n  knitr::kable()\n\n\n\n\nfeature\nstat\npadj\n\n\n\n\nFaecalibacterium\n-4.250\n0.0092\n\n\n[Ruminococcus]_gauvreauii_group\n4.110\n0.0092\n\n\nCatabacter\n-3.379\n0.0390\n\n\n\n\n\n\n\n8.2.6 ZicoSeq\nSubsequently, we demonstrate DAA with ZicoSeq, a method based on linear models and permutation. Further details can be found in this tutorial. This approach has been assessed to exhibit high power and a low false discovery rate, which has the following components:\n\nWinsorization to decrease the influence of outliers;\nPosterior sampling based on a beta mixture prior to address sampling variability and zero inflation;\nReference-based multiple-stage normalization to address compositional effects;\n\n\n# Load package\nlibrary(GUniFrac)\n\nset.seed(123)\nzicoseq_out &lt;- ZicoSeq(feature.dat = as.matrix(assay(tse)),\n                       meta.dat = as.data.frame(colData(tse)),\n                       grp.name = \"patient_status\",\n                       feature.dat.type = \"count\",\n                       return.feature.dat = TRUE,\n                       prev.filter = 0,\n                       mean.abund.filter = 0,\n                       max.abund.filter = 0,\n                       perm.no = 999)\n\nFor sample size less than 40, posterior sampling will not be used!\n0  features are filtered!\nThe data has  27  samples and  49  features will be tested!\nOn average,  1  outlier counts will be replaced for each feature!\nFinding the references ...\nPermutation testing ...\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\nCompleted!\n\n\n\nzicoseq_res &lt;- cbind.data.frame(p.raw = zicoseq_out$p.raw,\n                                p.adj.fdr = zicoseq_out$p.adj.fdr)\n\nzicoseq_res %&gt;%\n  filter(p.adj.fdr &lt; 0.05) %&gt;%\n  arrange(p.adj.fdr) %&gt;%\n  knitr::kable()\n\n\n\n\n\np.raw\np.adj.fdr\n\n\n\n\n[Ruminococcus]_gauvreauii_group\n0.001\n0.005\n\n\nFaecalibacterium\n0.001\n0.024\n\n\n[Clostridium]_innocuum_group\n0.003\n0.024\n\n\nCatabacter\n0.006\n0.043\n\n\n\n\n\n\n## x-axis is the effect size: R2 * direction of coefficient\nZicoSeq.plot(ZicoSeq.obj = zicoseq_out,\n             pvalue.type = 'p.adj.fdr')\n\n\n\n\n\n\n8.2.7 PhILR\nPhILR is a tree-based method that tests group-wise associations based on balances. A detailed introduction to this method is available in this Bioconductor tutorial.\n\n\n8.2.8 Comparison of methods\nAlthough the methods described above yield unidentical results, they are expected to agree on a few differentially abundant taxa. To draw more informed conclusions, it is good practice to compare the outcomes of different methods in terms of found features, their effect sizes and significances, as well as other method-specific aspects. Such comparative approach is outlined in this exercise."
  },
  {
    "objectID": "30_differential_abundance.html#daa-with-confounding",
    "href": "30_differential_abundance.html#daa-with-confounding",
    "title": "8  Differential Abundance",
    "section": "8.3 DAA with confounding",
    "text": "8.3 DAA with confounding\nConfounders can be defined as variables that are related to and affect the apparent dynamics between the response and the main independent variable. They are common in experimental studies. Generally, they can be classified into 3 groups:\n\nBiological confounders, such as age and sex\nTechnical confounders produced during sample collection, processing and analysis\nConfounders resulting from experimental models, such as batch effects and sample history\n\nControlling for confounders is an important practice to reach an unbiased conclusion. To perform causal inference, it is crucial that the method is able to include confounders in the model. This is not possible with statistical tests of general use, such as the Wilcoxon test. In contrast, methods that target DAA, such as those described in this chapter, allow controlling for confounders. In the following examples, we will perform DAA with a main independent variable and a few confounders.\n\n8.3.1 Selecting confounders\nIn addition to patient status, we will now control for two confounders: cohort and library size. The former is a categorical variable with three factors, whereas the latter is a discrete numerical variable. Remarkably, most DAA methods accept these two and several other data types.\nFor demonstration, library size is treated as a confounder and included in the formulas of the DAA methods. Although this is a satisfactory approach to control for uneven sequencing efforts across samples, rarefaction generally represents a better solution [@Schloss2023]. With that said, library size can be readily computed and added to the colData.\n\n# Compute and store library size in colData\ncolData(tse)$library_size &lt;- colSums(assay(tse, \"counts\"))\n\n\n\n8.3.2 ANCOM-BC\nHere, confounders can be added to the formula along with patient status, the main outcome variable. This way, the model evaluates whether differentially abundant taxa are associated with one of the variables when the other two are kept constant.\n\n# perform the analysis \nancombc2_out &lt;- ancombc2(tse,\n                         assay_name = \"counts\",\n                         fix_formula = \"patient_status + cohort + library_size\",\n                         p_adj_method = \"fdr\",\n                         lib_cut = 0,\n                         group = \"patient_status\", \n                         struc_zero = TRUE, \n                         neg_lb = TRUE,\n                         alpha = 0.05,\n                         # multi-group comparison is deactivated automatically\n                         global = TRUE)\n\nIn the output, each taxon is assigned with several effect sizes (lfc, which stands for log-fold change) and adjusted p-values (q). For categorical variables such as patient status and cohort, the statistics indicate whether the abundance of a given taxon is significantly different between the specified group (column name) and the reference group (the group that does not appear in the column names), whereas for numerical variables such as library size, they indicate whether the abundance of a given taxon varies with that variable.\n\nancombc2_out$res %&gt;%\n  dplyr::select(starts_with(c(\"taxon\", \"lfc\", \"q\"))) %&gt;%\n  arrange(q_patient_statusControl) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntaxon\nlfc_(Intercept)\nlfc_patient_statusControl\nlfc_cohortCohort_2\nlfc_cohortCohort_3\nlfc_library_size\nq_(Intercept)\nq_patient_statusControl\nq_cohortCohort_2\nq_cohortCohort_3\nq_library_size\n\n\n\n\nAkkermansia\n-0.8599\n0.2309\n0.2876\n0.4635\n0\n0\n0\n0\n0\n0.9147\n\n\nHungatella\n-0.0695\n-0.3270\n-0.1397\n-0.1151\n0\n0\n0\n0\n0\n0.0593\n\n\nRuminococcaceae_UCG-013\n-0.9344\n-0.3371\n0.6599\n-0.0231\n0\n0\n0\n0\n0\n0.0050\n\n\nBacteroides\n-0.3081\n-0.7575\n0.1482\n0.7615\n0\n0\n0\n0\n0\n0.9650\n\n\nEscherichia-Shigella\n-1.1600\n-0.5157\n1.3093\n0.2340\n0\n0\n0\n0\n0\n0.0397\n\n\n[Clostridium]_innocuum_group\n-0.7590\n0.7781\n-0.1629\n0.1688\n0\n0\n0\n0\n0\n0.0593\n\n\n\n\n\n\n\n8.3.3 LinDA\nAs in the previous method, confounders can be included in the formula with the main outcome variable.\n\nlinda_out &lt;- linda(as.data.frame(assay(tse, \"counts\")),\n                   as.data.frame(colData(tse)),\n                   formula = \"~ patient_status + cohort + library_size\",\n                   alpha = 0.05,\n                   prev.filter = 0,\n                   mean.abund.filter = 0)\n\n0  features are filtered!\nThe filtered data has  27  samples and  49  features will be tested!\nImputation approach is used.\nFit linear models ...\nCompleted.\n\n\nThe model returns an output for every variable included in the formula. Normally, only the results on the main outcome variable are relevant and can be retrieved as shown below. However, the statistics on the confounders can be similarly obtained by accessing the corresponding items from the output object.\n\n# Select results for the patient status\nlinda_res &lt;- linda_out$output$patient_statusControl\n\nlinda_res %&gt;%\n  filter(reject) %&gt;%\n  dplyr::select(log2FoldChange, stat, padj) %&gt;%\n  rownames_to_column(var = \"feature\") %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\nfeature\nlog2FoldChange\nstat\npadj\n\n\n\n\nFaecalibacterium\n-5.921\n-4.521\n0.0041\n\n\nErysipelatoclostridium\n3.743\n3.010\n0.0451\n\n\n[Ruminococcus]_gauvreauii_group\n4.240\n4.534\n0.0041\n\n\nBarnesiella\n-3.878\n-3.116\n0.0411\n\n\nRuminococcaceae_UCG-014\n-3.062\n-3.637\n0.0193\n\n\nButyricicoccus\n-2.357\n-3.127\n0.0411\n\n\n\n\n\nThe output shows effect sizes in terms of log-fold changes and a derived statistic (stat) as well as the corresponding adjusted p-values for differences in abundance of each taxon between the control and treated group.\n\n\n8.3.4 ZicoSeq\nFor this method, confounders can be added as a list to the adj.name argument.\n\nset.seed(123)\nzicoseq_out &lt;- ZicoSeq(feature.dat = as.matrix(assay(tse)),\n                       meta.dat = as.data.frame(colData(tse)),\n                       grp.name = \"patient_status\",\n                       adj.name = c(\"cohort\", \"library_size\"), \n                       feature.dat.type = \"count\",\n                       return.feature.dat = TRUE,\n                       prev.filter = 0,\n                       mean.abund.filter = 0,\n                       max.abund.filter = 0,\n                       perm.no = 999)\n\nFor sample size less than 40, posterior sampling will not be used!\n0  features are filtered!\nThe data has  27  samples and  49  features will be tested!\nOn average,  1  outlier counts will be replaced for each feature!\nFinding the references ...\nPermutation testing ...\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\n...................................................................................................\nCompleted!\n\n\nThe output shows the raw and adjusted p-values for clinical status.\n\nzicoseq_res &lt;- cbind.data.frame(p.raw = zicoseq_out$p.raw,\n                                p.adj.fdr = zicoseq_out$p.adj.fdr)\n\nzicoseq_res %&gt;%\n  filter(p.adj.fdr &lt; 0.05) %&gt;%\n  head() %&gt;%\n  knitr::kable()\n\n\n\n\n\np.raw\np.adj.fdr\n\n\n\n\nFaecalibacterium\n0.002\n0.0224\n\n\n[Clostridium]_innocuum_group\n0.003\n0.0238\n\n\n[Ruminococcus]_gauvreauii_group\n0.001\n0.0005\n\n\nRuminococcus_2\n0.002\n0.0300\n\n\nRuminococcaceae_UCG-014\n0.004\n0.0369\n\n\nCatabacter\n0.003\n0.0224"
  },
  {
    "objectID": "30_differential_abundance.html#additional-resources",
    "href": "30_differential_abundance.html#additional-resources",
    "title": "8  Differential Abundance",
    "section": "8.4 Additional resources",
    "text": "8.4 Additional resources\nDAA can be performed by several means. Although most of them provide similar functionality, some may be more suitable than others given a certain study design or data type. Commonly used DAA tools include:\n\nALDEx2 [@Gloor2016]\nANCOM [@Mandal2015]\nANCOMBC [@ancombc2020]\ncorncob [@Martin2021]\nDACOMP [@Brill2019]\nDESeq2 [@Love2014]\neBay [@Liu2020]\nedgeR [@Chen2016]\nfastANCOM [@fastANCOM2022]\nLDM [@Hu2020]\nlefser [@Khlebrodova2021]\nlimma [@Ritchie2015]\nLinDA [@Zhou2022]\nMaAsLin2 [@Mallick2020]\nmetagenomeSeq [@Paulson2017]\nOmnibus [@Omnibus2018]\nRAIDA [@Sohn2015]\nt-test\nWilcoxon test\nZicoSeq [@Yang2022]\nZINQ [@Ling2021]"
  },
  {
    "objectID": "40_machine_learning.html#supervised-machine-learning",
    "href": "40_machine_learning.html#supervised-machine-learning",
    "title": "9  Machine Learning",
    "section": "9.1 Supervised machine learning",
    "text": "9.1 Supervised machine learning\n“Supervised” means that the training data is introduced before. The training data contains labels (e.g., patient status), and the model is fitted based on the training data. After fitting, the model is utilized to predict labels of data whose labels are not known.\n\nlibrary(mia)\n\n# Load experimental data\ndata(peerj13075, package=\"mia\")\ntse &lt;- peerj13075\n\nLet’s first preprocess the data.\n\n# Agglomerate data\ntse &lt;- mergeFeaturesByRank(tse, rank = \"order\")\n\n# Apply CLR transform\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"clr\",\n                       MARGIN=\"samples\", pseudocount=1)\n\n# Get assay\nassay &lt;- assay(tse, \"clr\")\n# Transpose assay\nassay &lt;- t(assay)\n\n# Convert into data.frame\ndf &lt;- as.data.frame(assay)\n\n# Add labels to assay\nlabels &lt;- colData(tse)$Diet\nlabels &lt;- as.factor(labels)\ndf$diet &lt;- labels \n\ndf[5, 5]\n\n[1] -0.4612\n\n\nIn the example below, we use mikropml package. We try to predict the diet type based on the data.\n\nlibrary(mikropml)\n\n# Run random forest \nresults &lt;- run_ml(df, \"rf\", outcome_colname = \"diet\", \n                  kfold = 2, cv_times = 5, training_frac = 0.8)\n\n# Print result\nconfusionMatrix(data = results$trained_model$finalModel$predicted, \n                reference = results$trained_model$finalModel$y)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Mixed Veg\n     Mixed    13  10\n     Veg      10  14\n                                        \n               Accuracy : 0.574         \n                 95% CI : (0.422, 0.717)\n    No Information Rate : 0.511         \n    P-Value [Acc &gt; NIR] : 0.233         \n                                        \n                  Kappa : 0.149         \n                                        \n Mcnemar's Test P-Value : 1.000         \n                                        \n            Sensitivity : 0.565         \n            Specificity : 0.583         \n         Pos Pred Value : 0.565         \n         Neg Pred Value : 0.583         \n             Prevalence : 0.489         \n         Detection Rate : 0.277         \n   Detection Prevalence : 0.489         \n      Balanced Accuracy : 0.574         \n                                        \n       'Positive' Class : Mixed         \n                                        \n\n\nmikropml offers easier interface to caret package. However, we can also use it directly.\nLet’s use xgboost model which is another commonly used algorithm in bioinformatics.\n\n# Set seed for reproducibility\nset.seed(6358)\n\n# Specify train control\ntrain_control &lt;- trainControl(method = \"cv\", number = 5,\n                              classProbs = TRUE, \n                              savePredictions = \"final\",\n                              allowParallel = TRUE)\n\n# Specify hyperparameter tuning grid\ntune_grid &lt;- expand.grid(nrounds = c(50, 100, 200),\n                         max_depth = c(6, 8, 10),\n                         colsample_bytree = c(0.6, 0.8, 1),\n                         eta = c(0.1, 0.3),\n                         gamma = 0,\n                         min_child_weight = c(3, 4, 5),\n                         subsample = c(0.6, 0.8)\n                         )\n\n# Train the model, use LOOCV to evaluate performance\nmodel &lt;- train(x = assay, \n               y = labels, \n               method = \"xgbTree\",\n               objective = \"binary:logistic\",\n               trControl = train_control,\n               tuneGrid = tune_grid,\n               metric = \"AUC\",\n               verbosity = 0\n)\n\nLet’s create ROC curve which is a commonly used method in binary classification. For unbalanced data, you might want to plot precision-recall curve.\n\nlibrary(MLeval)\n\n# Calculate different evaluation metrics\nres &lt;- evalm(model, showplots = FALSE)\n\n# Use patchwork to plot ROC and precision-recall curve side-by-side\nlibrary(patchwork)\nres$roc + res$proc + \n    plot_layout(guides = \"collect\") & theme(legend.position = 'bottom')"
  },
  {
    "objectID": "40_machine_learning.html#unsupervised-machine-learning",
    "href": "40_machine_learning.html#unsupervised-machine-learning",
    "title": "9  Machine Learning",
    "section": "9.2 Unsupervised machine learning",
    "text": "9.2 Unsupervised machine learning\n“Unsupervised” means that the labels (e.g., patient status is not known), and patterns are learned based only the abundance table, for instance. Unsupervised ML is also known as a data mining where patterns are extracted from big datasets.\nFor unsupervised machine learning, please refer to chapters that are listed below:\n\nChapter @ref(clustering)\nChapter @ref(community-similarity)"
  },
  {
    "objectID": "23_multi-assay_analyses.html#cross-correlation",
    "href": "23_multi-assay_analyses.html#cross-correlation",
    "title": "10  Multi-Assay Analyses",
    "section": "10.1 Cross-correlation Analysis",
    "text": "10.1 Cross-correlation Analysis\nNext we can perform a cross-correlation analysis. Let us analyze if individual bacteria genera are correlated with concentrations of individual metabolites. This helps to answer the following question: “If bacterium X is present, is the concentration of metabolite Y lower or higher”?\n\n# Agglomerate microbiome data at family level\nmae[[1]] &lt;- mergeFeaturesByPrevalence(mae[[1]], rank = \"Family\")\n# Does log10 transform for microbiome data\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"log10\", pseudocount = TRUE)\n\n# Give unique names so that we do not have problems when we are creating a plot\nrownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]])\n\n# Cross correlates data sets\ncorrelations &lt;- testExperimentCrossCorrelation(mae, \n                                               experiment1 = 1,\n                                               experiment2 = 2,\n                                               assay.type1 = \"log10\", \n                                               assay.type2 = \"nmr\",\n                                               method = \"spearman\", \n                                               p_adj_threshold = NULL,\n                                               cor_threshold = NULL,\n                                               # Remove when mia is fixed\n                                               mode = \"matrix\",\n                                               sort = TRUE,\n                                               show_warnings = FALSE)\n\nNext, we create a heatmap depicting all cross-correlations between bacterial genera and metabolite concentrations.\n\nlibrary(ComplexHeatmap) \n\n# Create a heatmap and store it\nplot &lt;- Heatmap(correlations$cor,\n                # Print values to cells\n                cell_fun = function(j, i, x, y, width, height, fill) {\n                    # If the p-value is under threshold\n                    if( !is.na(correlations$p_adj[i, j]) & correlations$p_adj[i, j] &lt; 0.05 ){\n                        # Print \"X\"\n                        grid.text(sprintf(\"%s\", \"X\"), x, y, gp = gpar(fontsize = 10, col = \"#1dff00\"))\n                        }\n                    },\n                heatmap_legend_param = list(title = \"\", legend_height = unit(5, \"cm\"))\n                )\nplot"
  },
  {
    "objectID": "23_multi-assay_analyses.html#mofa",
    "href": "23_multi-assay_analyses.html#mofa",
    "title": "10  Multi-Assay Analyses",
    "section": "10.2 Multi-Omics Factor Analysis",
    "text": "10.2 Multi-Omics Factor Analysis\nMulti-Omics Factor Analysis (MOFA) is an unsupervised method for integrating multi-omic data sets in a downstream analysis [@Argelaguet2018]. It could be seen as a generalization of principal component analysis. Yet, with the ability to infer a latent (low-dimensional) representation, shared among the multiple (-omics) data sets in hand.\nWe use the R MOFA2 package for the analysis, and install the corresponding dependencies.\n\nlibrary(MOFA2)\n\n# For inter-operability between Python and R, and setting Python dependencies,\n# reticulate package is needed\nlibrary(reticulate)\n# Let us assume that these have been installed already.\n#reticulate::install_miniconda(force = TRUE)\n#reticulate::use_miniconda(condaenv = \"env1\", required = FALSE)\n#reticulate::py_install(packages = c(\"mofapy2\"), pip = TRUE, python_version=3.6)\n\nThe mae object could be used straight to create the MOFA model. Yet, we transform our assays since the model assumes normality per default. We can also use Poisson or Bernoulli distributions among others.\nNote that duplicates, such as “uncultured”, might appear when aggregating the microbiome data by a taxonomic rank. To check for duplicates, run any(duplicated(rownames(mae[[1]]))). If it returns TRUE, then the duplicates are present. We can add rownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]], make_unique=TRUE) to remove them.\n\nlibrary(MOFA2)\n# For simplicity, classify all high-fat diets as high-fat, and all the low-fat \n# diets as low-fat diets\ncolData(mae)$Diet &lt;- ifelse(colData(mae)$Diet == \"High-fat\" | \n                              colData(mae)$Diet == \"High-fat + XOS\", \n                            \"High-fat\", \"Low-fat\")\n\n# Transforming microbiome data with rclr\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"relabundance\")\nmae[[1]] &lt;- transformAssay(mae[[1]], assay.type = \"relabundance\", method = \"rclr\")\n\n# Transforming metabolomic data with log10\nmae[[2]] &lt;- transformAssay(mae[[2]], assay.type = \"nmr\",\n                            MARGIN = \"samples\",\n                            method = \"log10\")\n\n# Transforming biomarker data with z-transform\nmae[[3]] &lt;- transformAssay(mae[[3]], assay.type = \"signals\",\n                           MARGIN = \"features\",\n                           method = \"z\", pseudocount = 1)\n\n# Removing assays no longer needed\nassay(mae[[1]], \"counts\") &lt;- NULL\nassay(mae[[1]], \"log10\") &lt;- NULL\nassay(mae[[2]], \"nmr\") &lt;- NULL\nassay(mae[[3]], \"signals\") &lt;- NULL\n\n# Building our mofa model\nmodel &lt;- create_mofa_from_MultiAssayExperiment(mae,\n                                               groups = \"Diet\", \n                                               extract_metadata = TRUE)\nmodel\n\nUntrained MOFA model with the following characteristics: \n Number of views: 3 \n Views names: microbiota metabolites biomarkers \n Number of features (per view): 38 38 39 \n Number of groups: 2 \n Groups names: High-fat Low-fat \n Number of samples (per group): 20 20 \n \n\n\nModel options can be defined as follows:\n\nmodel_opts &lt;- get_default_model_options(model)\nmodel_opts$num_factors &lt;- 5\nhead(model_opts)\n\n$likelihoods\n microbiota metabolites  biomarkers \n \"gaussian\"  \"gaussian\"  \"gaussian\" \n\n$num_factors\n[1] 5\n\n$spikeslab_factors\n[1] FALSE\n\n$spikeslab_weights\n[1] FALSE\n\n$ard_factors\n[1] TRUE\n\n$ard_weights\n[1] TRUE\n\n\nTraining options for the model are defined in the following way:\n\ntrain_opts &lt;- get_default_training_options(model)\nhead(train_opts)\n\n$maxiter\n[1] 1000\n\n$convergence_mode\n[1] \"fast\"\n\n$drop_factor_threshold\n[1] -1\n\n$verbose\n[1] FALSE\n\n$startELBO\n[1] 1\n\n$freqELBO\n[1] 5\n\n\nThe model is then prepared with prepare_mofa and trained with run_mofa:\n\nmodel.prepared &lt;- prepare_mofa(\n  object = model,\n  model_options = model_opts\n)\n\n# Some systems may require the specification `use_basilisk = TRUE`\n# so it has been added to the following code\nmodel.trained &lt;- run_mofa(model.prepared, use_basilisk = TRUE)\n\n\n        #########################################################\n        ###           __  __  ____  ______                    ### \n        ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n        ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n        ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n        ###          | |  | | |__| | | / ____ \\|_|            ###\n        ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n        ###                                                   ### \n        ######################################################### \n       \n \n        \nuse_float32 set to True: replacing float64 arrays by float32 arrays to speed up computations...\n\nSuccessfully loaded view='microbiota' group='High-fat' with N=20 samples and D=38 features...\nSuccessfully loaded view='microbiota' group='Low-fat' with N=20 samples and D=38 features...\nSuccessfully loaded view='metabolites' group='High-fat' with N=20 samples and D=38 features...\nSuccessfully loaded view='metabolites' group='Low-fat' with N=20 samples and D=38 features...\nSuccessfully loaded view='biomarkers' group='High-fat' with N=20 samples and D=39 features...\nSuccessfully loaded view='biomarkers' group='Low-fat' with N=20 samples and D=39 features...\n\n\nModel options:\n- Automatic Relevance Determination prior on the factors: True\n- Automatic Relevance Determination prior on the weights: True\n- Spike-and-slab prior on the factors: False\n- Spike-and-slab prior on the weights: False\nLikelihoods:\n- View 0 (microbiota): gaussian\n- View 1 (metabolites): gaussian\n- View 2 (biomarkers): gaussian\n\n\n\n\n######################################\n## Training the model with seed 42 ##\n######################################\n\n\nELBO before training: -22013.97 \n\nIteration 1: time=0.00, ELBO=-4042.78, deltaELBO=17971.192 (81.63540032%), Factors=5\nIteration 2: time=0.00, Factors=5\nIteration 3: time=0.00, Factors=5\nIteration 4: time=0.00, Factors=5\nIteration 5: time=0.00, Factors=5\nIteration 6: time=0.00, ELBO=826.57, deltaELBO=4869.348 (22.11935643%), Factors=5\nIteration 7: time=0.00, Factors=5\nIteration 8: time=0.00, Factors=5\nIteration 9: time=0.00, Factors=5\nIteration 10: time=0.00, Factors=5\nIteration 11: time=0.00, ELBO=861.41, deltaELBO=34.839 (0.15825956%), Factors=5\nIteration 12: time=0.00, Factors=5\nIteration 13: time=0.00, Factors=5\nIteration 14: time=0.00, Factors=5\nIteration 15: time=0.00, Factors=5\nIteration 16: time=0.00, ELBO=867.97, deltaELBO=6.560 (0.02980063%), Factors=5\nIteration 17: time=0.00, Factors=5\nIteration 18: time=0.00, Factors=5\nIteration 19: time=0.00, Factors=5\nIteration 20: time=0.00, Factors=5\nIteration 21: time=0.00, ELBO=871.04, deltaELBO=3.072 (0.01395293%), Factors=5\nIteration 22: time=0.00, Factors=5\nIteration 23: time=0.00, Factors=5\nIteration 24: time=0.00, Factors=5\nIteration 25: time=0.00, Factors=5\nIteration 26: time=0.00, ELBO=872.88, deltaELBO=1.842 (0.00836904%), Factors=5\nIteration 27: time=0.00, Factors=5\nIteration 28: time=0.00, Factors=5\nIteration 29: time=0.00, Factors=5\nIteration 30: time=0.00, Factors=5\nIteration 31: time=0.00, ELBO=874.12, deltaELBO=1.240 (0.00563399%), Factors=5\nIteration 32: time=0.00, Factors=5\nIteration 33: time=0.00, Factors=5\nIteration 34: time=0.00, Factors=5\nIteration 35: time=0.00, Factors=5\nIteration 36: time=0.00, ELBO=875.02, deltaELBO=0.895 (0.00406653%), Factors=5\nIteration 37: time=0.00, Factors=5\nIteration 38: time=0.00, Factors=5\nIteration 39: time=0.00, Factors=5\nIteration 40: time=0.00, Factors=5\nIteration 41: time=0.00, ELBO=875.70, deltaELBO=0.678 (0.00308090%), Factors=5\nIteration 42: time=0.00, Factors=5\nIteration 43: time=0.00, Factors=5\nIteration 44: time=0.00, Factors=5\nIteration 45: time=0.00, Factors=5\nIteration 46: time=0.00, ELBO=876.23, deltaELBO=0.531 (0.00241399%), Factors=5\nIteration 47: time=0.00, Factors=5\nIteration 48: time=0.00, Factors=5\nIteration 49: time=0.00, Factors=5\nIteration 50: time=0.00, Factors=5\nIteration 51: time=0.00, ELBO=876.66, deltaELBO=0.431 (0.00195876%), Factors=5\nIteration 52: time=0.00, Factors=5\nIteration 53: time=0.00, Factors=5\nIteration 54: time=0.00, Factors=5\nIteration 55: time=0.00, Factors=5\nIteration 56: time=0.00, ELBO=877.02, deltaELBO=0.355 (0.00161258%), Factors=5\nIteration 57: time=0.00, Factors=5\nIteration 58: time=0.00, Factors=5\nIteration 59: time=0.00, Factors=5\nIteration 60: time=0.00, Factors=5\nIteration 61: time=0.00, ELBO=877.31, deltaELBO=0.299 (0.00135840%), Factors=5\nIteration 62: time=0.00, Factors=5\nIteration 63: time=0.00, Factors=5\nIteration 64: time=0.00, Factors=5\nIteration 65: time=0.00, Factors=5\nIteration 66: time=0.00, ELBO=877.57, deltaELBO=0.259 (0.00117674%), Factors=5\nIteration 67: time=0.00, Factors=5\nIteration 68: time=0.00, Factors=5\nIteration 69: time=0.00, Factors=5\nIteration 70: time=0.00, Factors=5\nIteration 71: time=0.00, ELBO=877.80, deltaELBO=0.224 (0.00101856%), Factors=5\nIteration 72: time=0.00, Factors=5\nIteration 73: time=0.00, Factors=5\nIteration 74: time=0.00, Factors=5\nIteration 75: time=0.00, Factors=5\nIteration 76: time=0.00, ELBO=878.00, deltaELBO=0.199 (0.00090239%), Factors=5\nIteration 77: time=0.00, Factors=5\nIteration 78: time=0.00, Factors=5\nIteration 79: time=0.00, Factors=5\nIteration 80: time=0.00, Factors=5\nIteration 81: time=0.00, ELBO=878.17, deltaELBO=0.177 (0.00080298%), Factors=5\nIteration 82: time=0.00, Factors=5\nIteration 83: time=0.00, Factors=5\nIteration 84: time=0.00, Factors=5\nIteration 85: time=0.00, Factors=5\nIteration 86: time=0.00, ELBO=878.33, deltaELBO=0.161 (0.00073358%), Factors=5\nIteration 87: time=0.00, Factors=5\nIteration 88: time=0.00, Factors=5\nIteration 89: time=0.00, Factors=5\nIteration 90: time=0.00, Factors=5\nIteration 91: time=0.00, ELBO=878.48, deltaELBO=0.144 (0.00065322%), Factors=5\nIteration 92: time=0.00, Factors=5\nIteration 93: time=0.00, Factors=5\nIteration 94: time=0.00, Factors=5\nIteration 95: time=0.00, Factors=5\nIteration 96: time=0.00, ELBO=878.61, deltaELBO=0.132 (0.00059933%), Factors=5\nIteration 97: time=0.00, Factors=5\nIteration 98: time=0.00, Factors=5\nIteration 99: time=0.00, Factors=5\nIteration 100: time=0.00, Factors=5\nIteration 101: time=0.00, ELBO=878.73, deltaELBO=0.122 (0.00055240%), Factors=5\nIteration 102: time=0.00, Factors=5\nIteration 103: time=0.00, Factors=5\nIteration 104: time=0.00, Factors=5\nIteration 105: time=0.00, Factors=5\nIteration 106: time=0.00, ELBO=878.84, deltaELBO=0.112 (0.00051068%), Factors=5\nIteration 107: time=0.00, Factors=5\nIteration 108: time=0.00, Factors=5\nIteration 109: time=0.00, Factors=5\nIteration 110: time=0.00, Factors=5\nIteration 111: time=0.00, ELBO=878.95, deltaELBO=0.103 (0.00046697%), Factors=5\nIteration 112: time=0.00, Factors=5\nIteration 113: time=0.00, Factors=5\nIteration 114: time=0.00, Factors=5\nIteration 115: time=0.00, Factors=5\nIteration 116: time=0.00, ELBO=879.04, deltaELBO=0.095 (0.00042938%), Factors=5\n\nConverged!\n\n\n\n#######################\n## Training finished ##\n#######################\n\n\nSaving model in /tmp/Rtmphy6qx4/mofa_20231020-133458.hdf5...\n\n\nThe explained variance is visualized with the plot_variance_explained function:\n\nlibrary(patchwork)\nlibrary(ggplot2)\n\nplot_list &lt;- plot_variance_explained(model.trained,\n                                     x = \"view\", y = \"factor\",\n                                     plot_total = T)\n\nwrap_plots(plot_list, nrow = 2) +\n  plot_annotation(title = \"Variance Explained per factor and assay\",\n                  theme = theme(plot.title = element_text(hjust = 0.5)))\n\n\n\n\nThe top weights for each assay using all five factors:\n\ncustom_plotter &lt;- function(name) {\n  \n  p &lt;- plot_top_weights(model.trained,\n                        view = name,\n                        factors = \"all\",\n                        nfeatures = 10) +\n    labs(title = paste0(\"Top weights of the \", name, \" assay\"))\n  \n}\n\nplot_list &lt;- lapply(c(\"microbiota\", \"metabolites\", \"biomarkers\"), custom_plotter)\n\nwrap_plots(plot_list, nrow = 3) & theme(text = element_text(size = 8))\n\n\n\n\nMore tutorials and examples of using the package are found at link"
  },
  {
    "objectID": "19_visualization_techniques.html#pre-analysis-exploration",
    "href": "19_visualization_techniques.html#pre-analysis-exploration",
    "title": "11  Visualization",
    "section": "11.1 Pre-analysis exploration",
    "text": "11.1 Pre-analysis exploration\n\n11.1.1 Accessing row and column data\nSCE and TreeSE objects contain multiple layers of information in the form of rows, columns and meta data. The scater package supports in accessing, modifying and graphing the meta data related to features as well as samples.\n\n# list row meta data\nnames(rowData(tse))\n\n[1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n\n# list column meta data\nnames(colData(tse))\n\n[1] \"X.SampleID\"               \"Primer\"                  \n[3] \"Final_Barcode\"            \"Barcode_truncated_plus_T\"\n[5] \"Barcode_full_length\"      \"SampleType\"              \n[7] \"Description\"             \n\n\nSuch meta data can be directly plotted with the functions plotRowData and plotColData.\n\n# obtain QC data\ntse &lt;- addPerCellQC(tse)\ntse &lt;- addPerFeatureQC(tse)\n# plot QC Mean against Species\nplotRowData(tse, \"mean\", \"Species\") +\n  theme(axis.text.x = element_blank()) +\n  labs(x = \"Species\", y = \"QC Mean\")\n\n\n\n# plot QC Sum against Sample ID, colour-labeled by Sample Type\nplotColData(tse, \"sum\", \"X.SampleID\", colour_by = \"SampleType\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Sample ID\", y = \"QC Sum\")\n\n\n\n\nAlternatively, they can be converted to a data.frame object and passed to ggplot.\n\n# store colData into a data frame\ncoldata &lt;- as.data.frame(colData(tse))\n# plot Number of Samples against Sampling Site\nggplot(coldata, aes(x = SampleType)) +\n  geom_bar(width = 0.5) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Sampling Site\",\n       y = \"Number of Samples\")\n\n\n\n\nFurther methods of application can be found in the chapters @ref(qc) and @ref(richness) and in a few external tutorials with open data. Additionally, rowData and colData allow manipulation and subsetting of large data sets into smaller units, as explained in chapter @ref(datamanipulation).\n\n\n11.1.2 Viewing abundance and prevalence patterns\nPrior-to-analysis exploration may involve questions such as how microorganisms are distributed across samples (abundance) and what microorganisms are present in most of the samples (prevalence). The information on abundance and prevalence can be summarized into a jitter or density plot and a tree, respectively, with the miaViz package.\nSpecifically, the functions plotAbundance, plotAbundanceDensity and plotRowTree are used, and examples on their usage are discussed throughout chapter @ref(quality-control)."
  },
  {
    "objectID": "19_visualization_techniques.html#diversity-estimation",
    "href": "19_visualization_techniques.html#diversity-estimation",
    "title": "11  Visualization",
    "section": "11.2 Diversity estimation",
    "text": "11.2 Diversity estimation\nAlpha diversity is commonly measured as one of the diversity indices explained in chapter @ref(community-diversity). Because the focus lies on each sample separately, one-dimensional plots, such as scatter, violin and box plots, are suitable.\nBeta diversity is generally evaluated as one of the dissimilarity indices reported in chapter @ref(community-similarity). Unlike alpha diversity, samples are compared collectively to estimate the heterogeneity across them, therefore multidimensional plots, such as Shepard and ordination plots are suitable.\n\n\n\n\n\n\n\n\n\nalpha diversity\nbeta diversity\n\n\n\n\nused metrics\ndiversity indices\ndissimilarity indices\n\n\nmetric dimensionality\none-dimensional\nmultidimensional\n\n\nsuitable visualization\nscatter, violin, box plots\nShepard, ordination plots\n\n\n\nIn conclusion, visualization techniques for alpha and beta diversity significantly differ from one another.\n\n11.2.1 Alpha diversity with scatter, violin and box plots\nThe basic method to visualize the diversity values assigned to the different samples in a TSE object includes the following, where each data point represents one sample:\n\n# estimate shannon diversity index\ntse &lt;- mia::estimateDiversity(tse, \n                              assay.type = \"counts\",\n                              index = \"shannon\", \n                              name = \"shannon\")\n# plot shannon diversity index, colour-labeled by Sample Type\nplotColData(tse, \"shannon\", colour_by = \"SampleType\")\n\n\n\n\nThe several indices available for the evaluation of alpha diversity often return slightly divergent results, which can be visually compared with a multiple violin or box plot. For this purpose, plotColData (for violin plots) or ggplot (for box plots) are recursively applied to a number of diversity indices with the function lapply and the multi-panel plotting functionality of the patchwork package is then exploited.\n\n# estimate faith diversity index\ntse &lt;- mia::estimateFaith(tse,\n                          assay.type = \"counts\")\n# store colData into a data frame\ncoldata &lt;- as.data.frame(colData(tse))\n# generate plots for shannon and faith indices\n# and store them into a list\nplots &lt;- lapply(c(\"shannon\", \"faith\"),\n                function(i) ggplot(coldata, aes_string(y = i)) +\n                  geom_boxplot() +\n                  theme(axis.text.x = element_blank(),\n                        axis.ticks.x = element_blank()))\n# combine plots with patchwork\nplots[[1]] + plots[[2]]\n\n\n\n\nThe analogous output in the form of a violin plot is obtained in chapter @ref(faith-diversity). In addition, box plots that group samples according to certain information, such as origin, sex, age and health condition, can be labeled with p-values for significant differences with the package ggsignif package, as shown in chapter @ref(estimate-diversity).\n\n\n11.2.2 Beta diversity with Shepard and coordination plots\nThe scater package offers the general function plotReducedDim. In its basic form, it takes a TSE object and the results on sample similarity stored in the same object, which can be evaluated with the following coordination methods:\n\nrunMDS\nrunNMDS\nrunPCA\nrunTSNE\nrunUMAP\n\nSince these clustering techniques allow for multiple coordinates or components, coordination plots can also span multiple dimensions, which is explained in chapter @ref(extras).\n\n# perform NMDS coordination method\ntse &lt;- runNMDS(tse,\n               FUN = vegan::vegdist,\n               name = \"NMDS\")\n\ninitial  value 47.733208 \niter   5 value 33.853364\niter  10 value 32.891200\nfinal  value 32.823570 \nconverged\n\n# plot results of a 2-component NMDS on tse,\n# coloured-scaled by shannon diversity index\nplotReducedDim(tse, \"NMDS\", colour_by = \"shannon\")\n\n\n\n\nMultiple combinations of coordinates or dimensions can also be integrated into a multi-panel arrangement.\n\n# perform MDS coordination method\ntse &lt;- runMDS(tse,\n              FUN = vegan::vegdist,\n              method = \"bray\",\n              name = \"MDS\",\n              assay.type = \"counts\",\n              ncomponents = 3)\n# plot results of a 3-component MDS on tse,\n# coloured-scaled by faith diversity index\nplotReducedDim(tse, \"MDS\", ncomponents = c(1:3), colour_by = \"faith\")\n\n\n\n\nSimilarly to iterating plotColData over indices of alpha diversity, lapply can be used in combination with patchwork to recursively apply plotReducedDim and visually compare results among various coordination methods.\n\n# generate plots for MDS and NMDS methods\n# and store them into a list\nplots &lt;- lapply(c(\"MDS\", \"NMDS\"),\n                plotReducedDim,\n                object = tse,\n                colour_by = \"shannon\")\n# combine plots with patchwork\nplots[[1]] + plots[[2]] +\n  plot_layout(guides = \"collect\")\n\n\n\n\nFor similar examples, readers are referred to chapter @ref(community-similarity). Further material on the graphic capabilities of patchwork is available in its official package tutorial."
  },
  {
    "objectID": "19_visualization_techniques.html#statistical-analysis",
    "href": "19_visualization_techniques.html#statistical-analysis",
    "title": "11  Visualization",
    "section": "11.3 Statistical analysis",
    "text": "11.3 Statistical analysis\n\n11.3.1 Heatmaps\nAs described in chapter @ref(visual-composition), bar plots and heatmaps can offer a useful insight into the composition of a community. Simple methods involve the functions plotAbundance and geom_tile in combination with scale_fill_gradientn from the packages miaViz and ggplot2, respectively.\nFor instance, below the composition of multiple samples (x axis) is reported in terms of relative abundances (y axis) for the top 10 taxa at the Order rank. Bar plots and heatmaps with analogous information at the Phylum level are available in the aforementioned chapter.\n\n# agglomerate tse by Order\ntse_order &lt;- mergeFeaturesByRank(tse,\n                                rank = \"Order\",\n                                onRankOnly = TRUE)\n# transform counts into relative abundance\ntse_order &lt;- transformAssay(tse_order,\n                              assay.type = \"counts\",\n                              method = \"relabundance\")\n# get top orders\ntop_taxa &lt;- getTopFeatures(tse_order,\n                       top = 10,\n                       assay.type = \"relabundance\")\n# leave only names for top 10 orders and label the rest with \"Other\"\norder_renamed &lt;- lapply(rowData(tse_order)$Order,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\nrowData(tse_order)$Order &lt;- as.character(order_renamed)\n# plot composition as a bar plot\nplotAbundance(tse_order,\n              assay.type = \"relabundance\",\n              rank = \"Order\",\n              order_rank_by = \"abund\",\n              order_sample_by = \"Clostridiales\")\n\n\n\n\nTo add a sample annotation, you can combine plots that you get from the output of plotAbundance.\n\n# Create plots\nplots &lt;- plotAbundance(tse_order,\n            assay.type = \"relabundance\",\n        rank = \"Order\",\n            order_rank_by = \"abund\",\n        order_sample_by = \"Clostridiales\",\n            features = \"SampleType\")\n\n# Modify the legend of the first plot to be smaller \nplots[[1]] &lt;- plots[[1]] +\n    theme(legend.key.size = unit(0.3, 'cm'),\n          legend.text = element_text(size = 6),\n          legend.title = element_text(size = 8))\n\n# Modify the legend of the second plot to be smaller \nplots[[2]] &lt;- plots[[2]] +\n    theme(legend.key.height = unit(0.3, 'cm'),\n          legend.key.width = unit(0.3, 'cm'),\n          legend.text = element_text(size = 6),\n          legend.title = element_text(size = 8),\n          legend.direction = \"vertical\")\n\n# Load required packages\nlibrary(ggpubr)\nlibrary(patchwork) \n# Combine legends\nlegend &lt;- wrap_plots(as_ggplot(get_legend(plots[[1]])), as_ggplot(get_legend(plots[[2]])), ncol = 1) \n\n# Remove legends from the plots\nplots[[1]] &lt;- plots[[1]] + theme(legend.position = \"none\")\nplots[[2]] &lt;- plots[[2]] + theme(legend.position = \"none\", axis.title.x=element_blank()) \n\n# Combine plots\nplot &lt;- wrap_plots(plots[[2]], plots[[1]], ncol = 1, heights = c(2, 10))\n# Combine the plot with the legend\nwrap_plots(plot, legend, nrow = 1, widths = c(2, 1))\n\n\n\n\nFor more sophisticated visualizations than those produced with plotAbundance and ggplot2, the packages pheatmap and sechm provide methods to include feature and sample clusters in a heatmap, along with further functionality.\n\n# Agglomerate tse by phylum\ntse_phylum &lt;- mergeFeaturesByRank(tse,\n                                rank = \"Phylum\",\n                                onRankOnly = TRUE)\n\n# Add clr-transformation on samples\ntse_phylum &lt;- transformAssay(tse_phylum, MARGIN = \"samples\", method = \"clr\", assay.type = \"counts\", pseudocount=1)\n\n# Add z-transformation on features (taxa)\ntse_phylum &lt;- transformAssay(tse_phylum, assay.type = \"clr\",\n                              MARGIN = \"features\", \n                              method = \"z\", name = \"clr_z\")\n\n# Take subset: only samples from feces, skin, or tongue\ntse_phylum_subset &lt;- tse_phylum[ , tse_phylum$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Add clr-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, method = \"clr\",\n                                     MARGIN=\"samples\",\n                                     assay.type = \"counts\", pseudocount=1)\n# Does z-transformation\ntse_phylum_subset &lt;- transformAssay(tse_phylum_subset, assay.type = \"clr\",\n                                     MARGIN = \"features\", \n                                     method = \"z\", name = \"clr_z\")\n\n# Get n most abundant taxa, and subsets the data by them\ntop_taxa &lt;- getTopFeatures(tse_phylum_subset, top = 20)\ntse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ]\n\n# Gets the assay table\nmat &lt;- assay(tse_phylum_subset, \"clr_z\")\n\n# Creates the heatmap\npheatmap(mat)\n\n\n\n\nWe can cluster both samples and features hierarchically and add them to the x and y axes of the heatmap, respectively.\n\n# Hierarchical clustering\ntaxa_hclust &lt;- hclust(dist(mat), method = \"complete\")\n\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\n\n# Plot taxa tree\ntaxa_tree &lt;- ggtree(taxa_tree) + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of taxa in plot\ntaxa_ordered &lt;- get_taxa_name(taxa_tree)\n\n# to view the tree, run\n# taxa_tree\n\nBased on phylo tree, we decide to create three clusters.\n\n# Creates clusters\ntaxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3)\n\n# Converts into data frame\ntaxa_clusters &lt;- data.frame(clusters = taxa_clusters)\ntaxa_clusters$clusters &lt;- factor(taxa_clusters$clusters)\n\n# Order data so that it's same as in phylo tree\ntaxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE] \n\n# Prints taxa and their clusters\ntaxa_clusters\n\n                 clusters\nChloroflexi             3\nActinobacteria          3\nCrenarchaeota           3\nPlanctomycetes          3\nGemmatimonadetes        3\nThermi                  3\nAcidobacteria           3\nSpirochaetes            2\nFusobacteria            2\nSR1                     2\nCyanobacteria           2\nProteobacteria          2\nSynergistetes           2\nLentisphaerae           1\nBacteroidetes           1\nVerrucomicrobia         1\nTenericutes             1\nFirmicutes              1\nEuryarchaeota           1\nSAR406                  1\n\n\nThe information on the clusters is then added to the feature meta data.\n\n# Adds information to rowData\nrowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ]\n\n# Prints taxa and their clusters\nrowData(tse_phylum_subset)$clusters\n\n [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1\nLevels: 1 2 3\n\n\nSimilarly, samples are hierarchically grouped into clusters, the most suitable number of clusters for the plot is selected and the new information is stored into the sample meta data.\n\n# Hierarchical clustering\nsample_hclust &lt;- hclust(dist(t(mat)), method = \"complete\")\n\n# Creates a phylogenetic tree\nsample_tree &lt;- as.phylo(sample_hclust)\n\n# Plot sample tree\nsample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() + \n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of samples in plot\nsamples_ordered &lt;- rev(get_taxa_name(sample_tree))\n\n# to view the tree, run\n# sample_tree\n\n# Creates clusters\nsample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3))\n\n# Converts into data frame\nsample_data &lt;- data.frame(clusters = sample_clusters)\n\n# Order data so that it's same as in phylo tree\nsample_data &lt;- sample_data[samples_ordered, , drop = FALSE] \n\n# Order data based on \ntse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)]\n\n# Add sample type data\nsample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType)\n\nsample_data\n\n        clusters sample_types\nM11Plmr        2         Skin\nM31Plmr        2         Skin\nF21Plmr        2         Skin\nM31Fcsw        1        Feces\nM11Fcsw        1        Feces\nTS28           3        Feces\nTS29           3        Feces\nM31Tong        3       Tongue\nM11Tong        3       Tongue\n\n\nNow we can create heatmap with additional annotations.\n\n# Determines the scaling of colorss\n# Scale colors\nbreaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))), \n              length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(mat, annotation_row = taxa_clusters, \n         annotation_col = sample_data,\n         breaks = breaks,\n         color = colors)\n\n\n\n\nThe package sechm allows for further visual capabilities and flexibility. In this case, the clustering step is automatically performed by the plotting function and does not need to be executed in advance.\n\n# Stores annotation colros to metadata\nmetadata(tse_phylum_subset)$anno_colors$SampleType &lt;- c(Feces = \"blue\", \n                                                        Skin = \"red\", \n                                                        Tongue = \"gray\")\n\n# Create a plot\nsechm(tse_phylum_subset, \n      features = rownames(tse_phylum_subset), \n      assayName = \"clr\", \n      do.scale = TRUE, \n      top_annotation = c(\"SampleType\"), \n      gaps_at = \"SampleType\",\n      cluster_cols = TRUE, cluster_rows = TRUE)\n\n\n\n\nIt is also possible to create an analogous heatmap by just using the ggplot2 package. However, a relatively long code is required to generate an identical output.\n\n# Add feature names to column as a factor\ntaxa_clusters$Feature &lt;- rownames(taxa_clusters)\ntaxa_clusters$Feature &lt;- factor(taxa_clusters$Feature, levels = taxa_clusters$Feature)\n\n# Create annotation plot\nrow_annotation &lt;- ggplot(taxa_clusters) + \n  geom_tile(aes(x = NA, y = Feature, fill = clusters)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank(),\n        axis.title.y=element_blank(),\n        axis.title.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        plot.margin=margin(0,0,0,0),\n        ) +\n      labs(fill = \"Clusters\", x = \"Clusters\")\n\n# to view the notation, run\n# row_annotation\n\n# Add sample names to one of the columns\nsample_data$sample &lt;- factor(rownames(sample_data), levels = rownames(sample_data))\n\n# Create annotation plot\nsample_types_annotation &lt;- ggplot(sample_data) +\n  scale_y_discrete(position = \"right\", expand = c(0,0)) +\n  geom_tile(aes(y = NA, x = sample, fill = sample_types)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.title.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        plot.margin=margin(0,0,0,0),\n        axis.title.y.right = element_text(angle=0, vjust = 0.5)\n        ) +\n      labs(fill = \"Sample types\", y = \"Sample types\")\n# to view the notation, run\n# sample_types_annotation\n\n# Create annotation plot\nsample_clusters_annotation &lt;- ggplot(sample_data) +\n  scale_y_discrete(position = \"right\", expand = c(0,0)) +\n  geom_tile(aes(y = NA, x = sample, fill = clusters)) +\n  coord_equal(ratio = 1) +\n  theme(\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.title.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        plot.margin=margin(0,0,0,0),\n        axis.title.y.right = element_text(angle=0, vjust = 0.5)\n        ) +\n      labs(fill = \"Clusters\", y = \"Clusters\")\n# to view the notation, run\n# sample_clusters_annotation\n\n# Order data based on clusters and sample types\nmat &lt;- mat[unfactor(taxa_clusters$Feature), unfactor(sample_data$sample)]\n\n# ggplot requires data in melted format\nmelted_mat &lt;- melt(mat)\ncolnames(melted_mat) &lt;- c(\"Taxa\", \"Sample\", \"clr_z\")\n\n# Determines the scaling of colorss\nmaxval &lt;- round(max(abs(melted_mat$clr_z)))\nlimits &lt;- c(-maxval, maxval)\nbreaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5)\ncolours &lt;- c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\")\n\nheatmap &lt;- ggplot(melted_mat) + \n  geom_tile(aes(x = Sample, y = Taxa, fill = clr_z)) +\n  theme(\n    axis.title.y=element_blank(),\n    axis.title.x=element_blank(),\n    axis.ticks.y=element_blank(),\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n    \n    plot.margin=margin(0,0,0,0), # removes margins\n    legend.key.height= unit(1, 'cm')\n    ) +\n  scale_fill_gradientn(name = \"CLR + Z transform\", \n                       breaks = breaks, \n                       limits = limits, \n                       colours = colours) + \n  scale_y_discrete(position = \"right\")\n\nheatmap\n\n\n\n\n\nlibrary(patchwork)\n\n# Create layout\ndesign &lt;- c(\n  patchwork::area(3, 1, 4, 1),\n  patchwork::area(1, 2, 1, 3),\n  patchwork::area(2, 2, 2, 3),\n  patchwork::area(3, 2, 4, 3)\n)\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- row_annotation + sample_clusters_annotation +\n                         sample_types_annotation +\n             heatmap  +\n    plot_layout(design = design, guides = \"collect\",\n                # Specify layout, collect legends\n                \n                # Adjust widths and heights to align plots.\n                # When annotation plot is larger, it might not fit into\n        # its column/row.\n                # Then you need to make column/row larger.\n                \n                # Relative widths and heights of each column and row:\n                # Currently, the width of the first column is 15 % and the height of\n                # first two rows are 30 % the size of others\n                \n                # To get this work most of the times, you can adjust all sizes to be 1, i.e. equal, \n                # but then the gaps between plots are larger.\n                widths = c(0.15, 1, 1),\n                heights = c(0.3, 0.3, 1, 1))\n\n# plot\n\n\n# Create layout\ndesign &lt;- c(\n  patchwork::area(4, 1, 5, 1),\n  patchwork::area(4, 2, 5, 2),\n  patchwork::area(1, 3, 1, 4),\n  patchwork::area(2, 3, 2, 4),\n  patchwork::area(3, 3, 3, 4),\n  patchwork::area(4, 3, 5, 4)\n)\n\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- taxa_tree + \n  row_annotation +\n  sample_tree + \n  sample_clusters_annotation +\n  sample_types_annotation +\n  heatmap +\n    plot_layout(design = design, guides = \"collect\", # Specify layout, collect legends\n                widths = c(0.2, 0.15, 1, 1, 1),\n                heights = c(0.1, 0.15, 0.15, 0.25, 1, 1))\n\nplot\n\nHeatmaps find several other applications in biclustering and multi-assay analyses. These are discussed further in chapters @ref(clustering) and @ref(multi-assay-analyses)."
  },
  {
    "objectID": "80_training.html",
    "href": "80_training.html",
    "title": "(PART) Training",
    "section": "",
    "text": "Training\nThe page provides practical information to support training and self-study."
  },
  {
    "objectID": "80_training.html#checklist",
    "href": "80_training.html#checklist",
    "title": "(PART) Training",
    "section": "Checklist",
    "text": "Checklist\nBrief checklist to prepare for training (see below for links).\n\nInstall the recommended software\nIf the time allows, watch the short online videos and familiarize with the other available material\nJoin Gitter online chat for support"
  },
  {
    "objectID": "80_training.html#software",
    "href": "80_training.html#software",
    "title": "(PART) Training",
    "section": "Recommended software",
    "text": "Recommended software\nWe recommend to install and set up the relevant software packages on your own computer as this will support later use. The essential components to install include:\n\nR (the latest official release)\nRStudio; choose “Rstudio Desktop” to download the latest version. Check the Rstudio home page for more information. RStudio is optional.\nInstall key R packages (Section @ref(packages) provides an installation script)\nAfter a successful installation you can consider trying out examples from Section @ref(exercises) already before training. You can run the workflows by simply copy-pasting examples. You can then test further examples from this tutorial, modifying and applying these techniques to your own data. Plain source code for the individual chapters of this book are available via Github"
  },
  {
    "objectID": "80_training.html#material",
    "href": "80_training.html#material",
    "title": "(PART) Training",
    "section": "Study material",
    "text": "Study material\nWe encourage to familiarize with the material and test examples in advance but this is optional:\n\nIntroduction to data analysis with R and Bioconductor (for beginners with R)\nShort online videos on microbiome data science with R/Bioconductor\nQuarto presentations\nOrchestrating Microbiome Analysis with Bioconductor (OMA) (this book)\nOther outreach material\nExercises for self-study\nResources and links to complementary external material"
  },
  {
    "objectID": "80_training.html#support-and-resources",
    "href": "80_training.html#support-and-resources",
    "title": "(PART) Training",
    "section": "Support and resources",
    "text": "Support and resources\nFor online support on installation and other matters, join us at Gitter.\nYou are also welcome to connect through various channels with our broader developer and user community."
  },
  {
    "objectID": "80_training.html#further-reading",
    "href": "80_training.html#further-reading",
    "title": "(PART) Training",
    "section": "Further reading",
    "text": "Further reading\nThe following online books provide good general data science background:\n\n(Data science basics in R](https://r4ds.had.co.nz)\n(Modern Statistics for Modern Biology)[https://www.huber.embl.de/msmb/] open access book (Holmes S, Huber W)\nThe Bioconductor project (background on the Bioconductor project; Carpentries workshop)"
  },
  {
    "objectID": "80_training.html#coc",
    "href": "80_training.html#coc",
    "title": "(PART) Training",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nWe support the Bioconductor Code of Conduct. The community values an open approach to science that promotes\n\nsharing of ideas, code, software and expertise\na kind and welcoming environment, diversity and inclusivity\ncommunity contributions and collaboration"
  },
  {
    "objectID": "95_resources.html#data-containers",
    "href": "95_resources.html#data-containers",
    "title": "12  Resources",
    "section": "12.1 Data containers",
    "text": "12.1 Data containers\n\n12.1.1 Data container documentation\n\nSingleCellExperiment [@R_SingleCellExperiment]\n\nOnline tutorial\nProject page\n\nSummarizedExperiment [@R_SummarizedExperiment]\n\nOnline tutorial\nProject page\n\nTreeSummarizedExperiment [@R_TreeSummarizedExperiment]\n\nOnline tutorial\nProject page\nPublication: [@Huang2021]\n\nMultiAssayExperiment [@Ramos2017]\n\nOnline tutorial\nProject page\n\n\n\n\n12.1.2 Other relevant containers\n\nDataFrame which behaves similarly to data.frame, yet efficient and fast when used with large datasets.\nDNAString along with DNAStringSet,RNAString and RNAStringSet efficient storage and handling of long biological sequences are offered within the Biostrings package [@R_Biostrings].\nGenomicRanges ([@GenomicRanges2013]) offers an efficient representation and manipulation of genomic annotations and alignments, see e.g. GRanges and GRangesList at An Introduction to the GenomicRangesPackage.\n\nNGS Analysis Basics provides a walk-through of the above-mentioned features with detailed examples.\n\n\n12.1.3 phyloseq: an alternative container for microbiome data\nThe phyloseq package and class became the first widely used data container for microbiome data science in R. Many methods for taxonomic profiling data are readily available for this class. We provide here a short description how phyloseq and *Experiment classes relate to each other.\nassays : This slot is similar to otu_table in phyloseq. In a SummarizedExperiment object multiple assays, raw counts, transformed counts can be stored. See also [-@Ramos2017] for storing data from multiple experiments such as RNASeq, Proteomics, etc. rowData : This slot is similar to tax_table in phyloseq to store taxonomic information. colData : This slot is similar to sample_data in phyloseq to store information related to samples. rowTree : This slot is similar to phy_tree in phyloseq to store phylogenetic tree.\nIn this book, you will encounter terms such as FeatureIDs and SampleIDs. FeatureIDs : These are basically OTU/ASV ids which are row names in assays and rowData. SampleIDs : As the name suggests, these are sample ids which are column names in assays and row names in colData. FeatureIDs and SampleIDs are used but the technical terms rownames and colnames are encouraged to be used, since they relate to actual objects we work with.\n\n\n12.1.3.1 Benchmarking TreeSE with phyloseq\nTreeSE objects can be converted into phyloseq objects and vice versa, therefore it is possible to compare the two containers in terms of computational efficiency. Remarkably, TreeSE and phyloseq were benchmarked against one another in mia v1.2.3 and phyloseq v1.38.0, respectively. 5 standard microbiome analysis operationswere applied to 4 datasets of varying size with both containers. In a nutshell, TreeSE and phyloseq showed a similar performance for datasets of small and medium size for most of the operations. However, TreeSE performed more efficiently as the size of the datasets increased. Further details on such results can be found in the benchmarking repository.\n\n\n12.1.3.2 Resources on phyloseq\nThe phyloseq container provides analogous methods to TreeSE. The following material can be used to familiarize with such alternative methods:\n\nList of R tools for microbiome analysis\nphyloseq [@McMurdie2013]\nmicrobiome tutorial\nmicrobiomeutilities\nBioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses [@Callahan2016]."
  },
  {
    "objectID": "95_resources.html#r-programming-resources",
    "href": "95_resources.html#r-programming-resources",
    "title": "12  Resources",
    "section": "12.2 R programming resources",
    "text": "12.2 R programming resources\n\n12.2.1 Base R and RStudio\nIf you are new to R, you could try swirl for a kickstart to R programming. Further support resources are available through the Bioconductor project [@Huber2015].\n\nBase R and RStudio cheatsheets\nPackage-specific cheatsheets\nVisualization with ggplot2\nR graphics cookbook\n\n\n\n12.2.2 Bioconductor Classes\nS4 system\nS4 class system has brought several useful features to the object-oriented programming paradigm within R, and it is constantly deployed in R/Bioconductor packages [@Huber2015].\n  Online Document:\n\nHervé Pagès, A quick overview of the S4 class system.\nLaurent Gatto, A practical tutorial on S4 programming\nHow S4 Methods Work [@Chambers2006]\n\n  Books:\n\nJohn M. Chambers. Software for Data Analysis: Programming with R. Springer, New York, 2008. ISBN-13 978-0387759357 [@Chambers2008]\nI Robert Gentleman. R Programming for Bioinformatics. Chapman & Hall/CRC, New York, 2008. ISBN-13 978-1420063677 [@gentleman2008r]"
  },
  {
    "objectID": "95_resources.html#quarto",
    "href": "95_resources.html#quarto",
    "title": "12  Resources",
    "section": "12.3 Reproducible reporting with Quarto",
    "text": "12.3 Reproducible reporting with Quarto\n\n12.3.1 Learn Quarto\nReproducible reporting is the starting point for robust interactive data science. Perform the following tasks:\n\nIf you are entirely new to Quarto, take this short tutorial to get introduced to the most important functions within Quarto. Then experiment with different options from the Quarto cheatsheet.\nCreate a Quarto template in RStudio, and render it into a document (markdown, PDF, docx or other format). In case you are new to Quarto, its documentation provides guidelines to use Quarto with the R language (here) and the RStudio IDE (here).\nFurther examples are tips for Quarto are available in this online tutorial to interactive reproducible reporting.\n\n\n\n12.3.2 Additional material on Rmarkdown\nBeing able to use Quarto in R partly relies on your previous knowledge of Rmarkdown. The following resources can help you get familiar with Rmarkdown:\n\nOnline tutorial\nCheatsheet\nDocumentation\nDr. C Titus Brown’s tutorial\n\nFigure sources:\nOriginal article - Huang R et al. (2021) TreeSummarizedExperiment: a S4 class for data with hierarchical structure. F1000Research 9:1246. [@Huang2021]\nReference Sequence slot extension - Lahti L et al. (2020) Upgrading the R/Bioconductor ecosystem for microbiome research F1000Research 9:1464 (slides)."
  },
  {
    "objectID": "98_exercises.html#basics-of-rbioconductor",
    "href": "98_exercises.html#basics-of-rbioconductor",
    "title": "13  Exercises",
    "section": "13.1 Basics of R/Bioconductor",
    "text": "13.1 Basics of R/Bioconductor\nBioconductor training material has been contributed to Carpentries. You can check the following lessons for basic background of R and Bioconductor.\n\nIntroduction to data analysis with R and Bioconductor\nIntroduction to the Bioconductor project"
  },
  {
    "objectID": "98_exercises.html#workflows",
    "href": "98_exercises.html#workflows",
    "title": "13  Exercises",
    "section": "13.2 Workflows",
    "text": "13.2 Workflows\n\n13.2.1 Reproducible reporting with Quarto\nThe following batch of exercises walks you through typical use cases of Quarto in RStudio. Before heading to the exercises, it is recommended to read the Quarto guidelines for RStudio\n\n13.2.1.1 New document\nThis exercise gets you started with creating a Quarto document and adding text to it with typing conventions borrowed from the markdown syntax. Feel free to render the document with the Render button after each step to see the changes in the final report.\n\nOpen RStudio and create a new Quarto file named My first Quarto.\nAdd the subtitle My first section and write some text of your choice underneath. You can choose the level of headings by the number of preceding hashes (#).\nAdd a subsection named List of items and list three items underneath, both ordered and unordered. You can initialize items with numbers (1., 2., 3., …) or stars (*) for the ordered and unordered case, respectively.\nAdd another subsection named Link to web and add a clickable link to the OMA book, using the pattern [text](url).\nRender the document and check its appearance\n\nNice start! You are now able to create a Quarto document, understand its syntax and can render it into a reproducible report. If you got stuck, you can look up the docs on creating and rendering Quarto documents.\n\n\n13.2.1.2 Code chunks\nWhile customizable text is nothing new by itself, the advantage of Quarto (and previously Rmakdown) is to combine text with code in R or other programming languages, so that both the analytical pipeline and verbal description can be put in one place. In this exercise, we learn how to write and run code in Quarto.\n\nOpen RStudio and create a new Quarto file.\nInitialize a code chunk by pressing alt + cmd + i and define the variables A &lt;- \"my name\" and B &lt;- 0 in it.\nWrite the text Below is my first code chunk just above the code chunk.\nInitialize one more code chunk and add 100 to the variable B in it.\nWrite the text Below I change variable B just above the second chunk.\nExtra: Write the following line of text: my name is A and I am B years old, where A and B are variables defined in the code chunks upstream and change if those variables are modified. Be aware that inline code can be added as &gt; r my_inline_command (without &gt;).\n\nGood job. You are now able to combine text and code in a Quarto document. If you got stuck, you can refer to the Quarto docs on using code chunks.\n\n\n13.2.1.3 Knitr options\nCode chunks can be greatly customized in terms of visibility and execution, output size and location and much more. This is possible with the knitr chunk options, which usually appear at the beginning of the target chunk with the syntax #| option-name: value, also described here. In this exercise, we explore part of the knitr potential.\n\nOpen RStudio and create a new Quarto file.\nInitialize three code chunks and label them as setup, fig-box and tbl-coldata, respectively. Remember that the name of a chunk can be specified with the label option.\nWrite the following code in the corresponding chunk and render the document.\n\n\n# setup\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# this line sets some options for all the chunks (global chunk options)\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n\n\n# fig-box\nboxplot(colSums(assay(tse)) ~ tse$SampleType)\n\n\n# tbl-coldata\nknitr::kable(head(colData(tse)))\n\n\n?(caption)\n\n\n\n\nSet include: false in the setup chunk, fig-width: 10 in the fig-box chunk and echo: false in the tbl-coldata chunk. Render the document again and find the differences from before.\nAdd the options fig-cap and tab-cap to the fig-box and tbl-coldata chunks, respectively. They require some text input, which makes for the caption of the figures or tables.\nExtra: Create a cross-reference to fig-box and tbl-coldata in the text above the respective code chunk. You can do that with the syntax @chunk-name.\nExtra: Define a custom folder for storing figures with fig-path. Insert it in knitr::opts_chunk$set, so that it applies globally to all the figures generated in the document.\n\nCongratulations! You are now familiar with the great potential and flexibility of knitr chunk options. An exhaustive list of available options can be found in the knitr documentation.\n\n\n13.2.1.4 YAML instructions\nThe box at the beginning of every Quarto document contains yaml options that let you define the metadata of the document. They will affect the appearance of the document when it is rendered. By default, the box includes yaml options for the title, format and editor to be used, but much more information on layout, code execution and figures can be specified. A comprehensive list of yaml options is available here. In this exercise, we will get a tiny taste of such functionality.\n\nOpen RStudio and create a new Quarto file.\nIn the yaml box at the beginning of the document, change the title from Untitled to My first Quarto.\nIn the same box, add the two lines author and date followed by your name and today’s date, respectively.\nRender the document and check its appearance.\nExtra: Set toc: true to produce a table of contents. This line should follow format and html at the second level of indentation.\n\nWell done! Now you are able to specify yaml options and understand how they affect your Quarto document. If you got stuck, you can check this section of the Quarto documentation.\n\n\n13.2.1.5 Quarto parameters\nAn advanced feature of Quarto consists of execution parameters, which are externally pre-defined variables that are also accessible in the Quarto document. They can be specified in the yaml box as params. Here we learn how to use them.\n\nOpen RStudio and create a new Quarto file.\nIn the yaml box at the beginning of the document, add a line named params followed by an indented line with gamma: 10\nInitialize a code chunk and type str(params$gamma) in it.\nRender the document and check what happened.\nDefine one more parameter beta: 3 and multiply gamma by beta in a code chunk below.\nRender the document again and check what happened.\n\nWell done! You can now use an advanced feature of Quarto such as parameters. If you got stuck, here you can find more information about parameter definition and usage."
  },
  {
    "objectID": "98_exercises.html#data-containers-treese",
    "href": "98_exercises.html#data-containers-treese",
    "title": "13  Exercises",
    "section": "13.3 Data containers: TreeSE",
    "text": "13.3 Data containers: TreeSE\nTreeSE containers represent the working unit of the mia package. In the following exercises we learn how to construct, explore and work with them. A few demo datasets can be imported with mia and can be accessed as explained in chapter @ref(example-data).\n\n13.3.1 Constructing a data object\nHere we cover how to construct a TreeSE from CSV files, using the components of OKeefeDSData from the microbiomeDataSets package as an example dataset.\n\nFetch or download the files in this directory.\nRead in the csv files with read.csv and store them into the variables assays, rowdata and coldata, respectively.\nCreate a TreeSE from the individual components with TreeSummarizedExperiment. Note that the function requires three arguments: assays, rowData and colData, to which you can give the appropriate item.\nCheck that importing is done correctly. E.g., choose random samples and features, and check that their values equal between raw files and TreeSE.\n\nUsefuls functions: DataFrame, TreeSummarizedExperiment, matrix, rownames, colnames, SimpleList\n\n\n13.3.2 Importing data\nRaw data of different types can be imported as a TreeSE with a number of functions explained in chapter @ref(import-from-file). You can also check the function reference in the mia package.\n\nGet familiar with the microbiome data repository and read the instructions in its README to import and construct datasets from there.\nImport data from another format (functions: loadFromMetaphlan | loadFromMothur | loadFromQIIME2 | makeTreeSummarizedExperimentFromBiom | makeTreeSummarizedExperimentFromDADA2 …)\nTry out conversions between TreeSE and phyloseq data containers (makeTreeSummarizedExperimentFromPhyloseq; makephyloseqFromTreeSummarizedExperiment)\n\n\n\n13.3.3 Preliminary exploration\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nGet a summary about the TreeSE with summary. What is the mean count across samples? How many features recur only once (singletons)?\nCheck the dimensions of the TreeSE with dim or alternatively with nrow and ncol. How many samples and features are present?\nList sample and features names with rownames and colnames.\nCheck what information about samples and features is contained by the colData and rowData of the TreeSE with names.\nExtra: Calculate the number of unique taxa for each taxonomic rank. You can use apply to count unique elements for each column of rowData.\n\n\n\n13.3.4 Assay retrieval\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nList the names of all available assays with assayNames.\nFetch the list of assays with assays.\nRetrieve the first assay of the TreeSE with assay, where the second argument can be either the name or the index of the desired assay.\n\nWell done! You can now locate and retrieve individual assays of a TreeSE. If you got stuck, you can refer to chapter @ref(assay-slot) of this book.\n\n\n13.3.5 Sample information\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nCheck the names of the samples with colnames.\nList the information on samples available in colData with names.\nVisualize the colData with View and briefly look at the information stored in the different columns.\nGet the abundances of all features for a specific sample, such as ID34, for an assay of your choice.\n\n\n\n13.3.6 Feature information\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nCheck the names of the features with rownames.\nList the information on features available in rowData with names.\nVisualize the rowData with View and briefly look at the information stored in the different columns.\nGet the abundances for a specific feature, such as OTU1810, in all the samples. You can access feature-specific abundances for an assay of your choice.\nExtra: Create a taxonomy tree based on the taxonomy mappings with addTaxonomyTree and display its content with taxonomyTree and ggtree.\n\nIf you got stuck, you can look up chapters @fref{datamanipulation} and @ref(fly-tree) on how to pick specific abundances and generate row trees, respectively.\n\n\n13.3.7 Other elements\nTry to extract some of the other TreeSE elements listed in chapter @ref(containers). However, such data are not always included.\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nFetch the metadata of the TreeSE. Is there any iformation available?\nAccess the phylogenetic tree with rowTree. How big is it in terms of tips and nodes. If you like you can visualize it with ggtree.\nCheck if a sample tree is available with colTree, which is suitable for hierarchical or nested study designs.\nIf present, obtain the information on feature DNA sequences from the DNA sequence slot."
  },
  {
    "objectID": "98_exercises.html#data-manipulation",
    "href": "98_exercises.html#data-manipulation",
    "title": "13  Exercises",
    "section": "13.4 Data manipulation",
    "text": "13.4 Data manipulation\n\n13.4.1 Subsetting\n\nSubset the TreeSE object to specific samples\nSubset the TreeSE object to specific features\nSubset the TreeSE object to specific samples and features\n\n\n\n13.4.2 Library sizes\n\nCalculate library sizes\nSubsample / rarify the counts (see: subsampleCounts)\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, addPerCellQC, mergeFeaturesByRank\n\n\n13.4.3 Prevalent and core taxonomic features\n\nEstimate prevalence for your chosen feature (row, taxonomic group)\nIdentify all prevalent features and subset the data accordingly\nReport the thresholds and the dimensionality of the data before and after subsetting\nVisualize prevalence\n\nUseful functions: getPrevalence, getPrevalentFeatures, subsetByPrevalentFeatures\n\n\n13.4.4 Data exploration\n\nSummarize sample metadata variables. (How many age groups, how they are distributed? 0%, 25%, 50%, 75%, and 100% quantiles of library size?)\nCreate two histograms. Another shows the distribution of absolute counts, another shows how CLR transformed values are distributed.\nVisualize how relative abundances are distributed between taxa in samples.\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, transformAssay, ggplot, wilcox.test, mergeFeaturesByRank, plotAbundance\n\n\n13.4.5 Other functions\n\nMerge data objects (merge, mergeSEs)\nMelt the data for visualization purposes (meltAssay)\n\n\n\n13.4.6 Assay transformation\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay and store it into the TreeSE as an assay named relabund (see chapter @ref(assay-transform)).\nSimilarly, perform a clr transformation on the counts assay with a pseudocount of 1 and add it to the TreeSE as a new assay.\nList the available assays by name with assays.\nAccess the clr assay and select a subset of its first 100 features and 10 samples. Remember that assays are subsettable with assay[row_idx, col_idx].\nTake the same subset from the TreeSE, and check how this affects the individual transformed assays. TreeSE can also be subsetted with tse[row_idx, col_idx].\nExtra: If the data has phylogenetic tree, perform the phILR transformation."
  },
  {
    "objectID": "98_exercises.html#abundance-tables",
    "href": "98_exercises.html#abundance-tables",
    "title": "13  Exercises",
    "section": "13.5 Abundance tables",
    "text": "13.5 Abundance tables\n\n13.5.1 Taxonomic levels\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nList the available taxonomic ranks in the data with taxonomyRanks.\nAgglomerate the data to Phylum level with mergeFeaturesByRank and the appropriate value for Rank.\nReport the dimensions of the TreeSE before and after agglomerating. You can use dim for that.\nExtra: Perform CLR transformation on the data. Does this affect agglomeration?\nExtra: List full taxonomic information for a few selected taxa, such as OTU1 and OTU1368. For that you can use mapTaxonomy on a specific subset of the TreeSE.\n\n\n\n13.5.2 Alternative experiments\n\nImport the mia package, load GlobalPatterns with data and store it into a variable named tse.\nCheck the taxonomic ranks of the features with taxonomyRanks. What is the deepest taxonomic rank available?\nAgglomerate the TreeSE to each taxonomic rank and store the resulting experiments as altExps. This can be performed automatically with splitByRanks.\nCheck the names of the generated altExps with altExpNames and retrieve a complete list with altExps.\nRetrieve the data agglomerated by genus from the corresponding altExp. As for assays, you can access the desired altExp by name or index.\nExtra: Split the data based on other features with splitOn."
  },
  {
    "objectID": "98_exercises.html#community-alpha-diversity",
    "href": "98_exercises.html#community-alpha-diversity",
    "title": "13  Exercises",
    "section": "13.6 Community (alpha) diversity",
    "text": "13.6 Community (alpha) diversity\n\n13.6.1 Estimation\n\nImport the mia package, load GlobalPatterns with data and store it into a variable named tse.\nCalculate multiple alpha diversity indices with estimateDiversity without any additional arguments.\nCheck the names of colData with names. Can you identify which columns contain the alpha diversity indices?\nExtra: Agglomerate the TreeSE by phylum and compare the mean Shannon diversity of the original experiment with its agglomerated version. You can use mergeFeaturesByRank to perform agglomeration and mean to calculate the mean values of the respective columns in colData.\n\n\n\n13.6.2 Visualization\n\nImport the mia and scater packages, load GlobalPatterns with data and store it into a variable named tse.\nCalculate Shannon diversity index and Faith’s phylogenetic diversity with estimateDiversity and the appropriate arguments for index.\nMake a boxplot of Shannon diversity on the y axis and sample type on the x axis with plotColData.\nRepeat the previous point with Faith’s phylogenetic diversity and compare the sample distributions of the two alpha diversity indices. How greatly do they differ?\nExtra: Make a scatterplot of Shannon diversity on the y axis and Faith’s phylogenetic diversity on the x axis with plotColData. Colour the points by sample type with the appropriate optional argument.\n\n\n\n13.6.3 Correlation\n\nImport the mia and scater packages, load peerj13075 with data and store it into a variable named tse.\nCalculate coverage and Shannon diversity index with estimateDiversity and the appropriate arguments for index.\nTest the correlation between the two indices with cor.test. Remember that colData parameters are accessible with tse$param_name. Use Kendall tau coefficients as method to measure correlation. Is the correlation weak or strong, significant or not?\nMake a scatterplot of Shannon diversity index on the y axis and coverage on the x axis. You can do that with plotColData. How do the two indices relate to one another?\nExtra: Compute the library size of the samples by applying colSums to the counts assay of the TreeSE, and test the correlation of library size with Shannon diversity or coverage. Which index is more correlated with library size?\n\nIn this example, we inspected the correlation between two related variables, also known as multicollinearity, and checked the correlation to library size, which is part of quality control. However, the correlation between alpha diversity and other numerical data about samples, such as participant’s age and weight, also represent an important analysis in several studies.\n\n\n13.6.4 Differences between groups\n\nImport the mia package, load peerj13075 with data and store it into a variable named tse.\nCalculate the Gini-Simpson diversity with estimateDiversity and the appropriate argument for index. Set name to simpson. You will use this name to access the diversity index from colData.\nInspect the Diet column in the colData. Determine how the samples are grouped in terms of diet. You can see the number of unique elements in a column with unique.\nTest differences in Gini-Simpson diversity between different diets with kruskal.test. Remember that colData parameters are accessible with tse$param_name.\nIs diversity significantly different between vegan and mixed diet? To visualize that, make a boxplot of Gini-Simpson diversity on the y axis and diet on the x axis with plotColData.\nExtra: Repeat points 3 through 5, this time for age groups. Make sure that you are using an appropriate statistical test for the number of groups and distribution."
  },
  {
    "objectID": "98_exercises.html#community-similarity",
    "href": "98_exercises.html#community-similarity",
    "title": "13  Exercises",
    "section": "13.7 Community similarity",
    "text": "13.7 Community similarity\n\n13.7.1 Reduced dimensions retrieval\n\nImport the mia package, load enterotype with data and store it into a variable named tse.\nList all available reduced dimensions with reducedDims. At this point, no reducedDims are likely found, because we haven’t created any yet.\nPerform PCA and store its output in the TreeSE by running tse &lt;- runPCA(tse, assay.type = \"counts\"). Note that it is required to specify the assay on which dimensionality reduction should be conducted.\nView the names of all available reduced dimensions with reducedDimNames. Has something new appeared?\nExtra: Access the PCA reducedDim object with reducedDim and explore its content. How are the different dimensions stored? Try to extract an array with only the values from the second dimension by indexing the object with [ , 2].\n\n\n\n13.7.2 Visualization basics with PCA\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nPerform a 3-component PCA based on the counts assay. You can use runPCA and set the optional arguments ncomponents and assay.type to the appropriate values.\nPlot the first two dimensions of PCA with plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Note that by default only the first two dimensions are shown.\nCheck which information is stored in the ColData of the TreeSE. What would be worth visualizing in our coordination plot?\nMake the same plot again, but this time colour the observations by Enterotype. You can do that by setting colour_by to the appropriate colname in the colData of the TreeSE.\nExtra: Plot all three dimensions of PCA with plotReducedDim and the optional argument ncomponents. Colour observations by Enterotype. Which pair of dimensions best explains the variance between Enterotypes?\n\n\n\n13.7.3 Principal Coordinate Analysis (PCoA)\nPCoA turns out to be particularly relevant for microbiome analysis, because unlike PCA it can generate reduced dimensions from distances other than Euclidean. There are several ecological distances to choose from and you can find many of them under methods in the vignettes of vegan::vegdist.\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nTransform the counts assay to relative abundances with transformAssay.\nPerform a Multi-Dimensional Scaling (MDS) based on the relative abundance assay in terms of Bray-Curtis dissimilarity. You can use runMDS with the compulsory argument FUN = vegan::vegdist.\nPlot the first two dimensions of PCA with plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Colour the observations by Enterotype with colour_by.\nExtra: Perform MDS again with runMDS, but this time use Jaccard dissimilarity. The distance metric to use can be defined with the optional argument method, choosing from the methods in ?vegan::vegdist. If you don’t want to overwrite the reducedDim object made in point 3, set name to a name of your choice. Visualize and compare it to the plot from point 4.\n\nGood job! You are now able to produce and visualize reduced dimensions of a TreeSE. runMDS is actually one of several algorithms for PCoA and dimensionality reduction, which you can find in section @ref(other-ord-methods).\n\n\n13.7.4 PERMANOVA analysis\nIn this exercise we focus on studying the weight of variables on the microbiome composition. Significance of each variable on beta diversity is tested with PERMANOVA (point 4) and the homogeneity assumption is also be controlled with a PERMDISP2 analysis (point 5).\n\nImport the mia and vegan packages, load peerj13075 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nExtract the relative abundance assay, transpose it and save it into a variable named relabund_assay.\nPerform PERMANOVA with adonis2 to see how much Diet can explain the relative abundance assay (formula = relabund_assay ~ Diet) in terms of Bray-Curtis dissimilarity (method = \"bray\"). Also set data = colData(tse) by = \"margin\" and permutations = 99. What do the results tell you about Diet with respect to beta diversity?\nExtra: Test homogeneity of distribution across Diet groups with anova(betadisper(my_mat), my_groups, where my_mat is the Bray-Curtis dissimilarity matrix of relabund_assay calculated with vegdist(relabund_assay, \"bray\") and my_groups is the vector of Diet values obtained from the colData of the TreeSE.\n\nWell done! You went through testing the effect and significance of Diet on beta diversity. Keep in mind that the formula fed to adonis2 can take more than one independent variable, so that you can also (and very often should) include covariates of your studies.\n\n\n13.7.5 Redundancy analysis (RDA)\nHere we apply RDA, an ordination method that provides dimensions with the largest variation between the data based in the light of the specified variables (point 3). The results of RDA are usually assessed with PERMANOVA (point 5) and the homogeneity assumption should be checked as in the previous exercise. This is a relatively complex procedure, but the way this is broken down into steps below will hopefully make more sense.\n\nImport the mia and vegan packages, load peerj13075 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nPerform RDA with calculateRDA to see how much Diet can explain the relative abundance assay (formula = assay ~ Diet and assay.type = relabundance) in terms of Bray-Curtis dissimilarity (method = \"bray\").\nExtract the RDA dimensions from the appropriate reducedDim slot with attr(reducedDim(tse, \"RDA\"), \"rda) and store it into rda.\nTest the effect and significance of Diet on beta diversity by PERMANOVA with anova.cca. Feed this function with rda and set by = \"margin\" and permutations = 99, respectively. What do the results tell you about Diet?\nExtra: Check what other parameters are stored in the colData of peerj13075, add them to the formula (formula = assay ~ Diet + ...) of calculateRDA and proceed to see how that changes the results of PERMANOVA.\n\nWell done! You went through an RDA analysis followed by significance testing with PERMANOVA and BETADISPER2. In the next exercise we’ll go deeper quantify the contributions to beta diversity.\n\n\n13.7.6 Beta diversity analysis\nThis exercise prompts you to implement a workflow with distance-based RDA (dbRDA). You can refer to chapter @ref(dbrda-workflow) for a step-by-step walkthrough, which may be simplified in the future.\n\nImport the mia and vegan packages, load peerj13075 with data and store it into a variable named tse.\nCreate dbRDA with Bray-Curtis dissimilarities on relative abundances. Use PERMANOVA. Can differences between samples be explained with variables of sample meta data?\nAnalyze diets’ association on beta diversity. Calculate dbRDA and then PERMANOVA. Visualize coefficients. Which taxa’s abundances differ the most between samples?\nInterpret your results. Is there association between community composition and location? What are those taxa that differ the most; find information from literature.\n\nUseful functions: runMDS, runRDA, anova.cca, transformAssay, mergeFeaturesByRank, ggplot, plotReducedDim, vegan::adonis2"
  },
  {
    "objectID": "98_exercises.html#differential-abundance",
    "href": "98_exercises.html#differential-abundance",
    "title": "13  Exercises",
    "section": "13.8 Differential abundance",
    "text": "13.8 Differential abundance\n\n13.8.1 Standard analysis with ALDEx2\n\nImport the mia and ALDEx2 packages, load peerj13075 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentTaxa by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with aldex.clr and store it into the variable x. As a second argument, provide the grouping variable Diet, which is contained in a column of the colData.\nFeed x to the functions aldex.ttest to erform t-test and to aldex.effect to estimate effect sizes. Store the output into x_tt and x_effect, respectively.\nCreate a data.frame named aldex_out which includes both x_tt and x_effect and filter for the features with wi.eBH &lt; 0.05. Are there any significantly differential abundance taxa?\nExtra: If these results appear boring, repeat steps 1 - 5, but use Gender or Age as the grouping variable. Do we have any better luck with Gender? What is the problem with Age?\n\n\n\n13.8.2 Controlling for confounders\n\nImport the mia and MicrobiomeStat packages, load peerj13075 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentTaxa by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with linda and store the output into a variable named linda_out. Provide the colData converted into a data.frame (with as.data.frame) as the second argument, and a formula with the Age, Gender and Diet as variables. For example, formula = \"~ A + B\" represents a formula with variables A and B.\nExtract the output$AgeElderly object from linda_out with $ and store it into a variable named linda_res.\nFilter linda_res for features with reject == TRUE. How many differentially abundant taxa were found? What are their names and how significant are they in terms of log-fold change and adjusted p-value?\n\n\n\n13.8.3 Comparing methods\nHere, we conduct DAA with identical parameters as in the previous exercise, but with a different method, namely ZicoSeq. We aim to compare the results between these two methods and draw better informed conclusions from such comparative approach.\n\nImport the mia and GUniFrac packages, load peerj13075 with data and store it into a variable named tse.\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalentTaxa by specifying the rank and prevalence arguments.\nModel the counts assay of the TreeSE with ZicoSeq as the feature.dat argument and store the output into a variable named zicoseq_out. Provide also the colData converted to a data.frame (with as.data.frame) as meta.dat. In addition, set grp.name to \"Age\", adj.name to c(\"Diet\", \"Gender\"), feature.dat.type to \"count\", return.feature.dat to TRUE and perm.no to 999.\nView the top six differentially abundant taxa and their adjusted p-values with head(sort(zicoseq_out$p.adj.fdr)). Is there any significant taxon according to ZicoSeq? Compared to the output of linda, do we see the same taxa at the top in terms of significance? Overall, to what extent do the two methods agree with one another?\n\n\n\n13.8.4 Workflow 1\n\nGet the abundances for an individual feature (taxonomic group / row)\nVisualize the abundances per group with boxplot / jitterplot\nIs the difference significant (Wilcoxon test)?\nIs the difference significant (linear model with covariates)?\nHow do transformations affect the outcome (log10, clr..)?\nGet p-values for all features (taxa), for instance with a for loop\nDo multiple testing correction\nCompare the results from different tests with a scatterplot\n\nUseful functions: [], ggplot2::geom_boxplot, ggplot2::geom_jitter, wilcox.test, lm.test, transformAssay, p.adjust\n\n\n13.8.5 Workflow 2\n\ninstall the latest development version of mia from GitHub.\nLoad experimental dataset from mia.\nCompare abundances of each taxa between groups. First, use Wilcoxon or Kruskall-Wallis test. Then use some other method dedicated to microbiome data.\nSummarize findings by plotting a taxa vs samples heatmap. Add column annotation that tells the group of each sample, and row annotation that tells whether the difference of certain taxa was statistically significant.\nChoose statistically significant taxa and visualize their abundances with boxplot & jitterplot.\n\nUseful functions: wilcox.test, kruskal.test, ggplot, pheatmap, ComplexHeatMap::Heatmap, ancombc, aldex2, maaslin2, mergeFeaturesByRank, transformAssay, subsetByPrevalentFeatures"
  },
  {
    "objectID": "98_exercises.html#visualization-1",
    "href": "98_exercises.html#visualization-1",
    "title": "13  Exercises",
    "section": "13.9 Visualization",
    "text": "13.9 Visualization\n\n13.9.1 Multivariate ordination\n\nLoad experimental dataset from mia.\nCreate PCoA with Bray-Curtis dissimilarities\nCreate PCA with Aitchison dissimilarities\nVisualize and compare both\nTest other transformations, dissimilarities, and ordination methods\n\nUseful functions: runMDS, runNMDS, transformAssay, ggplot, plotReducedDim\n\n\n13.9.2 Heatmap visualization\n\nLoad experimental dataset from mia.\nVisualize abundances with heatmap\nVisualize abundances with heatmap after CLR + Z transformation\n\nSee the OMA book for examples."
  },
  {
    "objectID": "98_exercises.html#multiomics",
    "href": "98_exercises.html#multiomics",
    "title": "13  Exercises",
    "section": "13.10 Multiomics",
    "text": "13.10 Multiomics\n\n13.10.1 Basic exploration\nHere we learn how to conduct preliminary exploration on a MAE, using HintikkaXOData as an example dataset.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhich experiments make up the MAE? How many samples and features are contained by each experiment? You can get a summary for all experiments with experiments, and check for each individual experiment with dim, nrow and ncol.\nWhat are the names of the features and samples of the different experiments? You can see that with rownames and colnames, respectively.\nWhat information is known about the samples? Remember that information about samples is stored in the colData of the MAE.\nExtra: How do the samples of the individual experiments map to the columns of the MAE? You can find the sample mapping in the sampleMap of the MAE.\n\nSo far so good. You explored a MAE and its experiments, getting a taste of how information is organized in its internal structure.\n\n\n13.10.2 Experiment agglomeration\nHere we learn how to manipulate an experiment contained by a MAE and save the new modified version of the experiment in a suitable place (the altExp slot).\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAgglomerate the microbiota experiment by Genus and store the output into the altExp slot of the microbiota experiment, with the custom name microbiota_genus.\nHow many features remain after agglomerating? What are their names?\nExtra: create one more alternative experiment named prevalent_microbiota_family, which contains the microbiota experiment agglomerated by Family with a prevalence threshold of 10%. You can agglomerate and in parallel select by prevalence with mergeFeaturesByPrevalence.\n\nGood job! You agglomerated one of the experiments in the MAE and stored it as an alternative experiment.\n\n\n13.10.3 Experiment transformation\nWe proceed with an exercise on a different type of data manipulation, that is, transformation of assays of individual experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhat assays are contained by each individual experiment? You can check their names with assays.\nApply a log10 transformation to the assay of the metabolite experiment. For that you can use transformAssay and don’t forget to specify the assay to be transformed with the argument assay.type.\nApply a CLR transformation to the counts assay of the microbiota experiment. To ensure non-null values in the assay, set pseudocount equal to 1.\n\nYou made it! You learnt how to apply different transformations to the assays of individual experiments in a MAE with transformAssay, specifying optional arguments based on the used method.\n\n\n13.10.4 Assay extraction\nThe following exercise walks you through disassembling a MAE object in order to retrieve a specific assay, or to store its components as multiple separate csv files.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nExtract the individual metabolite experiment from the MAE into a distinct TreeSE object named metabolites.\nWhich and how many assays are contained by metabolites? You can check that with assays or assayNames.\nWrite a csv file for the nmr assay with write.csv. You can access an individual assay of a TreeSE with assay by specifying the name of the desired assay.\nExtra: Repeat step 1 thorugh 4 also for the microbiota and biomarkers experiments, so that a completely disassembled version of the MAE is available.\nExtra: Besides experiments, MAEs also include a sampleData and a sampleMap, which are accessible with colData(mae) and sampleMap(mae), respectively. Save also each of these two elements into a csv file.\n\nWell done! You just splitted a MAE into its components and stored them as csv files. This script shows a possible approach.\n\n\n13.10.5 MAE reconstruction\nNext, we will try to reconstruct the same MAE from the files you created. Make sure you know their names and location! Alternatively, you can fetch or download the CSV files in this directory with the readily disassembled components of HintikkaXOData.\n\nRead in the csv files containing assays with read.csv and save each of them into a variable named &lt;assay name&gt;_assays.\nCreate one TreeSE from each assays object with the TreeSummarizedExperiment function, as explained in this exercise.\nRead in the sampleData and the sampleMap and store them into the variables sample_data and sample_map, respectively.\nCombine the components with MultiAssayExperiment, where the first argument is an ExperimentList (for now include only the microbiota and metabolites TreeSEs), the second is colData and the third is sampleMap.\nMake sure that the MAE experiments are identical to the original TreeSEs. You can do that qualitatively by checking their head and quantitatively by looking at their dim.\nExtra: Add the biomarkers TreeSE as a new experiment to the MAE. Note that new experiments can be added to a MAE through simple concatenation with c(mae, experiment).\n\nGood job! Now you are aware of how MAEs are built and we can proceed to some analytical exercises.\n\n\n13.10.6 Cross-correlation analysis\nNow we will perform a cross-correlation analysis between two of the experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAnalyze correlations between the microbiota and the biomarkers experiments with getExperimentCrossAssociation. Don’t forget to specify the experiments you want to compare with the arguments experiment1 and experiment2, and which of their assays with assay.type1 and assay.type2.\nWhat does the output look like? By default, correlation is measured in terms of Kendall tau coefficients. Repeat point 2, but this time change method to Spearman coefficients.\nAre you able to infer significance from the output? In order to also obtain p-values from the cross-correlation analysis, repeat point 2 with the additional argument test_significance = TRUE.\nVisualize results with a heatmap similarly to the example in section @ref(cross-correlation). Do you see any significant correlations? Interpret your results.\nExtra: Perform cross-correlation analysis between the remaining experiments (microbiota vs metabolites and metabolites vs biomarkers) and visualize results with heatmaps.\n\nGreat job! You performed a cross-correlation analysis between two experiments of a MAE and visualized the results with a heatmap. You are also able to customise the correlation method and significance testing used for the analysis."
  },
  {
    "objectID": "97_extra_materials.html",
    "href": "97_extra_materials.html",
    "title": "(PART) Appendix",
    "section": "",
    "text": "Extra material\nknitr::opts_chunk$set(eval=FALSE)"
  },
  {
    "objectID": "97_extra_materials.html#slides",
    "href": "97_extra_materials.html#slides",
    "title": "(PART) Appendix",
    "section": "Slides",
    "text": "Slides\nOutreach material includes slide sets for training events."
  },
  {
    "objectID": "97_extra_materials.html#compare-permanova",
    "href": "97_extra_materials.html#compare-permanova",
    "title": "(PART) Appendix",
    "section": "PERMANOVA comparison",
    "text": "PERMANOVA comparison\nHere we present two possible uses of the adonis2 function which performs PERMANOVA. The optional argument by has an effect on the statistical outcome, so its two options are compared here.\n\n# import necessary packages\nlibrary(gtools)\nlibrary(purrr)\nlibrary(vegan)\nlibrary(gtools)\nlibrary(purrr)\n\nLet us load the enterotype TSE object and run PERMANOVA for different orders of three variables with two different approaches: by = \"margin\" or by = \"terms\".\n\n# load and prepare data\nlibrary(mia)\ndata(\"enterotype\", package=\"mia\")\nenterotype &lt;- transformAssay(enterotype, method = \"relabundance\")\n# drop samples missing meta data\nenterotype &lt;- enterotype[ , !rowSums(is.na(colData(enterotype)[, c(\"Nationality\", \"Gender\", \"ClinicalStatus\")]) &gt; 0)]\n# define variables and list all possible combinations\nvars &lt;- c(\"Nationality\", \"Gender\", \"ClinicalStatus\")\nvar_perm &lt;- permutations(n = 3, r = 3, vars)\nformulas &lt;- apply(var_perm, 1, function(row) purrr::reduce(row, function(x, y) paste(x, \"+\", y)))\n# create empty data.frames for further storing p-values\nterms_df &lt;- data.frame(\"Formula\" = formulas,\n                       \"ClinicalStatus\" = rep(0, 6),\n                       \"Gender\" = rep(0, 6),\n                       \"Nationality\" = rep(0, 6))\nmargin_df &lt;- data.frame(\"Formula\" = formulas,\n                        \"ClinicalStatus\" = rep(0, 6),\n                        \"Gender\" = rep(0, 6),\n                        \"Nationality\" = rep(0, 6))\n\n\nfor (row_idx in 1:nrow(var_perm)) {\n  \n  # generate temporary formula (i.e. \"assay ~ ClinicalStatus + Nationality + Gender\")\n  tmp_formula &lt;- purrr::reduce(var_perm[row_idx, ], function(x, y) paste(x, \"+\", y))\n  tmp_formula &lt;- as.formula(paste0('t(assay(enterotype, \"relabundance\")) ~ ',\n                            tmp_formula))\n\n  # multiple variables, default: by = \"terms\"\n  set.seed(75)\n  with_terms &lt;- adonis2(tmp_formula, \n                by = \"terms\",\n                data = colData(enterotype),\n                permutations = 99)\n  \n  # multiple variables, by = \"margin\"\n  set.seed(75)\n  with_margin &lt;- adonis2(tmp_formula, \n                 by = \"margin\",\n                 data = colData(enterotype),\n                 permutations = 99)\n\n  # extract p-values\n  terms_p &lt;- with_terms[[\"Pr(&gt;F)\"]]\n  terms_p &lt;- terms_p[!is.na(terms_p)]\n  margin_p &lt;- with_margin[[\"Pr(&gt;F)\"]]\n  margin_p &lt;- margin_p[!is.na(margin_p)]\n  \n  # store p-values into data.frames\n  for (col_idx in 1:ncol(var_perm)) {\n    \n    terms_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- terms_p[col_idx]\n    margin_df[var_perm[row_idx, col_idx]][row_idx, ] &lt;- margin_p[col_idx]\n    \n  }\n  \n}\n\nThe following table displays the p-values for the three variables ClinicalStatus, Gender and Nationality obtained by PERMANOVA with adonis2. Note that the p-values remain identical when by = \"margin\", but change with the order of the variables in the formula when by = \"terms\" (default).\n\ndf &lt;- terms_df %&gt;%\n  dplyr::inner_join(margin_df, by = \"Formula\", suffix = c(\" (terms)\", \" (margin)\"))\n\nknitr::kable(df)"
  },
  {
    "objectID": "97_extra_materials.html#bayesian-multinomial-logistic-normal-models",
    "href": "97_extra_materials.html#bayesian-multinomial-logistic-normal-models",
    "title": "(PART) Appendix",
    "section": "Bayesian Multinomial Logistic-Normal Models",
    "text": "Bayesian Multinomial Logistic-Normal Models\nAnalysis using such model could be performed with the function pibble from the fido package, wihch is in form of a Multinomial Logistic-Normal Linear Regression model; see vignette of package.\nThe following presents such an exemplary analysis based on the data of @Sprockett2020 available through microbiomeDataSets package.\n\nlibrary(fido)\n\nLoading the libraries and importing data:\n\nlibrary(fido)\n\n\nlibrary(microbiomeDataSets)\ntse &lt;- SprockettTHData()\n\nWe pick three covariates (“Sex”,“Age_Years”,“Delivery_Mode”) during this analysis as an example, and beforehand we check for missing data:\n\nlibrary(mia)\ncov_names &lt;- c(\"Sex\",\"Age_Years\",\"Delivery_Mode\")\nna_counts &lt;- apply(is.na(colData(tse)[,cov_names]), 2, sum)\nna_summary&lt;-as.data.frame(na_counts,row.names=cov_names)\n\nWe drop missing values of the covariates:\n\ntse &lt;- tse[ , !is.na(colData(tse)$Delivery_Mode) ]\ntse &lt;- tse[ , !is.na(colData(tse)$Age_Years) ]\n\nWe agglomerate microbiome data to Phylum:\n\ntse_phylum &lt;- mergeFeaturesByRank(tse, \"Phylum\")\n\nWe extract the counts assay and covariate data to build the model matrix:\n\nY &lt;- assays(tse_phylum)$counts\n# design matrix\n# taking 3 covariates\nsample_data&lt;-as.data.frame(colData(tse_phylum)[,cov_names])\nX &lt;- t(model.matrix(~Sex+Age_Years+Delivery_Mode,data=sample_data))\n\nBuilding the parameters for the pibble call to build the model; see more at vignette:\n\nn_taxa&lt;-nrow(Y)\nupsilon &lt;- n_taxa+3\nOmega &lt;- diag(n_taxa)\nG &lt;- cbind(diag(n_taxa-1), -1)\nXi &lt;- (upsilon-n_taxa)*G%*%Omega%*%t(G)\nTheta &lt;- matrix(0, n_taxa-1, nrow(X))\nGamma &lt;- diag(nrow(X))\n\nAutomatically initializing the priors and visualizing their distributions:\n\npriors &lt;- pibble(NULL, X, upsilon, Theta, Gamma, Xi)\nnames_covariates(priors) &lt;- rownames(X)\nplot(priors, pars=\"Lambda\") + ggplot2::xlim(c(-5, 5))\n\nEstimating the posterior by including our response data Y. Note: Some computational failures could occur (see discussion) the arguments multDirichletBoot calcGradHess could be passed in such case.\n\npriors$Y &lt;- Y \nposterior &lt;- refit(priors, optim_method=\"adam\", multDirichletBoot=0.5) #calcGradHess=FALSE\n\nPrinting a summary about the posterior:\n\nppc_summary(posterior)\n\nPlotting the summary of the posterior distributions of the regression parameters:\n\nnames_categories(posterior) &lt;- rownames(Y)\nplot(posterior,par=\"Lambda\",focus.cov=rownames(X)[2:4])\n\nTaking a closer look at “Sex” and “Delivery_Mode”:\n\nplot(posterior, par=\"Lambda\", focus.cov = rownames(X)[c(2,4)])"
  },
  {
    "objectID": "97_extra_materials.html#interactive-3d-plots",
    "href": "97_extra_materials.html#interactive-3d-plots",
    "title": "(PART) Appendix",
    "section": "Interactive 3D Plots",
    "text": "Interactive 3D Plots\n\n# Load libraries\nlibrary(rgl)\nlibrary(plotly)\n\n\nlibrary(knitr)\nknitr::knit_hooks$set(webgl = hook_webgl)\n\nIn this section we make a 3D version of the earlier Visualizing the most dominant genus on PCoA (see @ref(quality-control)), with the help of the plotly [@Sievert2020].\n\n# Importing necessary libraries\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\nlibrary(DT)\nlibrary(mia)\nlibrary(scater)\n\n# Querying the data\ntse &lt;- sampleMetadata %&gt;%\n    filter(age &gt;= 18) %&gt;% # taking only data of age 18 or above\n    filter(!is.na(alcohol)) %&gt;% # excluding missing values\n    returnSamples(\"relative_abundance\")\n\ntse_Genus &lt;- mergeFeaturesByRank(tse, rank=\"genus\")\ntse_Genus &lt;- addPerSampleDominantFeatures(tse_Genus,assay.type=\"relative_abundance\", name = \"dominant_taxa\")\n\n# Performing PCoA with Bray-Curtis dissimilarity.\ntse_Genus &lt;- runMDS(tse_Genus, FUN = vegan::vegdist, ncomponents = 3,\n              name = \"PCoA_BC\", assay.type = \"relative_abundance\")\n\n# Getting the 6 top taxa\ntop_taxa &lt;- getTopFeatures(tse_Genus,top = 6, assay.type = \"relative_abundance\")\n\n# Naming all the rest of non top-taxa as \"Other\"\nmost_abundant &lt;- lapply(colData(tse_Genus)$dominant_taxa,\n                   function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\n\n# Storing the previous results as a new column within colData\ncolData(tse_Genus)$most_abundant &lt;- as.character(most_abundant)\n\n# Calculating percentage of the most abundant\nmost_abundant_freq &lt;- table(as.character(most_abundant))\nmost_abundant_percent &lt;- round(most_abundant_freq/sum(most_abundant_freq)*100, 1)\n\n# Retrieving the explained variance\ne &lt;- attr(reducedDim(tse_Genus, \"PCoA_BC\"), \"eig\");\nvar_explained &lt;- e/sum(e[e&gt;0])*100"
  },
  {
    "objectID": "90_acknowledgments.html",
    "href": "90_acknowledgments.html",
    "title": "Developers",
    "section": "",
    "text": "Core team\nContributions to this Gitbook from the various developers are coordinated by:\n\nLeo Lahti, DSc, professor in Data Science at the Department of Computing, University of Turku, Finland, with a focus on computational microbiome analysis. Lahti obtained doctoral degree (DSc) from Aalto University in Finland (2010), developing probabilistic machine learning with applications to high-throughput life science data integration. Since then he has focused on microbiome research and developed, for instance, the phyloseq-based microbiome R package before starting to develop the TreeSummarizedExperiment / MultiAssayExperiment framework and the mia family of Bioconductor packages for microbiome data science introduced in this gitbook. Lahti led the development of national policy on open access to research methods in Finland. He is current member in the Bioconductor Community Advisory Board and runs regular training workshops in microbiome data science.\nTuomas Borman, PhD researcher and the lead developer of OMA/mia at the Department of Computing, University of Turku.\n\n\n\nContributors\nThis work is a remarkably collaborative effort. The full list of contributors is available via Github. Some key authors/contributors include:\n\nFelix Ernst, PhD, among the first developers of R/Bioc methods for microbiome research based on the SummarizedExperiment class and its derivatives.\nGiulio Benedetti, scientific programmer at the Department of Computing, University of Turku. His research interest is mostly related to Data Science. He has also helped to expand the SummarizedExperiment-based microbiome analysis framework to the Julia language, implementing MicrobiomeAnalysis.jl.\nSudarshan Shetty, PhD has supported the establishment of the framework and associated tools. He also maintains a list of microbiome R packages.\nHenrik Eckermann, in particular to the development of the differential abundance analyses\nChouaib Benchraka provided various contributions to the package ecosystem and the OMA book\nYağmur Şimşek converted the miaSim R package to support the Bioconductor framework\nBasil Courbayre provided various contributions to the package ecosystem and the OMA book, in particular on unsupervised machine learning\nMatti Ruuskanen, PhD, added machine learning techniques for microbiome analysis\nShigdel Rajesh, PhD\nArtur Sannikov\nJeba Akewak\nHimmi Lindgren\nLu Yang\n\n\n\nAcknowledgments\nThis work would not have been possible without the countless contributions and interactions with other researchers, developers, and users. We express our gratitude to the entire Bioconductor community for developing this high-quality open research software repository for life science analytics, continuously pushing the limits in emerging fields [@Gentleman2004], [@Huber2015].\nThe presented framework for microbiome data science is based on the TreeSummarizedExperiment data container created by Ruizhu Huang and others [@R_TreeSummarizedExperiment], [@Ernst2020], and on the MultiAssayExperiment by Marcel Ramos et al. [@Ramos2017]. The idea of using these containers as a basis for microbiome data science was initially advanced by the groundwork of Domenick Braccia, Héctor Corrada Bravo and others and brought together with other microbiome data science developers [@Shetty2019]. Setting up the base ecosystem of packages and tutorials was then subsequently led by Tuomas Borman, Felix Ernst, and Leo Lahti. We would specifically like to thank everyone who contributed to the work supporting the TreeSummarizedExperiment ecosystem for microbiome research, including but not limited to the R packages mia, miaViz, miaTime, miaSim, philr, ANCOMBC, curatedMetagenomicData, scater, scuttle, and other packages, some of which are listed in Section @ref(ecosystem). A number of other contributors have advanced the ecosystem further, and will be acknowledged in the individual packages, pull requests, issues, and other work.\nAmple demonstration data resources supporting this framework have been made available through the curatedMetagenomicData project by Edoardo Pasolli, Lucas Schiffer, Levi Waldron and others [@Pasolli2017].\nThe work has drawn initial inspiration from many sources, most notably from the work on phyloseq by Paul McMurdie and Susan Holmes [@McMurdie2013] who pioneered the work on rigorous and reproducible microbiome data science ecosystems in R/Bioconductor. The phyloseq framework continues to provide a vast array of complementary packages and methods for microbiome studies. The Orchestrating Single-Cell Analysis with Bioconductor, or OSCA book by Robert Amezquita, Aaron Lun, Stephanie Hicks, and Raphael Gottardo [@Amezquita2020natmeth] has implemented closely related work on the SummarizedExperiment data container and its derivatives in the field of single cell sequencing studies that have inspired this work.\nIn the background, the open source books by Susan Holmes and Wolfgang Huber, Modern Statistics for Modern Biology [@Holmes2019] and by Garret Grolemund and Hadley Wickham, the R for Data Science [@Grolemund2017], and Richard McElreath’s Statistical Rethinking and the associated online resources by Solomon Kurz [@McElreath2020] are key references that have advanced reproducible data science training and dissemination.\n\n\nHow to contribute\nTo contribute reports, follow the Git flow procedure (you can see instructions to getting started with Github):\n\nFork the project\nClone your fork\nModify the material\nCheck locally that the changes render successfully (see above)\nAdd and commit the changes to your fork\nCreate a pull request (PR) from your fork back to the original repo\nFix and discuss issues in the review process\n\nMore detailed instructions for contributing can be found on OMA README.\n\n\nSupport\nThis work has been supported by:\n\nResearch Council of Finland\nFindingPheno European Union’s Horizon 2020 research and innovation programme under grant agreement No 952914\nCOST Action network on Statistical and Machine Learning Techniques for Human Microbiome Studies (ML4microbiome) [@MorenoIndias2021].\nComputational Life Science Research Program, Biocity Turku\nTurku University Foundation"
  },
  {
    "objectID": "Session_info.html",
    "href": "Session_info.html",
    "title": "Sessioninfo",
    "section": "",
    "text": "sessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\n\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] BiocStyle_2.28.1 rebook_1.10.1   \n\nloaded via a namespace (and not attached):\n[1] knitr_1.44        shiny_1.7.5.1     htmltools_0.5.6.1 rmarkdown_2.25   \n[5] miniUI_0.1.1.1    tools_4.3.1"
  },
  {
    "objectID": "99_bibliography.html",
    "href": "99_bibliography.html",
    "title": "Bibliography",
    "section": "",
    "text": "r if (knitr::is_html_output()) ' '"
  }
]